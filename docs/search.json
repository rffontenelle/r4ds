[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R Para Ciencia de Datos",
    "section": "",
    "text": "Bienvenida\nEste es el sitio web de la versión en español de “R for Data Science”, de Hadley Wickham y Garrett Grolemund. Este texto te enseñará cómo hacer ciencia de datos con R: aprenderás a importar datos, llevarlos a la estructura más conveniente, transformarlos, visualizarlos y modelarlos. Así podrás poner en pŕactica las habilidades necesarias para hacer ciencia de datos. Tal como los químicos aprenden a limpiar tubos de ensayo y ordenar un laboratorio, aprenderás a limpiar datos y crear gráficos— junto a muchas otras habilidades que permiten que la ciencia de datos tenga lugar. En este libro encontrarás las mejores prácticas para desarrollar dichas tareas usando R. También aprenderás a usar la gramática de gráficos, programación letrada e investigación reproducible para ahorrar tiempo. Además, aprenderás a manejar recursos cognitivos para facilitar el hacer descubrimientos al momento de manipular, visualizar y explorar datos."
  },
  {
    "objectID": "index.html#sobre-la-traducción",
    "href": "index.html#sobre-la-traducción",
    "title": "R Para Ciencia de Datos",
    "section": "Sobre la traducción",
    "text": "Sobre la traducción\n\nLa traducción de “R para Ciencia de Datos” es un proyecto colaborativo de la comunidad de R de Latinoamérica, que tiene por objetivo hacer R más accesible en la región.\nEn la traducción del libro participaron las siguientes personas (en orden alfabético): Marcela Alfaro, Mónica Alonso, Fernando Álvarez, Zulemma Bazurto, Yanina Bellini, Juliana Benítez, María Paula Caldas, Elio Campitelli, Florencia D’Andrea, Rocío Espada, Joshua Kunst, Patricia Loto, Pamela Matías, Lina Moreno, Paola Prieto, Riva Quiroga, Lucía Rodríguez, Mauricio “Pachá” Vargas, Daniela Vázquez, Melina Vidoni, Roxana N. Villafañe. ¡Muchas gracias por su trabajo! La administración del repositorio con la traducción ha estado cargo de Mauricio “Pachá” Vargas. La coordinación general y la edición, a cargo de Riva Quiroga.\nAgradecemos a todas las personas que han ayudado revisando las traducciones y haciendo sugerencias de mejora. Puedes revisar la documentación del proyecto para ver los créditos de participación. Gracias también a Marcela Alfaro por el tuit que hizo visible la necesidad de la versión en español, y a Laura Ación y Edgar Ruiz, que pusieron en contacto a las personas del equipo.\nEste proyecto no solo implica la traducción del texto, sino también de los sets de datos que se utilizan a lo largo de él. Para ello, se creó el paquete datos, que contiene las versiones traducidas de estos. Puedes revisar su documentación acá. El paquete fue desarrollado por Edgar Ruiz, Riva Quiroga, Mauricio “Pachá” Vargas y Mauro Lepore. Para su creación se utilizaron funciones del paquete datalang de Edgar Ruiz y las sabias sugerencias de Hadley Wickham.\nSi quieres conocer más sobre los principios que han orientado nuestro trabajo puedes leer la documentación del proyecto. Para estar al tanto de novedades sobre el paquete {datos} y nuevas iniciativas del equipo, sigue nuestra cuenta en Twitter."
  },
  {
    "objectID": "index.html#sobre-la-versión-original-en-inglés",
    "href": "index.html#sobre-la-versión-original-en-inglés",
    "title": "R Para Ciencia de Datos",
    "section": "Sobre la versión original en inglés",
    "text": "Sobre la versión original en inglés\nPuedes consultar la versión original del libro en r4ds.had.co.nz/. Existe una edición impresa, que fue publicada por O’Reilly en enero de 2017. Puedes adquirir una copia en Amazon.\n\n(El libro “R for Data Science” primero se llamó “Data Science with R” en “Hands-On Programming with R”)\nEsta obra se distribuye bajo los términos y condiciones de la licencia Creative Commons Atribución-No Comercial-Sin Derivados 4.0 vigente en los Estados Unidos de América."
  },
  {
    "objectID": "11-import.html#introducción",
    "href": "11-import.html#introducción",
    "title": "11  Importación de datos",
    "section": "11.1 Introducción",
    "text": "11.1 Introducción\nTrabajar con datos incluidos en paquetes de R es una muy buena forma de empezar a conocer las herramientas de la ciencia de datos. Sin embargo, en algún punto deberás parar de aprender y comenzar a trabajar con tus propios datos. En este capítulo aprenderás cómo leer en R archivos rectangulares de texto plano. Si bien solo tocaremos superficialmente el tema de importación, muchos de los principios que veremos son aplicables al trabajo con otras formas de datos. Finalizaremos sugiriendo algunos paquetes que son útiles para otros formatos.\n\n11.1.1 Prerrequisitos\nEn este capítulo aprenderás cómo cargar archivos planos en R con readr, uno de los paquetes principales de tidyverse.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "11-import.html#comenzando",
    "href": "11-import.html#comenzando",
    "title": "11  Importación de datos",
    "section": "11.2 Comenzando",
    "text": "11.2 Comenzando\nLa mayoría de las funciones de readr se enfocan en transformar archivos planos en data frames:\n\nread_csv() lee archivos delimitados por coma, read_csv2() lee archivos separados por punto y coma (comunes en países donde ‘,’ es utilizada para separar decimales), read_tsv() lee archivos delimitados por tabulaciones y read_delim() archivos con cualquier delimitador.\nread_fwf() lee archivos de ancho fijo. Puedes especificar los campos ya sea por su ancho, con fwf_widths(), o por su ubicación, con fwf_positions(). read_table() lee una variación común de estos archivos de ancho fijo en los que las columnas se encuentran separadas por espacios.\nread_log() lee archivos de registro estilo Apache. (Revisa también webreadr, que está construido sobre read_log() y proporciona muchas otras herramientas útiles).\n\nTodas estas funciones tienen una sintaxis similar, por lo que una vez que dominas una, puedes utilizar todas las demás con facilidad. En el resto del capítulo nos enfocaremos en read_csv(). Los archivos csv no solo son una de las formas de almacenamiento más comunes, sino que una vez que comprendas read_csv() podrás aplicar fácilmente tus conocimientos a todas las otras funciones de readr.\nEl primer argumento de read_csv() es el más importante: es la ruta al archivo a leer.\n\nalturas &lt;- read_csv(\"data/alturas.csv\")\n\nRows: 1192 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): sex, race\ndbl (4): earn, height, ed, age\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCuando ejecutas read_csv(), la función devuelve el nombre y tipo de datos con que se importó cada columna. Esta es una parte importante de readr, sobre la cual volveremos luego en segmentar un archivo.\nPuedes también definir un archivo CSV “en línea” (inline). Esto es útil para experimentar con readr y para crear ejemplos reproducibles para ser compartidos.\n\nread_csv(\"a,b,c\n1,2,3\n4,5,6\")\n\nRows: 2 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): a, b, c\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 2 × 3\n      a     b     c\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     2     3\n2     4     5     6\n\n\nEn ambos casos read_csv() emplea la primera línea de los datos para los nombres de columna, lo que es una convención muy común. Hay dos casos en los que podrías querer ajustar este comportamiento:\n\nA veces hay unas pocas líneas de metadatos al comienzo del archivo. Puedes usar skip = n para omitir las primeras n líneas, o bien, o usar comment = \"#\" para quitar todas las líneas que comienzan con, por ejemplo, #.\n::: {.cell}\nread_csv(\"La primera línea de metadata \n  La segunda línea de metadata\n  x,y,z\n  1,2,3\", skip = 2)\n::: {.cell-output .cell-output-stderr} ``` Rows: 1 Columns: 3 ── Column specification ──────────────────────────────────────────────────────── Delimiter: “,” dbl (3): x, y, z\nℹ Use spec() to retrieve the full column specification for this data. ℹ Specify the column types or set show_col_types = FALSE to quiet this message. ``` :::\n::: {.cell-output .cell-output-stdout} # A tibble: 1 × 3        x     y     z    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  1     1     2     3 :::\nread_csv(\"# Un comentario que quiero ignorar\n  x,y,z\n  1,2,3\", comment = \"#\")\n::: {.cell-output .cell-output-stderr} ``` Rows: 1 Columns: 3 ── Column specification ──────────────────────────────────────────────────────── Delimiter: “,” dbl (3): x, y, z\nℹ Use spec() to retrieve the full column specification for this data. ℹ Specify the column types or set show_col_types = FALSE to quiet this message. ``` :::\n::: {.cell-output .cell-output-stdout} # A tibble: 1 × 3        x     y     z    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  1     1     2     3 ::: :::\nLos datos pueden no tener nombres de columna. En ese caso, puedes utilizar col_names = FALSE para decirle a read_csv() que no trate la primera fila como encabezados y que, en lugar de eso, los etiquete secuencialmente desde X1 a Xn:\n\nread_csv(\"1,2,3\\n4,5,6\", col_names = FALSE)\n\nRows: 2 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): X1, X2, X3\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 2 × 3\n     X1    X2    X3\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     2     3\n2     4     5     6\n\n\n(\"\\n\" es un atajo conveniente para agregar una línea nueva. Aprenderás más acerca de él y otros modos de evitar texto en la sección [Cadenas: elementos básicos]).\nAlternativamente puedes utilizar col_names con el vector de caracteres que será utilizado como nombres de columna:\n\nread_csv(\"1,2,3\\n4,5,6\", col_names = c(\"x\", \"y\", \"z\"))\n\nRows: 2 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): x, y, z\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 2 × 3\n      x     y     z\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     2     3\n2     4     5     6\n\n\n\nOtra opción que comúnmente necesita ajustes es na (del inglés, “not available”: Esto especifica el valor (o valores) que se utilizan para representar los valores faltantes en tu archivo:\n\nread_csv(\"a,b,c\\n1,2,.\", na = \".\")\n\nRows: 1 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): a, b\nlgl (1): c\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 1 × 3\n      a     b c    \n  &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;\n1     1     2 NA   \n\n\nEsto es todo lo que necesitas saber para leer el ~75% de los archivos csv con los que te encontrarás en la práctica. También puedes adaptar fácilmente lo que has aprendido para leer archivos separados por tabuladores con read_tsv() y archivos de ancho fijo con read_fwf(). Para leer archivos más desafiantes, necesitas aprender un poco más sobre cómo readr segmenta cada columna y las transforma en vectores de R.\n\n11.2.1 Comparación con R base\nSi has utilizado R anteriormente, tal vez te preguntas por qué no usamos read.csv(). Hay unas pocas buenas razones para preferir las funciones de readr sobre las equivalentes de R base:\n\nGeneralmente son mucho más rápidas (~10x) que sus equivalentes. Los trabajos que tienen un tiempo de ejecución prolongado poseen una barra de progreso para que puedas ver qué está ocurriendo. Si solo te interesa la velocidad, prueba data.table::fread(). No se ajusta tan bien con el tidyverse, pero puede ser bastante más rápido.\nProducen tibbles, no convierten los vectores de caracteres a factores, no usan nombres de filas ni distorsionan los nombres de columnas. Estas son fuentes comunes de frustración al utilizar las funciones de R base.\nSon más reproducibles. Las funciones de R base heredan ciertos comportamientos de tu sistema operativo y de las variables del ambiente, de modo que importar código que funciona bien en tu computadora puede no funcionar en la de otros.\n\n\n\n11.2.2 Ejercicios\n\n¿Qué función utilizarías para leer un archivo donde los campos están separados con “|”?\nAdemás de file, skip y comment, ¿qué otros argumentos tienen en común read_csv() y read_tsv()?\n¿Cuáles son los argumentos más importantes de read_fwf()?\nAlgunas veces las cadenas de caracteres en un archivo csv contienen comas. Para evitar que causen problemas, deben estar rodeadas por comillas, como \" o '. Por convención, read_csv() asume que el caracter de separación será \".¿Qué argumentos debes especificar para leer el siguiente texto en un data frame?\n::: {.cell}\n\"x,y\\n1,'a,b'\"\n:::\nIdentifica qué está mal en cada una de los siguientes archivos csv en línea (inline). ¿Qué pasa cuando corres el código?\n::: {.cell}\nread_csv(\"a,b\\n1,2,3\\n4,5,6\")\nread_csv(\"a,b,c\\n1,2\\n1,2,3,4\")\nread_csv(\"a,b\\n\\\"1\")\nread_csv(\"a,b\\n1,2\\na,b\")\nread_csv(\"a;b\\n1;3\")\n:::"
  },
  {
    "objectID": "11-import.html#segmentar-un-vector",
    "href": "11-import.html#segmentar-un-vector",
    "title": "11  Importación de datos",
    "section": "11.3 Segmentar un vector",
    "text": "11.3 Segmentar un vector\nAntes de entrar en detalles sobre cómo readr lee archivos del disco, necesitamos desviarnos un poco para hablar sobre las funciones parse_*() (del inglés analizar, segmentar). Estas funciones toman un vector de caracteres y devuelven un vector más especializado, como un vector lógico, numérico o una fecha:\n\nstr(parse_logical(c(\"TRUE\", \"FALSE\", \"NA\")))\n\n logi [1:3] TRUE FALSE NA\n\nstr(parse_integer(c(\"1\", \"2\", \"3\")))\n\n int [1:3] 1 2 3\n\nstr(parse_date(c(\"2010-01-01\", \"1979-10-14\")))\n\n Date[1:2], format: \"2010-01-01\" \"1979-10-14\"\n\n\nEstas funciones son útiles por sí mismas, pero también son un bloque estructural importante para readr. Una vez que aprendas en esta sección cómo funcionan los segmentadores individuales, en la próxima volveremos atrás y veremos cómo se combinan entre ellos para analizar un archivo completo.\nComo todas las funciones dentro del tidyverse, las funciones parse_*() son uniformes: el primer argumento es un vector de caracteres a analizar y el argumento na especifica qué cadenas deberían ser tratadas como faltantes:\n\nparse_integer(c(\"1\", \"231\", \".\", \"456\"), na = \".\")\n\n[1]   1 231  NA 456\n\n\nSi la segmentación falla, obtendrás una advertencia:\n\nx &lt;- parse_integer(c(\"123\", \"345\", \"abc\", \"123.45\"))\n\nWarning: 2 parsing failures.\nrow col               expected actual\n  3  -- no trailing characters abc   \n  4  -- no trailing characters 123.45\n\n\nY las fallas aparecerán como faltantes en el output:\n\nx\n\n[1] 123 345  NA  NA\nattr(,\"problems\")\n# A tibble: 2 × 4\n    row   col expected               actual\n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                  &lt;chr&gt; \n1     3    NA no trailing characters abc   \n2     4    NA no trailing characters 123.45\n\n\nSi hay muchas fallas de segmentación, necesitarás utilizar problems() (del inglés problemas) para obtener la totalidad de ellas. Esto devuelve un tibble que puedes luego manipular con dplyr.\n\nproblems(x)\n\n# A tibble: 2 × 4\n    row   col expected               actual\n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                  &lt;chr&gt; \n1     3    NA no trailing characters abc   \n2     4    NA no trailing characters 123.45\n\n\nUtilizar segmentadores es más que nada una cuestión de entender qué está disponible y cómo enfrentar diferentes tipos de input. Hay ocho segmentadores particularmente importantes:\n\nparse_logical() y parse_integer() analizan valores lógicos y números enteros respectivamente. No hay prácticamente nada que pueda salir mal con estos segmentadores, así que no los describiremos con detalle aquí.\nparse_double() es un segmentador numérico estricto, y parse_number() es un segmentador numérico flexible. Son más complicados de lo que podrías esperar debido a que los números se escriben de diferentes formas en distintas partes del mundo.\nparse_character() parece tan simple que no debiera ser necesario. Pero una complicación lo hace bastante importante: la codificación de caracteres (el encoding).\nparse_factor() crea factores, la estructura de datos que R usa para representar variables categóricas con valores fijos y conocidos.\nparse_datetime(), parse_date() y parse_time() te permiten analizar diversas especificaciones de fechas y horas. Estos son los más complicados, ya que hay muchas formas diferentes de escribir las fechas.\n\nLas secciones siguientes describen estos analizadores en mayor detalle.\n\n11.3.1 Números\nPareciera que analizar un número debiese ser algo sencillo, pero hay tres problemas que pueden complicar el proceso:\n\nLas personas escriben los números de forma distinta en diferentes partes del mundo. Por ejemplo, algunos países utilizan . entre el entero y la fracción de un número real, mientras que otros utilizan ,.\nA menudo los números están rodeados por otros caracteres que proporcionan algún contexto, como “$1000” o “10%”.\nLos números frecuentemente contienen caracteres de “agrupación” para hacerlos más fáciles de leer, como “1,000,000”. Estos caracteres de agrupación varían alrededor del mundo.\n\nPara enfrentar al primer problema, readr tiene el concepto de “locale”, un objeto que especifica las opciones de segmentación que difieren de un lugar a otro. Cuando segmentamos números, la opción más importante es el caracter que utilizas como símbolo decimal. Puedes sobreescribir el valor por defecto . creando un nuevo locale y estableciendo el argumento decimal_mark (del inglés marca decimal):\n\nparse_double(\"1.23\")\n\n[1] 1.23\n\nparse_double(\"1,23\", locale = locale(decimal_mark = \",\"))\n\n[1] 1.23\n\n\nEl locale por defecto de readr es EEUU-céntrico, porque generalmente R es EEUU-céntrico (por ejemplo, la documentación de R base está escrita en inglés norteamericano). Una aproximación alternativa podría ser probar y adivinar las opciones por defecto de tu sistema operativo. Esto es difícil de hacer y, lo que es más importante, hace que tu código sea frágil. Incluso si funciona en tu computadora, puede fallar cuando lo envíes a un/a colega en otro país.\nparse_number() responde al segundo problema: ignora los caracteres no-numéricos antes y después del número. Esto es particularmente útil para monedas y porcentajes, pero también sirve para extraer números insertos en texto.\n\nparse_number(\"$100\")\n\n[1] 100\n\nparse_number(\"20%\")\n\n[1] 20\n\nparse_number(\"It cost $123.45\")\n\n[1] 123.45\n\n\nEl problema final se puede enfrentar combinando parse_number() y el locale, ya que parse_number() ignorará el “símbolo decimal”:\n\n# Utilizado en América\nparse_number(\"$123,456,789\")\n\n[1] 123456789\n\n# Utilizado en muchas regiones de Europa\nparse_number(\"123.456.789\", locale = locale(grouping_mark = \".\"))\n\n[1] 123456789\n\n# Utilizado en Suiza\nparse_number(\"123'456'789\", locale = locale(grouping_mark = \"'\"))\n\n[1] 123456789\n\n\n\n\n11.3.2 Cadenas de texto (strings)\nEn apariencia, parse_character() debería ser realmente simple — podría tan solo devolver su input. Desafortunadamente, la vida no es tan simple, dado que existen múltiples formas de representar la misma cadena de texto. Para entender qué está pasando, necesitamos profundizar en los detalles de cómo las computadoras representan las cadenas de texto. En R, podemos acceder a su representación subyacente empleando charToRaw():\n\ncharToRaw(\"Hadley\")\n\n[1] 48 61 64 6c 65 79\n\n\nCada número hexadecimal representa un byte de información: 48 es H, 61 es a, y así. El mapeo desde un número hexadecimal a caracteres se denomina codificación o encoding y, en este caso, la codificación utilizada se llama ASCII. ASCII hace un muy buen trabajo representando caracteres del inglés, ya que es el American Standard Code for Information Interchange (del inglés Código Americano estandarizado para el intercambio de información).\nLas cosas se complican un poco más para lenguas distintas al inglés. En los comienzos de la computación existían muchos estándares de codificación para caracteres no-ingleses compitiendo. Para poder interpretar correctamente una cadena de texto se necesita conocer tanto los valores como la codificación. Por ejemplo, dos codificaciones comunes son Latin1 (conocida también como ISO-8859-1 y utilizada para las lenguas del oeste de Europa) y Latin2 (o ISO-8859-2, utilizada para las lenguas de Europa del este). En Latin1, el byte ‘b1’ es “Â±”, pero en Latin2, ¡es “ą”! Afortunadamente, en la actualidad hay un estándar que tiene soporte casi en todos lados: UTF-8. UTF-8 puede codificar casi cualquier caracter utilizado por humanos, así como muchos símbolos adicionales (¡como los emoji!).\nreadr utiliza UTF-8 en todas partes: asume que tus datos están codificados en UTF-8 cuando los lee y lo emplea siempre cuando los escribe. Esta es una buena opción por defecto, pero fallará con datos producidos por sistemas más viejos que no entienden UTF-8. Si te sucede esto, tus cadenas de texto se verán extrañas cuando las imprimas en la consola. Algunas veces solo uno o dos caracteres estarán errados. Otras veces obtendrás un total jeroglífico. Por ejemplo:\n\nx1 &lt;- \"El Ni\\xf1o was particularly bad this year\"\nx2 &lt;- \"\\x82\\xb1\\x82\\xf1\\x82\\xc9\\x82\\xbf\\x82\\xcd\"\nx1\n\n[1] \"El Ni\\xf1o was particularly bad this year\"\n\nx2\n\n[1] \"\\x82\\xb1\\x82\\xf1\\x82ɂ\\xbf\\x82\\xcd\"\n\n\nPara corregir el problema necesitas especificar la codificación en parse_character():\n\nparse_character(x1, locale = locale(encoding = \"Latin1\"))\n\n[1] \"El Niño was particularly bad this year\"\n\nparse_character(x2, locale = locale(encoding = \"Shift-JIS\"))\n\n[1] \"こんにちは\"\n\n\n¿Cómo encontrar la codificación correcta? Si tienes suerte, estará incluida en alguna parte de la documentación de los datos. Desafortunadamente raras veces es ese el caso, así que readr provee la función guess_encoding() para ayudarte a adivinarla. No es a prueba de tontos y funciona mejor cuando tienes mucho texto (a diferencia de aquí), pero es un punto de inicio razonable. Es esperable hacer varias pruebas con diferentes codificaciones antes de encontrar la correcta.\n\nguess_encoding(charToRaw(x1))\n\n# A tibble: 2 × 2\n  encoding   confidence\n  &lt;chr&gt;           &lt;dbl&gt;\n1 ISO-8859-1       0.46\n2 ISO-8859-9       0.23\n\nguess_encoding(charToRaw(x2))\n\n# A tibble: 1 × 2\n  encoding confidence\n  &lt;chr&gt;         &lt;dbl&gt;\n1 KOI8-R         0.42\n\n\nEl primer argumento para guess_encoding() puede ser la ruta a un archivo o, como en este caso, un vector en bruto (útil si el texto ya se encuentra en R). Las codificaciones son un tema rico y complejo y solo te hemos mostrado la superficie acá. Si quieres aprender más al respecto, te recomendamos que leas la explicación detallada en http://kunststube.net/encoding/.\n\n\n11.3.3 Factores\nR utiliza factores para representar las variables categóricas que tienen un conjunto conocido de valores posibles. Puedes darle a parse_factor() un vector de niveles conocidos (levels) para generar una advertencia cada vez que haya un valor inesperado:\n\nfruta &lt;- c(\"manzana\", \"banana\")\nparse_factor(c(\"manzana\", \"banana\", \"bananana\"), levels = fruta)\n\nWarning: 1 parsing failure.\nrow col           expected   actual\n  3  -- value in level set bananana\n\n\n[1] manzana banana  &lt;NA&gt;   \nattr(,\"problems\")\n# A tibble: 1 × 4\n    row   col expected           actual  \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;              &lt;chr&gt;   \n1     3    NA value in level set bananana\nLevels: manzana banana\n\n\nSi tienes muchas entradas problemáticas, a menudo es más fácil dejarlas como vectores de caracteres y luego utilizar las herramientas sobre las que aprenderás en los capítulos [Cadenas de caracteres] y Factores para limpiarlas.\n\n\n11.3.4 Fechas, fechas-horas, y horas\nDebes elegir entre tres segmentadores dependiendo de si quieres una fecha (el número de los días desde el 01-01-1970), una fecha-hora (el número de segundos desde la medianoche del 01-01-1970) o una hora (el número de segundos desde la medianoche). Cuando se llaman sin argumentos adicionales:\n\nparse_datetime() asume una fecha-hora ISO8601. ISO8601 es un estándar internacional en el que los componentes de una fecha están organizados de mayor a menor: año, mes, día, hora, minuto, segundo.\n\n::: {.cell}\nparse_datetime(\"2010-10-01T2010\")\n::: {.cell-output .cell-output-stdout} [1] \"2010-10-01 20:10:00 UTC\" :::\n# Si se omite la hora, será determinada como medianoche.\nparse_datetime(\"20101010\")\n::: {.cell-output .cell-output-stdout} [1] \"2010-10-10 UTC\" ::: :::\nEsta es la estandarización de fecha/hora más importante. Si trabajas con fechas y horas frecuentemente, te recomendamos que leas https://en.wikipedia.org/wiki/ISO_8601\n\nparse_date() asume un año de cuatro dígitos, un guión - o /, el mes, un guión - o / y luego el día.\n::: {.cell}\n    parse_date(\"2010-10-01\")\n::: {.cell-output .cell-output-stdout} [1] \"2010-10-01\" ::: :::\nparse_time() espera la hora, :, minutos, opcionalmente : y segundos, y un especificador opcional am/pm:\n::: {.cell}\n    library(hms)\n::: {.cell-output .cell-output-stderr} ```\nAttaching package: ‘hms’ ``` :::\n::: {.cell-output .cell-output-stderr} ``` The following object is masked from ‘package:lubridate’:\n hms\n:::\n\n```{.r .cell-code}\n    parse_time(\"01:10 am\")\n::: {.cell-output .cell-output-stdout} 01:10:00 :::\n    parse_time(\"20:10:01\")\n::: {.cell-output .cell-output-stdout} 20:10:01 ::: :::\nR base no tiene incorporada una muy buena clase para datos temporales, por lo que usamos la provista en el paquete hms.\n\nSi esos valores por defecto no funcionan con tus datos, puedes proporcionar tu propio formato fecha-hora construido con las siguientes piezas:\nAño\n%Y (4 dígitos).\n%y (2 dígitos); 00-69 -&gt; 2000-2069, 70-99 -&gt; 1970-1999.\nMes\n%m (2 dígitos).\n%b (nombre abreviado, como “ene”).\n%B (nombre completo, “enero”).\nDía\n%d (2 dígitos).\n%e (espacio opcional destacado).\nHora\n%H 0-23 horas.\n%I 0-12, debe utilizarse con %p.\n%p indicador AM/PM.\n%M minutos.\n%S segundos enteros.\n%OS segundos reales.\n%Z Zona horaria (como nombre, por ejemplo, America/Chicago). Advertencia sobre abreviaturas: si eres de EEUU, ten en cuenta que “EST” es una zona horaria canadiense que no tiene cambios de horario.¡No es la hora Estandar del Este! Retomaremos esto más adelante en la sección [Husos horarios].\n%z (como complemento para las UTC, por ejemplo, +0800).\nNo-dígitos\n%. se salta un caracter no-dígito.\n%* se salta cualquier número de caracteres no-dígitos.\nLa mejor manera de deducir el formato correcto es crear unos pocos ejemplos en un vector de caracteres y probarlos con una de las funciones de segmentación. Por ejemplo:\n\nparse_date(\"01/02/15\", \"%m/%d/%y\")\n\n[1] \"2015-01-02\"\n\nparse_date(\"01/02/15\", \"%d/%m/%y\")\n\n[1] \"2015-02-01\"\n\nparse_date(\"01/02/15\", \"%y/%m/%d\")\n\n[1] \"2001-02-15\"\n\n\nSi estás utilizando %b o %B con nombres de meses no ingleses, necesitarás ajustar el argumento lang para locale(). Mira la lista de lenguas incorporados en date_names_langs(). Si tu lengua no está incluida, puedes crearla con date_names().\n\nparse_date(\"1 janvier 2015\", \"%d %B %Y\", locale = locale(\"fr\"))\n\n[1] \"2015-01-01\"\n\n\n\n\n11.3.5 Ejercicios\n\n¿Cuáles son los argumentos más importantes para locale()?\n¿Qué pasa si intentas establecer decimal_mark y grouping_mark como el mismo caracter? ¿Qué pasa con el valor por defecto de grouping_mark cuando estableces decimal_mark como ,? ¿Qué pasa con el valor por defecto de decimal_mark cuando estableces grouping_mark como .?\nNo discutimos las opciones de date_format y time_format para locale(). ¿Qué hacen? Construye un ejemplo que muestre cuándo podrían ser útiles.\nSi vives fuera de EEUU, crea un nuevo objeto locale que contenga las opciones para los tipos de archivo que lees más comúnmente.\n¿Cuál es la diferencia entre read_csv() y read_csv2()?\n¿Cuáles son las codificaciones más comunes empleadas en Europa? ¿Cuáles son las codificaciones más comunes utilizadas en Asia? ¿Y en América Latina? Googlea un poco para descubrirlo.\nGenera el formato correcto de texto para segmentar cada una de las siguientes fechas y horas:\n\nd1 &lt;- \"Enero 1, 2010\"\nd2 &lt;- \"2015-Ene-07\"\nd3 &lt;- \"06-Jun-2017\"\nd4 &lt;- c(\"Augosto 19 (2015)\", \"Julio 1 (2015)\")\nd5 &lt;- \"12/30/14\" # Dec 30, 2014\nt1 &lt;- \"1705\"\nt2 &lt;- \"11:15:10.12 PM\""
  },
  {
    "objectID": "11-import.html#segmentar-un-archivo",
    "href": "11-import.html#segmentar-un-archivo",
    "title": "11  Importación de datos",
    "section": "11.4 Segmentar un archivo",
    "text": "11.4 Segmentar un archivo\nAhora que aprendiste cómo analizar un vector individual, es tiempo de volver al comienzo y explorar cómo readr analiza un archivo. Hay dos cosas nuevas que aprenderás al respecto en esta sección:\n\nCómo readr deduce automáticamente el tipo de cada columna.\nCómo sobreescribir las especificaciones por defecto.\n\n\n11.4.1 Estrategia\nreadr utiliza una heurística para deducir el tipo de cada columna: lee las primeras 1000 filas y utiliza una heurística (moderadamente conservadora) para deducir el formato de las columnas. Puedes simular este proceso con un vector de caracteres utilizando guess_parser(), que devuelve la mejor deducción de readr, y parse_guess() que utiliza esa deducción para analizar la columna:\n\nguess_parser(\"2010-10-01\")\n\n[1] \"date\"\n\nguess_parser(\"15:01\")\n\n[1] \"time\"\n\nguess_parser(c(\"TRUE\", \"FALSE\"))\n\n[1] \"logical\"\n\nguess_parser(c(\"1\", \"5\", \"9\"))\n\n[1] \"double\"\n\nguess_parser(c(\"12,352,561\"))\n\n[1] \"number\"\n\nstr(parse_guess(\"2010-10-10\"))\n\n Date[1:1], format: \"2010-10-10\"\n\n\nLa heurística prueba cada uno de los siguientes tipos y se detiene cuando encuentra una coincidencia:\n\nlógico: contiene solo “F”, “T”, “FALSE”, o “TRUE”.\nentero: contiene solo caracteres numéricos (y ‘-’).\ndoble: contiene solo dobles válidos (incluyendo números como ‘4.5e-5’).\nnúmero: contiene dobles válidos con la marca de agrupamiento en su interior.\nhora: coincide con el formato horario por defecto (time_format).\nfecha: coincide con el formato fecha por defecto (date_format).\nfecha-hora: cualquier fecha ISO8601.\n\nSi ninguna de esas reglas se aplica, entonces la columna quedará como un vector de cadenas de caracteres.\n\n\n11.4.2 Problemas\nEsos valores por defecto no siempre funcionan para archivos de gran tamaño. Hay dos problemas básicos:\n\nLas primeras mil filas podrían ser un caso especial y readr estaría deduciendo un formato que no es suficientemente general. Por ejemplo, podrías tener una columna de dobles que solo contiene enteros en las primeras 1000 filas.\nLa columna podría contener muchos valores faltantes. Si las primeras 1000 filas contienen solo NA, readr deducirá que es un vector lógico, mientras que tú probablemente quieras analizarlo como algo más específico.\n\nreadr contiene un archivo csv desafiante que ilustra ambos problemas:\n\ndesafio &lt;- read_csv(readr_example(\"challenge.csv\"))\n\nRows: 2000 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl  (1): x\ndate (1): y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n(Fíjate en el uso de readr_example(), que encuentra la ruta a uno de los archivos incluidos en el paquete.)\nHay dos outputs impresos en la consola: la especificación de columna generada al mirar las primeras 1000 filas y las primeras cinco fallas de segmentación. Siempre es una buena idea extraer explícitamente los problemas con problems(), así puedes explorarlos en mayor profundidad:\n\nproblems(desafio)\n\n# A tibble: 0 × 5\n# ℹ 5 variables: row &lt;int&gt;, col &lt;int&gt;, expected &lt;chr&gt;, actual &lt;chr&gt;, file &lt;chr&gt;\n\n\nUna buena estrategia es trabajar columna por columna hasta que no queden problemas. Aquí podemos ver que hubo muchos problemas de análisis con la columna y. Si miramos la últimas líneas, verás que hay fechas almacenadas en un vector de caracteres.\n\ntail(desafio)\n\n# A tibble: 6 × 2\n      x y         \n  &lt;dbl&gt; &lt;date&gt;    \n1 0.805 2019-11-21\n2 0.164 2018-03-29\n3 0.472 2014-08-04\n4 0.718 2015-08-16\n5 0.270 2020-02-04\n6 0.608 2019-01-06\n\n\nEsto sugiere que mejor sería utilizar un segmentador de fechas. Para arreglar este problema, copia y pega la especificación de las columnas que habías obtenido inicialmente y agrégalas a tu código:\n\ndesafio &lt;- read_csv(\n  readr_example(\"challenge.csv\"), \n  col_types = cols(\n    x = col_double(),\n    y = col_logical()\n  )\n)\n\nY luego ajusta el tipo de la columna y especificando que se trata de una fecha:\n\ndesafio &lt;- read_csv(\n  readr_example(\"challenge.csv\"), \n  col_types = cols(\n    x = col_double(),\n    y = col_date()\n  )\n)\ntail(desafio)\n\n# A tibble: 6 × 2\n      x y         \n  &lt;dbl&gt; &lt;date&gt;    \n1 0.805 2019-11-21\n2 0.164 2018-03-29\n3 0.472 2014-08-04\n4 0.718 2015-08-16\n5 0.270 2020-02-04\n6 0.608 2019-01-06\n\n\nCada función parse_*() tiene su correspondiente función col_*(). Se utiliza parse_*() cuando los datos se encuentran en un vector de caracteres que ya está disponible en R; col_* para cuando quieres decirle a readr cómo cargar los datos.\nTe recomendamos proporcionar la estructura para col_types a partir de la impresión en consola provista por readr. Esto asegura que tienes un script para importar datos consistente y reproducible. Si confías en las deducciones por defecto y tus datos cambian, readr continuará leyéndolos. Si quieres ser realmente estricto/a, emplea stop_for_problems() (detenerse en problemas): esto devolverá un mensaje de error y detendrá tu script si hay cualquier problema con la segmentación.\n\n\n11.4.3 Otras estrategias\nExisten algunas estrategias generales más para ayudarte a segmentar archivos:\n\nEn el ejemplo previo simplemente tuvimos mala suerta: si miramos solo una fila más que el número por defecto, podemos segmentar correctamente en un solo intento:\n\ndesafio2 &lt;- read_csv(readr_example(\"challenge.csv\"), guess_max = 1001)\n\nRows: 2000 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl  (1): x\ndate (1): y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndesafio2\n\n# A tibble: 2,000 × 2\n       x y     \n   &lt;dbl&gt; &lt;date&gt;\n 1   404 NA    \n 2  4172 NA    \n 3  3004 NA    \n 4   787 NA    \n 5    37 NA    \n 6  2332 NA    \n 7  2489 NA    \n 8  1449 NA    \n 9  3665 NA    \n10  3863 NA    \n# ℹ 1,990 more rows\n\n\nAlgunas veces es más fácil diagnosticar problemas si lees todas las columnas como vectores de caracteres:\n\ndesafio &lt;- read_csv(readr_example(\"challenge.csv\"), \n  col_types = cols(.default = col_character())\n)\n\nEsto es particularmente útil en combinación con ‘type_convert()’, que aplica la heurística de segmentación a las columnas de caracteres en un data frame.\n\n  df &lt;- tribble(\n    ~x,  ~y,\n    \"1\", \"1.21\",\n    \"2\", \"2.32\",\n    \"3\", \"4.56\"\n  )\n  df\n\n# A tibble: 3 × 2\n  x     y    \n  &lt;chr&gt; &lt;chr&gt;\n1 1     1.21 \n2 2     2.32 \n3 3     4.56 \n\n# Fíjate en los tipos de columna\ntype_convert(df)\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  x = col_double(),\n  y = col_double()\n)\n\n\n# A tibble: 3 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1     1  1.21\n2     2  2.32\n3     3  4.56\n\n\nSi estás leyendo un archivo muy largo, podrías querer seleccionar n_max a un número pequeño como 10000 o 100000. Esto acelerará las iteraciones a la vez que eliminarás problemas comunes.\nSi tienes problemas de segmentación importantes, a veces es más fácil leer un vector de caracteres de líneas con read_lines(), o incluso un vector de caracteres de largo 1 con read_file(). Luego puedes utilizar las habilidades sobre segmentación de cadenas de caracteres que aprenderás más adelante para segmentar formatos más exóticos."
  },
  {
    "objectID": "11-import.html#escribir-a-un-archivo",
    "href": "11-import.html#escribir-a-un-archivo",
    "title": "11  Importación de datos",
    "section": "11.5 Escribir a un archivo",
    "text": "11.5 Escribir a un archivo\nreadr también incluye dos funciones muy útiles para escribir datos de vuelta al disco: write_csv() y write_tsv(). Ambas funciones incrementan las posibilidades de que el archivo resultante sea leído correctamente al:\n\ncodificar siempre las cadenas de caracteres en UTF-8.\nguardar fechas y fechas-horas en formato ISO8601, por lo que son fácilmente segmentadas en cualquier sitio.\n\nSi quieres exportar un archivo csv a Excel, utiliza write_excel_csv() —esto escribe un caracter especial (una marca de orden de bytes) al comienzo del archivo que le dice a Excel que estás utilizando codificación UTF-8. Los argumentos más importantes son x (el data frame a guardar) y path (la ubicación donde lo guardarás). También puedes especificar cómo se escriben los valores ausentes con na y si quieres append (agregarlo) a un archivo existente.\n\nwrite_csv(desafio, \"desafio.csv\")\n\nFíjate que la información sobre el tipo de datos se pierde cuando guardas en csv:\n\ndesafio\n\n# A tibble: 2,000 × 2\n   x     y    \n   &lt;chr&gt; &lt;chr&gt;\n 1 404   &lt;NA&gt; \n 2 4172  &lt;NA&gt; \n 3 3004  &lt;NA&gt; \n 4 787   &lt;NA&gt; \n 5 37    &lt;NA&gt; \n 6 2332  &lt;NA&gt; \n 7 2489  &lt;NA&gt; \n 8 1449  &lt;NA&gt; \n 9 3665  &lt;NA&gt; \n10 3863  &lt;NA&gt; \n# ℹ 1,990 more rows\n\nwrite_csv(desafio, \"desafio-2.csv\")\nread_csv(\"desafio-2.csv\")\n\nRows: 2000 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl  (1): x\ndate (1): y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 2,000 × 2\n       x y     \n   &lt;dbl&gt; &lt;date&gt;\n 1   404 NA    \n 2  4172 NA    \n 3  3004 NA    \n 4   787 NA    \n 5    37 NA    \n 6  2332 NA    \n 7  2489 NA    \n 8  1449 NA    \n 9  3665 NA    \n10  3863 NA    \n# ℹ 1,990 more rows\n\n\nEsto hace a los CSV poco confiables para almacenar en caché los resultados provisorios — necesitas recrear la especificación de las columnas cada vez que los cargas. Hay dos alternativas:\n\nwrite_rds() and read_rds() son funciones “envoltorio” (wrappers) uniformes sobre las funciones base readRDS() y saveRDS(). Estas almacenan datos en un formato binario propio de R llamado RDS:\n\nwrite_rds(desafio, \"desafio.rds\")\nread_rds(\"desafio.rds\")\n\n# A tibble: 2,000 × 2\n   x     y    \n   &lt;chr&gt; &lt;chr&gt;\n 1 404   &lt;NA&gt; \n 2 4172  &lt;NA&gt; \n 3 3004  &lt;NA&gt; \n 4 787   &lt;NA&gt; \n 5 37    &lt;NA&gt; \n 6 2332  &lt;NA&gt; \n 7 2489  &lt;NA&gt; \n 8 1449  &lt;NA&gt; \n 9 3665  &lt;NA&gt; \n10 3863  &lt;NA&gt; \n# ℹ 1,990 more rows\n\n\nEl paquete feather implementa un formato rápido de archivos binarios que puede compartirse a través de lenguajes de programación:\n::: {.cell}\nlibrary(feather)\nwrite_feather(desafio, \"desafio.feather\")\nread_feather(\"desafio.feather\")\n#&gt; # A tibble: 2,000 x 2\n#&gt;       x      y\n#&gt;   &lt;dbl&gt; &lt;date&gt;\n#&gt; 1   404   &lt;NA&gt;\n#&gt; 2  4172   &lt;NA&gt;\n#&gt; 3  3004   &lt;NA&gt;\n#&gt; 4   787   &lt;NA&gt;\n#&gt; 5    37   &lt;NA&gt;\n#&gt; 6  2332   &lt;NA&gt;\n#&gt; # ... with 1,994 more rows\n:::\n\nFeather tiende a ser más rápido que RDS y es utilizable fuera de R. RDS permite columnas-listas (sobre las que aprenderás en el capítulo [Muchos modelos]), algo que feather no permite actualmente."
  },
  {
    "objectID": "11-import.html#otros-tipos-de-datos",
    "href": "11-import.html#otros-tipos-de-datos",
    "title": "11  Importación de datos",
    "section": "11.6 Otros tipos de datos",
    "text": "11.6 Otros tipos de datos\nPara acceder a otros tipos de datos en R te recomendamos comenzar con los paquetes de tidyverse listados abajo. Ciertamente no son perfectos, pero son un buen lugar para comenzar. Para datos rectangulares:\n\nhaven lee archivos SPSS, Stata y SAS.\nreadxl lee archivos excel (tanto .xls como .xlsx).\nDBI, junto con un backend de base de datos específico (e.g. RMySQL, RSQLite, RPostgreSQL, etc.) te permite correr consultas SQL contra una base de datos y devolver un data frame.\n\nPara datos jerárquicos: utiliza jsonlite (de Jeroen Ooms) para json y xml2 para XML. Jenny Bryan tiene algunos ejemplos muy bien trabajados en https://jennybc.github.io/purrr-tutorial/.\nPara otros tipos de archivos, prueba el manual de importación/exportación de datos de R y el paquete rio."
  },
  {
    "objectID": "12-tidy.html#introducción",
    "href": "12-tidy.html#introducción",
    "title": "12  Datos ordenados",
    "section": "12.1 Introducción",
    "text": "12.1 Introducción\n\n“Todas las familias felices se parecen unas a otras, pero cada familia infeliz lo es a su manera.” –– León Tolstoy\n\n\n“Todos los set de datos ordenados se parecen unos a otros, pero cada set de datos desordenado lo es a su manera” — Hadley Wickham\n\nEn este capítulo aprenderás una manera consistente para organizar tus datos en R a la que llamaremos tidy data (datos ordenados). Llevar tus datos a este formato requiere algo de trabajo previo; sin embargo, dicho trabajo tiene retorno positivo en el largo plazo. Una vez que tengas tus datos ordenados y las herramientas para ordenar datos que provee el tidyverse, vas a gastar mucho menos tiempo pasando de una forma de representar datos a otra, lo que te permitirá destinar más tiempo a las preguntas analíticas.\nEste capítulo te dará una introducción práctica a los datos ordenados (o tidy data) y a las herramientas que provee el paquete tidyr. Si deseas aprender más acerca de la teoría subyacente, puede que te guste el artículo Tidy Data publicado en la revista Journal of Statistical Software, http://www.jstatsoft.org/v59/i10/paper.\n\n12.1.1 Prerrequisitos\nEn este capítulo nos enfocaremos en tidyr, un paquete que provee un conjunto de herramientas que te ayudarán a ordenar datos desordenados. tidyr es parte del núcleo del tidyverse.\n\nlibrary(tidyverse)\nlibrary(datos)"
  },
  {
    "objectID": "12-tidy.html#datos-ordenados",
    "href": "12-tidy.html#datos-ordenados",
    "title": "12  Datos ordenados",
    "section": "12.2 Datos ordenados",
    "text": "12.2 Datos ordenados\nPuedes representar los mismos datos subyacentes de múltiples formas. El ejemplo a continuación muestra los mismos datos organizados de cuatro maneras distintas. Cada dataset muestra los mismos valores de cuatro variables —pais, anio, poblacion y casos—, pero cada uno organiza los valores de forma distinta.\n\ntabla1\n\n# A tibble: 6 × 4\n  pais        anio  casos  poblacion\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afganistán  1999    745   19987071\n2 Afganistán  2000   2666   20595360\n3 Brasil      1999  37737  172006362\n4 Brasil      2000  80488  174504898\n5 China       1999 212258 1272915272\n6 China       2000 213766 1280428583\n\ntabla2\n\n# A tibble: 12 × 4\n   pais        anio tipo          cuenta\n   &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;\n 1 Afganistán  1999 casos            745\n 2 Afganistán  1999 población   19987071\n 3 Afganistán  2000 casos           2666\n 4 Afganistán  2000 población   20595360\n 5 Brasil      1999 casos          37737\n 6 Brasil      1999 población  172006362\n 7 Brasil      2000 casos          80488\n 8 Brasil      2000 población  174504898\n 9 China       1999 casos         212258\n10 China       1999 población 1272915272\n11 China       2000 casos         213766\n12 China       2000 población 1280428583\n\ntabla3\n\n# A tibble: 6 × 3\n  pais        anio tasa             \n  &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;            \n1 Afganistán  1999 745/19987071     \n2 Afganistán  2000 2666/20595360    \n3 Brasil      1999 37737/172006362  \n4 Brasil      2000 80488/174504898  \n5 China       1999 212258/1272915272\n6 China       2000 213766/1280428583\n\n# Dividido en dos tibbles\ntabla4a # casos\n\n# A tibble: 3 × 3\n  pais       `1999` `2000`\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n1 Afganistán    745   2666\n2 Brasil      37737  80488\n3 China      212258 213766\n\ntabla4b # poblacion\n\n# A tibble: 3 × 3\n  pais           `1999`     `2000`\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;\n1 Afganistán   19987071   20595360\n2 Brasil      172006362  174504898\n3 China      1272915272 1280428583\n\n\nLas anteriores son representaciones de los mismos datos subyacentes, pero no todas son igualmente fáciles de usar. Un tipo de conjunto de datos, el conjunto de datos ordenado, será mucho más fácil de trabajar dentro del tidyverse.\nExisten tres reglas interrelacionadas que hacen que un conjunto de datos sea ordenado:\n\nCada variable debe tener su propia columna.\nCada observación debe tener su propia fila.\nCada valor debe tener su propia celda.\n\nLa figura @ref(fig:tidy-structure) muestra estas reglas visualmente.\n\n\n\n\n\nReglas que hacen que un conjunto de datos sea ordenado: las variables están en columnas, las observaciones en filas y los valores en celdas.\n\n\n\n\nEstas reglas están interrelacionadas ya que es imposible cumplir solo dos de las tres. Esta interrelación lleva a un conjunto práctico de instrucciones más simple aún:\n\nColoca cada conjunto de datos en un tibble.\nColoca cada variable en una columna.\n\nEn este ejemplo, solo la tabla1 está ordenada. Es la única representación en que cada columna es una variable.\n¿Por qué asegurarse de que los datos estén ordenados? Existen dos ventajas principales:\n\nExiste una ventaja general al elegir una forma consistente de almacenar datos. Si tienes una estructura de datos consistente, es más fácil aprender las herramientas que funcionan con ella ya que tienen una uniformidad subyacente.\nExiste una ventaja específica al situar las variables en las columnas, ya que permite que la naturaleza vectorizada de R brille. Como habrás aprendido en las secciones sobre crear nuevas variables y resúmenes, muchas de las funciones que vienen con R trabajan con vectores de valores. Esto hace que transformar datos ordenados se perciba como algo casi natural.\n\ndplyr, ggplot2 y el resto de los paquetes del tidyverse están diseñados para trabajar con datos ordenados. Aquí hay algunos ejemplos de cómo podrías trabajar con tabla1.\n\n# Calcular tasa por cada 10,000 habitantes\ntabla1 %&gt;%\n  mutate(tasa = casos / poblacion * 10000)\n\n# A tibble: 6 × 5\n  pais        anio  casos  poblacion  tasa\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Afganistán  1999    745   19987071 0.373\n2 Afganistán  2000   2666   20595360 1.29 \n3 Brasil      1999  37737  172006362 2.19 \n4 Brasil      2000  80488  174504898 4.61 \n5 China       1999 212258 1272915272 1.67 \n6 China       2000 213766 1280428583 1.67 \n\n# Calcular casos por anio\ntabla1 %&gt;%\n  count(anio, wt = casos)\n\n# A tibble: 2 × 2\n   anio      n\n  &lt;dbl&gt;  &lt;dbl&gt;\n1  1999 250740\n2  2000 296920\n\n# Visualizar cambios en el tiempo\nlibrary(ggplot2)\nggplot(tabla1, aes(anio, casos)) +\n  geom_line(aes(group = pais), colour = \"grey50\") +\n  geom_point(aes(colour = pais))\n\n\n\n\n\n12.2.1 Ejercicios\n\nUsando prosa, describe cómo las variables y observaciones se organizan en las tablas de ejemplo.\nCalcula la tasa para las tablas tabla2 y tabla4a + tabla4b. Necesitarás las siguientes operaciones:\nExtraer el número de casos de tuberculosis por país y año.\nExtraer la población por país y año.\nDividir los casos por la población y multiplicarla por 10000.\nInsertar los datos de vuelta en el lugar adecuado.\n\n¿Cuál representación es más fácil de trabajar? ¿Cuál es la más difícil? ¿Por qué?\n\nRecrea el gráfico que muestra el cambio en el número de casos usando la tabla2 en lugar de la tabla1. ¿Qué necesitas hacer en primero?"
  },
  {
    "objectID": "12-tidy.html#pivotar",
    "href": "12-tidy.html#pivotar",
    "title": "12  Datos ordenados",
    "section": "12.3 Pivotar",
    "text": "12.3 Pivotar\nLos principios sobre datos ordenados parecen tan obvios que te podrías preguntar si alguna vez encontrarás un dataset que no esté ordenado. Desafortunadamente, gran parte de los datos que vas a encontrar están desordenados. Existen dos principales razones para esto:\n\nLa mayoría de las personas no están familiarizadas con los principios de datos ordenados y es difícil derivarlos por cuenta propia a menos que pases mucho tiempo trabajando con datos.\nLos datos a menudo están organizados para facilitar tareas distintas del análisis. Por ejemplo, los datos se organizan para que su registro sea lo más sencillo posible.\n\nEsto significa que para la mayoría de los análisis necesitarás hacer algún tipo de orden. El primer paso es entender siempre cuáles son las variables y las observaciones. Esto a veces es fácil; otras veces deberás consultar con quienes crearon el dataset. El segundo paso es resolver uno de los siguientes problemas frecuentes:\n\nUna variable se extiende por varias columnas\nUna observación está dispersa entre múltiples filas.\n\nTípicamente, un set de datos tiene uno de estos problemas. Si contiene ambos ¡significa que tienes muy mala suerte! Para solucionar estos problemas necesitarás las dos funciones más importantes de tidyr: gather() (reunir) y spread() (esparcir/extender).\n\n12.3.1 Datos “largos”\nUn problema común es cuando en un dataset los nombres de las columnas no representan nombres de variables, sino que representan los valores de una variable. Tomando el caso de la tabla4a: los nombres de las columnas 1999 y 2000 representan los valores de la variable año, los valores en las columnas 1999 y 2000 representan valores de la variable casos y cada fila representa dos observaciones en lugar de una.\n\ntabla4a\n\n# A tibble: 3 × 3\n  pais       `1999` `2000`\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n1 Afganistán    745   2666\n2 Brasil      37737  80488\n3 China      212258 213766\n\n\nPara ordenar un dataset como este necesitamos pivotar las columnas que no cumplen en un nuevo par de variables. Para describir dicha operación necesitamos tres parámetros:\n\nEl conjunto de columnas cuyos nombres son valores y no variables. En este ejemplo son las columnas 1999 y 2000.\nEl nombre de la variable cuyos valores forman los nombres de las columnas. Llamaremos a esto key (clave) y en este caso corresponde a anio.\nEl nombre de la variable cuyos valores están repartidos por las celdas. Llamaremos a esto value (valor) y en este caso corresponde al número de casos.\n\nCon estos parámetros podemos utilizar la función pivot_longer() (pivotar a lo largo):\n\ntabla4a %&gt;%\n  pivot_longer(cols = c(`1999`, `2000`), names_to = \"anio\", values_to = \"casos\")\n\n# A tibble: 6 × 3\n  pais       anio   casos\n  &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;\n1 Afganistán 1999     745\n2 Afganistán 2000    2666\n3 Brasil     1999   37737\n4 Brasil     2000   80488\n5 China      1999  212258\n6 China      2000  213766\n\n\nLas columnas a girar quedan seleccionadas siguiendo el estilo de notación de dplyr::select(). En este caso hay solo dos columnas, por lo que las listamos individualmente. Ten en consideración que “1999” y “2000” son nombres no-sintáxicos (debido a que no comienzan con una letra) por lo que los rodeamos con acentos graves (o_backticks_). Para refrescar tu memoria respecto de la selección de columnas, consulta la sección sobre select. Las variables anio y casos no existen todavpia en la tabla4a, por lo que tenemos que poner sus nombres entre comillas.\n\n\n\n\n\nPivotar la tabla4 para un formato ‘largo’ y ordenado.\n\n\n\n\nEn el resultado final, las columnas pivotadas se eliminan y obtenemos la nuevas columnas anio y casos. La relación entre las variables originales se mantiene, tal como se puede observar en la Figura @ref(fig:tidy-gather). Podemos usar pivot_longer() para ordenar tabla4b de modo similar. La única diferencia es la variable almacenada en los valores de las celdas:\n\ntabla4b %&gt;%\n  pivot_longer(cols = c(`1999`, `2000`), names_to = \"anio\", values_to = \"poblacion\")\n\n# A tibble: 6 × 3\n  pais       anio   poblacion\n  &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt;\n1 Afganistán 1999    19987071\n2 Afganistán 2000    20595360\n3 Brasil     1999   172006362\n4 Brasil     2000   174504898\n5 China      1999  1272915272\n6 China      2000  1280428583\n\n\nPara combinar las versiones ordenadas de tabla4a y tabla4b en un único tibble, necesitamos usar dplyr::left_join(), función que aprenderás en el capítulo sobre [datos relacionales].\n\ntidy4a &lt;- tabla4a %&gt;%\n  pivot_longer(cols = c(`1999`, `2000`), names_to = \"anio\", values_to = \"casos\")\n\ntidy4b &lt;- tabla4b %&gt;%\n  pivot_longer(cols = c(`1999`, `2000`), names_to = \"anio\", values_to = \"poblacion\")\n\nleft_join(tidy4a, tidy4b)\n\nJoining with `by = join_by(pais, anio)`\n\n\n# A tibble: 6 × 4\n  pais       anio   casos  poblacion\n  &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afganistán 1999     745   19987071\n2 Afganistán 2000    2666   20595360\n3 Brasil     1999   37737  172006362\n4 Brasil     2000   80488  174504898\n5 China      1999  212258 1272915272\n6 China      2000  213766 1280428583\n\n\n\n\n12.3.2 Datos “anchos”\npivot_wider() (pivotar a lo ancho) es lo opuesto de pivot_longer(). Se usa cuando una observación aparece en múltiples filas. Por ejemplo, considera la tabla2: una observación es un país en un año, pero cada observación aparece en dos filas.\n\ntabla2\n\n# A tibble: 12 × 4\n   pais        anio tipo          cuenta\n   &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;\n 1 Afganistán  1999 casos            745\n 2 Afganistán  1999 población   19987071\n 3 Afganistán  2000 casos           2666\n 4 Afganistán  2000 población   20595360\n 5 Brasil      1999 casos          37737\n 6 Brasil      1999 población  172006362\n 7 Brasil      2000 casos          80488\n 8 Brasil      2000 población  174504898\n 9 China       1999 casos         212258\n10 China       1999 población 1272915272\n11 China       2000 casos         213766\n12 China       2000 población 1280428583\n\n\nPara ordenar esto, primero analizamos la representación de un modo similar a cómo se haría con pivot_longer(). Esta vez, sin embargo, necesitamos únicamente dos parámetros:\n\nLa columna desde la que obtener los nombres de las variables. En este caso corresponde a tipo.\nLa columna desde la que obtener los valores. En este caso corresponde a cuenta.\n\nUna vez resuelto esto, podemos usar pivot_wider(), como se muestra programáticamente abajo y visualmente en la Figura @ref(fig:tidy-spread).\n\ntabla2 %&gt;%\n  pivot_wider(names_from = tipo, values_from = cuenta)\n\n# A tibble: 6 × 4\n  pais        anio  casos  población\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afganistán  1999    745   19987071\n2 Afganistán  2000   2666   20595360\n3 Brasil      1999  37737  172006362\n4 Brasil      2000  80488  174504898\n5 China       1999 212258 1272915272\n6 China       2000 213766 1280428583\n\n\n\n\n\n\n\nPivotar la tabla2 para un formato ‘ancho’ y ordenado\n\n\n\n\nComo te habrás dado cuenta a partir de sus nombres, las funciones pivot_longer() y pivot_wider() son complementarias. pivot_longer() genera tablas angostas y largas, pivot_wider() genera tablas anchas y cortas.\n\n\n12.3.3 Ejercicios\n\n¿Por qué pivot_longer() y pivot_wider() no son perfectamente simétricas? Observa cuidadosamente el siguiente ejemplo:\n\n::: {.cell}\nacciones &lt;- tibble(\n  anio = c(2015, 2015, 2016, 2016),\n  semestre = c(1, 2, 1, 2),\n  retorno = c(1.88, 0.59, 0.92, 0.17)\n)\nacciones %&gt;%\n  pivot_wider(names_from = anio, values_from = retorno) %&gt;% \n  pivot_longer(`2015`:`2016`, names_to = \"anio\", values_to = \"retorno\")\n:::\n(Sugerencia: observa los tipos de variables y piensa en los nombres de las columnas)\n`pivot_longer()` tiene el argumento `names_ptype`: por ejemplo: `names_ptype = list(year = double())`. ¿Qué es lo que hace dicho argumento?\n\n¿Por qué falla el siguiente código?\n\n::: {.cell}\ntabla4a %&gt;%\n  pivot_longer(c(1999, 2000), names_to = \"anio\", values_to = \"casos\")\n::: {.cell-output .cell-output-error} Error in `pivot_longer()`:   ! Can't subset columns past the end.   ℹ Locations 1999 and 2000 don't exist.   ℹ There are only 3 columns. ::: :::\n\n¿Qué pasaría si trataras de pivotar esta tabla a lo ancho? ¿Por qué? ¿Cómo podrías agregar una nueva columna que identifique de manera única cada valor?\n\n::: {.cell}\npersonas &lt;- tribble(\n  ~nombre, ~nombres, ~valores,\n  #-----------------|--------|------\n  \"Phillip Woods\", \"edad\", 45,\n  \"Phillip Woods\", \"estatura\", 186,\n  \"Phillip Woods\", \"edad\", 50,\n  \"Jessica Cordero\", \"edad\", 37,\n  \"Jessica Cordero\", \"estatura\", 156\n)\n:::\n\nOrdena la siguiente tabla. ¿Necesitas alargarla o ensancharla? ¿Cuáles son las variables?\n\n::: {.cell}\nembarazo &lt;- tribble(\n  ~embarazo, ~hombre, ~mujer,\n  \"sí\", NA, 10,\n  \"no\", 20, 12\n)\n:::"
  },
  {
    "objectID": "12-tidy.html#separar-y-unir",
    "href": "12-tidy.html#separar-y-unir",
    "title": "12  Datos ordenados",
    "section": "12.4 Separar y unir",
    "text": "12.4 Separar y unir\nHasta ahora has aprendido a ordenar las tablas tabla2 y tabla4, pero no la tabla3, que tiene un problema diferente: tenemos una columna (tasa) que contiene dos variables (casos y poblacion). Para solucionar este problema, necesitamos la función separate() (separar). También aprenderás acerca del complemento de separate(): unite() (unir), que se usa cuando una única variable se reparte en varias columnas.\n\n12.4.1 Separar\nseparate() desarma una columna en varias columnas, dividiendo de acuerdo a la posición de un carácter separador. Tomemos la tabla3:\n\ntabla3\n\n# A tibble: 6 × 3\n  pais        anio tasa             \n  &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;            \n1 Afganistán  1999 745/19987071     \n2 Afganistán  2000 2666/20595360    \n3 Brasil      1999 37737/172006362  \n4 Brasil      2000 80488/174504898  \n5 China       1999 212258/1272915272\n6 China       2000 213766/1280428583\n\n\nLa columna tasa contiene tanto los casos como la poblacion, por lo que necesitamos dividirla en dos variables. La función separate() toma el nombre de la columna a separar y el nombre de las columnas a donde irá el resultado, tal como se muestra en la Figura @ref(fig:tidy-separate) y el código a continuación.\n\ntabla3 %&gt;%\n  separate(tasa, into = c(\"casos\", \"poblacion\"))\n\n# A tibble: 6 × 4\n  pais        anio casos  poblacion \n  &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n1 Afganistán  1999 745    19987071  \n2 Afganistán  2000 2666   20595360  \n3 Brasil      1999 37737  172006362 \n4 Brasil      2000 80488  174504898 \n5 China       1999 212258 1272915272\n6 China       2000 213766 1280428583\n\n\n\n\n\n\n\nSeparar la tabla3 la vuelve ordenada\n\n\n\n\nPor defecto, separate() dividirá una columna donde encuentre un carácter no alfanumérico (esto es, un carácter que no es un número o letra). Por ejemplo, en el siguiente código, separate() divide los valores de tasa donde aparece una barra (/). Si deseas usar un carácter específico para separar una columna, puedes especificarlo en el argumento sep de separate(). Por ejemplo, el código anterior se puede re-escribir del siguiente modo:\n\ntabla3 %&gt;%\n  separate(tasa, into = c(\"casos\", \"poblacion\"), sep = \"/\")\n\n(Formalmente, sep es una expresión regular y aprenderás más sobre esto en el capítulo sobre [cadenas de caracteres].)\nMira atentamente los tipos de columna: notarás que casos y poblacion son columnas de tipo carácter. Este es el comportamiento por defecto en separate(): preserva el tipo de columna. Aquí, sin embargo, no es muy útil, ya que se trata de números. Podemos pedir a separate() que intente convertir a un tipo más adecuado usando convert = TRUE:\n\ntabla3 %&gt;%\n  separate(tasa, into = c(\"casos\", \"poblacion\"), convert = TRUE)\n\n# A tibble: 6 × 4\n  pais        anio  casos  poblacion\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt;\n1 Afganistán  1999    745   19987071\n2 Afganistán  2000   2666   20595360\n3 Brasil      1999  37737  172006362\n4 Brasil      2000  80488  174504898\n5 China       1999 212258 1272915272\n6 China       2000 213766 1280428583\n\n\nTambién puedes pasar un vector de enteros a sep. separate() interpreta los enteros como las posiciones donde dividir. Los valores positivos comienzan en 1 al extremo izquierdo de las cadenas de texto; los valores negativos comienzan en -1 al extremo derecho. Cuando uses enteros para separar cadenas de texto, el largo de sep debe ser uno menos que el número de nombres en into.\nPuedes usar este arreglo para separar los últimos dos dígitos de cada año. Esto deja los datos menos ordenados, pero es útil en otros casos, como se verá más adelante.\n\ntabla3 %&gt;%\n  separate(anio, into = c(\"siglo\", \"anio\"), sep = 2)\n\n# A tibble: 6 × 4\n  pais       siglo anio  tasa             \n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;            \n1 Afganistán 19    99    745/19987071     \n2 Afganistán 20    00    2666/20595360    \n3 Brasil     19    99    37737/172006362  \n4 Brasil     20    00    80488/174504898  \n5 China      19    99    212258/1272915272\n6 China      20    00    213766/1280428583\n\n\n\n\n12.4.2 Unir\nunite() es el inverso de separate(): combina múltiples columnas en una única columna. Necesitarás esta función con mucha menos frecuencia que separate(), pero aún así es una buena herramienta para tener en el bolsillo trasero.\n\n\n\n\n\nUnir la tabla5 la vuelve ordenada\n\n\n\n\nPodemos usar unite() para unir las columnas siglo y anio creadas en el ejemplo anterior. Los datos están guardados en datos::tabla5. unite() toma un data frame, el nombre de la nueva variable a crear y un conjunto de columnas a combinar, las que se especifican siguiendo el estilo de la función dplyr::select():\n\ntabla5 %&gt;%\n  unite(nueva, siglo, anio)\n\n# A tibble: 6 × 3\n  pais       nueva tasa             \n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;            \n1 Afganistán 19_99 745/19987071     \n2 Afganistán 20_00 2666/20595360    \n3 Brasil     19_99 37737/172006362  \n4 Brasil     20_00 80488/174504898  \n5 China      19_99 212258/1272915272\n6 China      20_00 213766/1280428583\n\n\nEn este caso también necesitamos el argumento sep. Por defecto, pondrá un guión bajo (_) entre los valores de las distintas columnas. Si no queremos ningún separador usamos \"\":\n\ntabla5 %&gt;%\n  unite(nueva, siglo, anio, sep = \"\")\n\n# A tibble: 6 × 3\n  pais       nueva tasa             \n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;            \n1 Afganistán 1999  745/19987071     \n2 Afganistán 2000  2666/20595360    \n3 Brasil     1999  37737/172006362  \n4 Brasil     2000  80488/174504898  \n5 China      1999  212258/1272915272\n6 China      2000  213766/1280428583\n\n\n\n\n12.4.3 Ejercicios\n\n¿Qué hacen los argumentos extra y fill en separate()? Experimenta con las diversas opciones a partir de los siguientes datasets de ejemplo.\n\n::: {.cell}\ntibble(x = c(\"a,b,c\", \"d,e,f,g\",   \"h,i,j\")) %&gt;%\n  separate(x, c(\"one\", \"two\",       \"three\"))\n\ntibble(x = c(\"a,b,c\", \"d,e\",   \"f,g,i\")) %&gt;%\n  separate(x, c(\"one\", \"two\",     \"three\"))\n:::\n\nTanto unite() como separate() tienen un argumento remove. ¿Qué es lo que hace? ¿Por qué lo dejarías en FALSE?\nCompara y contrasta separate() y extract(). ¿Por qué existen tres variaciones de separación (por posición, separador y grupos), pero solo una forma de unir?"
  },
  {
    "objectID": "12-tidy.html#valores-faltantes",
    "href": "12-tidy.html#valores-faltantes",
    "title": "12  Datos ordenados",
    "section": "12.5 Valores faltantes",
    "text": "12.5 Valores faltantes\nCambiar la representación de un dataset conlleva el riesgo de generar valores faltantes. Sorprendentemente, un valor puede perderse de dos formas:\n\nExplícita, esto es, aparece como NA.\nImplícita, esto es, simplemente no aparece en los datos.\n\nIlustremos esta idea con un dataset muy sencillo:\n\nacciones &lt;- tibble(\n  anio = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),\n  trimestre = c(1, 2, 3, 4, 2, 3, 4),\n  retorno = c(1.88, 0.59, 0.35, NA, 0.92, 0.17, 2.66)\n)\n\nExisten dos valores faltantes en este dataset:\n\nEl retorno del cuarto trimestre de 2015 que está explícitamente perdido, debido a que la celda donde el valor debiera estar contiene NA.\nEl retorno del primer semestre de 2016 está implícitamente perdido, debido a que simplemente no aparece en el set de datos.\n\nUna forma de pensar respecto de esta diferencia es al estilo de un kōan Zen: Un valor faltante explícito es la presencia de una ausencia; un valor faltante implícito es la ausencia de una presencia.\nLa forma en que se representa un dataset puede dejar explícitos los valores implícitos. Por ejemplo, podemos volver explícitos los valores faltantes implícitos al mover los años a las columnas:\n\nacciones %&gt;%\n  spread(anio, retorno)\n\n# A tibble: 4 × 3\n  trimestre `2015` `2016`\n      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1         1   1.88  NA   \n2         2   0.59   0.92\n3         3   0.35   0.17\n4         4  NA      2.66\n\n\nDebido a que estos valores faltantes explícitos pueden no ser tan importantes en otras representaciones de los datos, puedes especificar na.rm = TRUE en gather() para dejar explícitos los valores faltantes implícitos:\n\nacciones %&gt;%\n  pivot_wider(names_from = anio, values_from = retorno) %&gt;% \n  pivot_longer(\n    cols = c(`2015`, `2016`), \n    names_to = \"anio\", \n    values_to = \"retorno\", \n    values_drop_na = TRUE\n  )\n\n# A tibble: 6 × 3\n  trimestre anio  retorno\n      &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1         1 2015     1.88\n2         2 2015     0.59\n3         2 2016     0.92\n4         3 2015     0.35\n5         3 2016     0.17\n6         4 2016     2.66\n\n\nOtra herramienta importante para hacer explícitos los valores faltantes en datos ordenados es complete():\n\nacciones %&gt;%\n  complete(anio, trimestre)\n\n# A tibble: 8 × 3\n   anio trimestre retorno\n  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1  2015         1    1.88\n2  2015         2    0.59\n3  2015         3    0.35\n4  2015         4   NA   \n5  2016         1   NA   \n6  2016         2    0.92\n7  2016         3    0.17\n8  2016         4    2.66\n\n\ncomplete() toma un conjunto de columnas y encuentra todas las combinaciones únicas. Luego se asegura de que el dataset original contenga todos los valores, completando con NAs donde sea necesario.\nExiste otra herramienta importante que deberías conocer al momento de trabajar con valores faltantes. En algunos casos en que la fuente de datos se ha usado principalmente para ingresar datos, los valores faltantes indican que el valor previo debe arrastrarse hacia adelante:\n\ntratamiento &lt;- tribble(\n  ~sujeto, ~tratamiento, ~respuesta,\n  \"Derrick Whitmore\", 1, 7,\n  NA, 2, 10,\n  NA, 3, 9,\n  \"Katherine Burke\", 1, 4\n)\n\nPuedes completar los valores faltantes usando fill(). Esta función toma un conjunto de columnas sobre las cuales los valores faltantes son reemplazados por el valor anterior más cercano que se haya reportado (también conocido como el método LOCF, del inglés last observation carried forward).\n\ntratamiento %&gt;%\n  fill(sujeto)\n\n# A tibble: 4 × 3\n  sujeto           tratamiento respuesta\n  &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;\n1 Derrick Whitmore           1         7\n2 Derrick Whitmore           2        10\n3 Derrick Whitmore           3         9\n4 Katherine Burke            1         4\n\n\n\n12.5.1 Ejercicios\n\nCompara y contrasta el argumento fill que se usa en pivot_wider() con complete().\n¿Qué hace el argumento de dirección en fill()?"
  },
  {
    "objectID": "12-tidy.html#estudio-de-caso",
    "href": "12-tidy.html#estudio-de-caso",
    "title": "12  Datos ordenados",
    "section": "12.6 Estudio de caso",
    "text": "12.6 Estudio de caso\nPara finalizar el capítulo, combinemos todo lo que aprendiste para enfrentar un problema real de ordenamiento de datos. El dataset datos::oms contiene datos de tuberculosis (TB) detallados por año, país, edad, sexo y método de diagnóstico. Los datos provienen del Informe de Tuberculosis de la Organización Mundial de la Salud 2014, disponible en http://www.who.int/tb/country/data/download/en/.\nExiste abundante información epidemiológica en este dataset, pero es complicado trabajar con estos datos tal como son entregados:\n\noms\n\n# A tibble: 7,240 × 60\n   pais      iso2  iso3   anio nuevos_fpp_h014 nuevos_fpp_h1524 nuevos_fpp_h2534\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n 1 Afganist… AF    AFG    1980              NA               NA               NA\n 2 Afganist… AF    AFG    1981              NA               NA               NA\n 3 Afganist… AF    AFG    1982              NA               NA               NA\n 4 Afganist… AF    AFG    1983              NA               NA               NA\n 5 Afganist… AF    AFG    1984              NA               NA               NA\n 6 Afganist… AF    AFG    1985              NA               NA               NA\n 7 Afganist… AF    AFG    1986              NA               NA               NA\n 8 Afganist… AF    AFG    1987              NA               NA               NA\n 9 Afganist… AF    AFG    1988              NA               NA               NA\n10 Afganist… AF    AFG    1989              NA               NA               NA\n# ℹ 7,230 more rows\n# ℹ 53 more variables: nuevos_fpp_h3544 &lt;dbl&gt;, nuevos_fpp_h4554 &lt;dbl&gt;,\n#   nuevos_fpp_h5564 &lt;dbl&gt;, nuevos_fpp_h65 &lt;dbl&gt;, nuevos_fpp_m014 &lt;dbl&gt;,\n#   nuevos_fpp_m1524 &lt;dbl&gt;, nuevos_fpp_m2534 &lt;dbl&gt;, nuevos_fpp_m3544 &lt;dbl&gt;,\n#   nuevos_fpp_m4554 &lt;dbl&gt;, nuevos_fpp_m5564 &lt;dbl&gt;, nuevos_fpp_m65 &lt;dbl&gt;,\n#   nuevos_fpn_h014 &lt;dbl&gt;, nuevos_fpn_h1524 &lt;dbl&gt;, nuevos_fpn_h2534 &lt;dbl&gt;,\n#   nuevos_fpn_h3544 &lt;dbl&gt;, nuevos_fpn_h4554 &lt;dbl&gt;, nuevos_fpn_h5564 &lt;dbl&gt;, …\n\n\nEste es un ejemplo muy típico de un dataset de la vida real. Contiene columnas redundantes, códigos extraños de variables y muchos valores faltantes. En breve, oms está desordenado y necesitamos varios pasos para ordenarlo. Al igual que dplyr, tidyr está diseñado de modo tal que cada función hace bien una cosa. Esto significa que en una situación real deberás encadenar múltiples verbos.\nLCasi siempre, la mejor forma de comenzar es reunir las columnas que no representan variables. Miremos lo que hay:\n\nPareciera ser que pais, iso2 e iso3 son variables redundantes que se refieren al país.\nanio es claramente una variable.\nNo sabemos aún el significado de las otras columnas, pero dada la estructura de los nombres de las variables (e.g. nuevos_fpp_h014, nuevos_ep_h014, nuevos_ep_m014) parecieran ser valores y no variables.\n\nNecesitamos agrupar todas las columnas desde nuevos_fpp_h014 hasta recaidas_m65. No sabemos aún qué representa esto, por lo que le daremos el nombre genérico de \"clave\". Sabemos que las celdas representan la cuenta de casos, por lo que usaremos la variable casos.\nExisten múltiples valores faltantes en la representación actual, por lo que de momento usaremos na.rm para centrarnos en los valores que están presentes.\n\noms1 &lt;- oms %&gt;%\n  pivot_longer(\n    cols = nuevos_fpp_h014:nuevosrecaida_m65, \n    names_to = \"clave\", \n    values_to = \"casos\", \n    values_drop_na = TRUE\n  )\noms1\n\n# A tibble: 76,046 × 6\n   pais       iso2  iso3   anio clave            casos\n   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n 1 Afganistán AF    AFG    1997 nuevos_fpp_h014      0\n 2 Afganistán AF    AFG    1997 nuevos_fpp_h1524    10\n 3 Afganistán AF    AFG    1997 nuevos_fpp_h2534     6\n 4 Afganistán AF    AFG    1997 nuevos_fpp_h3544     3\n 5 Afganistán AF    AFG    1997 nuevos_fpp_h4554     5\n 6 Afganistán AF    AFG    1997 nuevos_fpp_h5564     2\n 7 Afganistán AF    AFG    1997 nuevos_fpp_h65       0\n 8 Afganistán AF    AFG    1997 nuevos_fpp_m014      5\n 9 Afganistán AF    AFG    1997 nuevos_fpp_m1524    38\n10 Afganistán AF    AFG    1997 nuevos_fpp_m2534    36\n# ℹ 76,036 more rows\n\n\nPodemos tener una noción de la estructura de los valores en la nueva columna clave si hacemos un conteo:\n\noms1 %&gt;%\n  count(clave)\n\n# A tibble: 56 × 2\n   clave               n\n   &lt;chr&gt;           &lt;int&gt;\n 1 nuevos_ep_h014   1038\n 2 nuevos_ep_h1524  1026\n 3 nuevos_ep_h2534  1020\n 4 nuevos_ep_h3544  1024\n 5 nuevos_ep_h4554  1020\n 6 nuevos_ep_h5564  1015\n 7 nuevos_ep_h65    1018\n 8 nuevos_ep_m014   1032\n 9 nuevos_ep_m1524  1021\n10 nuevos_ep_m2534  1021\n# ℹ 46 more rows\n\n\nPodrías resolver esto por tu cuenta pensando y experimentando un poco, pero afortunadamente tenemos el diccionario de datos a mano. Este nos dice lo siguiente:\n\nLo que aparece antes del primer _ en las columnas indica si la columna contiene casos nuevos o antiguos de tuberculosis. En este dataset, cada columna contiene nuevos casos.\nLo que aparece luego de indicar si se refiere casos nuevos o antiguos es el tipo de tuberculosis:\n\n\nrecaida se refiere a casos reincidentes\nep se refiere a tuberculosis extra pulmonar\nfpn se refiere a casos de tuberculosis pulmonar que no se pueden detectar mediante examen de frotis pulmonar (frotis pulmonar negativo)\nfpp se refiere a casos de tuberculosis pulmonar que se pueden detectar mediante examen de frotis pulmonar (frotis pulmonar positivo)\n\n\nLa letra que aparece después del último _ se refiere al sexo de los pacientes. El conjunto de datos agrupa en hombres (h) y mujeres (m).\nLos números finales se refieren al grupo etareo que se ha organizado en siete categorías:\n\n\n014 = 0 – 14 años de edad\n1524 = 15 – 24 años de edad\n2534 = 25 – 34 años de edad\n3544 = 35 – 44 años de edad\n4554 = 45 – 54 años de edad\n5564 = 55 – 64 años de edad\n65 = 65 o más años de edad\n\nNecesitamos hacer un pequeño cambio al formato de los nombres de las columnas: desafortunadamente lo nombres de las columnas son ligeramente inconsistentes debido a que en lugar de nuevos_recaida tenemos nuevosrecaida (es difícil darse cuenta de esto en esta parte, pero si no lo arreglas habrá errores en los pasos siguientes). Aprenderás sobre str_replace() en [cadenas de caracteres], pero la idea básica es bastante simple: reemplazar los caracteres “nuevosrecaida” por “nuevos_recaida”. Esto genera nombres de variables consistentes.\n\noms2 &lt;- oms1 %&gt;%\n  mutate(clave = stringr::str_replace(clave, \"nuevosrecaida\", \"nuevos_recaida\"))\noms2\n\n# A tibble: 76,046 × 6\n   pais       iso2  iso3   anio clave            casos\n   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n 1 Afganistán AF    AFG    1997 nuevos_fpp_h014      0\n 2 Afganistán AF    AFG    1997 nuevos_fpp_h1524    10\n 3 Afganistán AF    AFG    1997 nuevos_fpp_h2534     6\n 4 Afganistán AF    AFG    1997 nuevos_fpp_h3544     3\n 5 Afganistán AF    AFG    1997 nuevos_fpp_h4554     5\n 6 Afganistán AF    AFG    1997 nuevos_fpp_h5564     2\n 7 Afganistán AF    AFG    1997 nuevos_fpp_h65       0\n 8 Afganistán AF    AFG    1997 nuevos_fpp_m014      5\n 9 Afganistán AF    AFG    1997 nuevos_fpp_m1524    38\n10 Afganistán AF    AFG    1997 nuevos_fpp_m2534    36\n# ℹ 76,036 more rows\n\n\nPodemos separar los valores en cada código aplicando separate() dos veces. La primera aplicación dividirá los códigos en cada _.\n\noms3 &lt;- oms2 %&gt;%\n  separate(clave, c(\"nuevos\", \"tipo\", \"sexo_edad\"), sep = \"_\")\noms3\n\n# A tibble: 76,046 × 8\n   pais       iso2  iso3   anio nuevos tipo  sexo_edad casos\n   &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 Afganistán AF    AFG    1997 nuevos fpp   h014          0\n 2 Afganistán AF    AFG    1997 nuevos fpp   h1524        10\n 3 Afganistán AF    AFG    1997 nuevos fpp   h2534         6\n 4 Afganistán AF    AFG    1997 nuevos fpp   h3544         3\n 5 Afganistán AF    AFG    1997 nuevos fpp   h4554         5\n 6 Afganistán AF    AFG    1997 nuevos fpp   h5564         2\n 7 Afganistán AF    AFG    1997 nuevos fpp   h65           0\n 8 Afganistán AF    AFG    1997 nuevos fpp   m014          5\n 9 Afganistán AF    AFG    1997 nuevos fpp   m1524        38\n10 Afganistán AF    AFG    1997 nuevos fpp   m2534        36\n# ℹ 76,036 more rows\n\n\nA continuación podemos eliminar la columna nuevos, ya que es constante en este dataset. Además eliminaremos iso2 e iso3 ya que son redundantes.\n\noms3 %&gt;%\n  count(nuevos)\n\n# A tibble: 1 × 2\n  nuevos     n\n  &lt;chr&gt;  &lt;int&gt;\n1 nuevos 76046\n\noms4 &lt;- oms3 %&gt;%\n  select(-nuevos, -iso2, -iso3)\n\nLuego separamos sexo_edad en sexo y edad dividiendo luego del primer carácter:\n\noms5 &lt;- oms4 %&gt;%\n  separate(sexo_edad, c(\"sexo\", \"edad\"), sep = 1)\noms5\n\n# A tibble: 76,046 × 6\n   pais        anio tipo  sexo  edad  casos\n   &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 Afganistán  1997 fpp   h     014       0\n 2 Afganistán  1997 fpp   h     1524     10\n 3 Afganistán  1997 fpp   h     2534      6\n 4 Afganistán  1997 fpp   h     3544      3\n 5 Afganistán  1997 fpp   h     4554      5\n 6 Afganistán  1997 fpp   h     5564      2\n 7 Afganistán  1997 fpp   h     65        0\n 8 Afganistán  1997 fpp   m     014       5\n 9 Afganistán  1997 fpp   m     1524     38\n10 Afganistán  1997 fpp   m     2534     36\n# ℹ 76,036 more rows\n\n\n¡Ahora el dataset oms está ordenado!\nHemos mostrado el código parte por parte, asignando los resultados intermedios a nuevas variables. Esta no es la forma típica de trabajo. En cambio, lo que se hace es formar incrementalmente un encadenamiento complejo usando pipes:\n\noms %&gt;%\n  pivot_longer(\n    cols = nuevos_fpp_h014:nuevosrecaida_m65,\n    names_to = \"clave\", \n    values_to = \"valor\", \n    values_drop_na = TRUE) %&gt;%\n  mutate(clave = stringr::str_replace(clave, \"nuevosrecaida\", \"nuevos_recaida\")) %&gt;%\n  separate(clave, c(\"nuevos\", \"tipo\", \"sexo_edad\")) %&gt;%\n  select(-nuevos, -iso2, -iso3) %&gt;%\n  separate(sexo_edad, c(\"sexo\", \"edad\"), sep = 1)\n\n\n12.6.1 Ejercicios\n\nEn este caso de estudio fijamos values_drop_na = TRUE para hacer más simple el verificar que tenemos los valores correctos. ¿Es esto razonable? Piensa en cómo los valores faltantes están representados en este dataset. ¿Existen valores faltantes implícitos? ¿Cuál es la diferencia entre NA y cero?\n¿Qué ocurre si omites la aplicación de mutate()? (mutate(clave = stringr::str_replace(clave, \"nuevosrecaida\", \"nuevos_recaida\")))\nAfirmamos que iso2 e iso3 son redundantes respecto a pais. Confirma esta aseveración.\nPara cada país, año y sexo calcula el total del número de casos de tuberculosis. Crea una visualización informativa de los datos."
  },
  {
    "objectID": "12-tidy.html#datos-no-ordenados",
    "href": "12-tidy.html#datos-no-ordenados",
    "title": "12  Datos ordenados",
    "section": "12.7 Datos no ordenados",
    "text": "12.7 Datos no ordenados\nAntes de pasar a otros tópicos, es conveniente referirse brevemente a datos no ordenados. Anteriormente en el capítulo, usamos el término peyorativo “desordenados” para referirnos a datos no ordenados. Esto es una sobresimplificación: existen múltiples estructuras de datos debidamente fundamentadas que no corresponden a datos ordenados. Existen dos principales razones para usar otras estructuras de datos:\n\nLas representaciones alternativas pueden traer ventajas importantes en términos de desempeño o tamaño.\nAlgunas áreas especializadas han evolucionado y tienen sus propias convenciones para almacenar datos, las que pueden diferir respecto de las convenciones de datos ordenados.\n\nCada uno de estas razones significa que necesitarás algo distinto a un tibble (o data frame). Si tus datos naturalmente se ajustan a una estructura rectangular compuesta de observaciones y variables, pensamos que datos ordenados debería ser tu elección por defecto. Sin embargo, existen buenas razones para usar otras estructuras; los datos ordenados no son la única forma.\nSi quieres aprender más acerca de datos no ordenados, recomendamos fuertemente este artículo del blog de Jeff Leek: http://simplystatistics.org/2016/02/17/non-tidy-data/"
  },
  {
    "objectID": "13-relational-data.html#introducción",
    "href": "13-relational-data.html#introducción",
    "title": "13  Datos relacionales",
    "section": "13.1 Introducción",
    "text": "13.1 Introducción\nEs raro que un análisis de datos involucre una única tabla de datos. Lo típico es que tengas muchas tablas que debes combinar para responder a tus preguntas de interés. De manera colectiva, se le llama datos relacionales a esas múltiples tablas de datos, ya que sus relaciones, y no solo los conjuntos de datos individuales, son importantes.\nLas relaciones siempre se definen sobre un par de tablas. Todas las otras relaciones se construyen sobre esta idea simple: las relaciones entre tres o más tablas son siempre una propiedad de las relaciones entre cada par. ¡A veces ambos elementos de un par pueden ser la misma tabla! Esto se necesita si, por ejemplo, tienes una tabla de personas y cada persona tiene una referencia a sus padres.\nPara trabajar con datos relacionales necesitas verbos que funcionen con pares de tablas. Existen tres familias de verbos diseñadas para trabajar con datos relacionales:\n\nUniones de transformación (del inglés mutating joins), que agregan nuevas variables a un data frame a partir de las observaciones coincidentes en otra tabla.\nUniones de filtro (del inglés filtering joins), que filtran observaciones en un data frame con base en si coinciden o no con una observación de otra tabla.\nOperaciones de conjuntos (del inglés set operations), que tratan las observaciones como elementos de un conjunto.\n\nEl lugar más común para encontrar datos relacionales es en un sistema relacional de administración de bases de datos (Relational Data Base Management System en inglés), un concepto que abarca casi todas las bases de datos modernas. Si has usado una base de datos con anterioridad, casi seguramente fue SQL. Si es así, los conceptos de este capítulo debiesen ser familiares, aunque su expresión en dplyr es un poco distinta. En términos generales, dplyr es un poco más fácil de usar que SQLes, ya que dplyr se especializa en el análisis de datos: facilita las operaciones habituales, a expensas de dificultar otras que no se requieren a menudo para el análisis de datos.\n\n13.1.1 Prerrequisitos\nVamos a explorar datos relacionales contenidos en el paquete datos usando los verbos para dos tablas de dplyr.\n\nlibrary(tidyverse)\nlibrary(datos)"
  },
  {
    "objectID": "13-relational-data.html#nycflights13-relational",
    "href": "13-relational-data.html#nycflights13-relational",
    "title": "13  Datos relacionales",
    "section": "13.2 Datos sobre vuelos",
    "text": "13.2 Datos sobre vuelos\nUsaremos datos sobre vuelos desde y hacia Nueva York para aprender sobre datos relacionales1. El paquete datos contiene cinco tibbles que utilizaremos para este propósito: aerolineas, aeropuertos, aviones y clima, que se relacionan con la tabla vuelos (que se usó en el capítulo sobre [transformación de datos]):\n\naerolineas permite observar el nombre completo de la aerolínea a partir de su código abreviado:\n\n::: {.cell}\naerolineas\n::: {.cell-output .cell-output-stdout} # A tibble: 16 × 2     aerolinea nombre                          &lt;chr&gt;     &lt;chr&gt;                         1 9E        Endeavor Air Inc.             2 AA        American Airlines Inc.        3 AS        Alaska Airlines Inc.          4 B6        JetBlue Airways               5 DL        Delta Air Lines Inc.          6 EV        ExpressJet Airlines Inc.      7 F9        Frontier Airlines Inc.        8 FL        AirTran Airways Corporation   9 HA        Hawaiian Airlines Inc.       10 MQ        Envoy Air                    11 OO        SkyWest Airlines Inc.        12 UA        United Air Lines Inc.        13 US        US Airways Inc.              14 VX        Virgin America               15 WN        Southwest Airlines Co.       16 YV        Mesa Airlines Inc. ::: :::\n\naeropuertos entrega información de cada aeropuerto, identificado por su código:\n\n::: {.cell}\naeropuertos\n::: {.cell-output .cell-output-stdout} # A tibble: 1,458 × 8     codigo_aeropuerto nombre  latitud longitud altura zona_horaria horario_verano     &lt;chr&gt;             &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;            1 04G               Lansdo…    41.1    -80.6   1044           -5 A                2 06A               Moton …    32.5    -85.7    264           -6 A                3 06C               Schaum…    42.0    -88.1    801           -6 A                4 06N               Randal…    41.4    -74.4    523           -5 A                5 09J               Jekyll…    31.1    -81.4     11           -5 A                6 0A9               Elizab…    36.4    -82.2   1593           -5 A                7 0G6               Willia…    41.5    -84.5    730           -5 A                8 0G7               Finger…    42.9    -76.8    492           -5 A                9 0P2               Shoest…    39.8    -76.6   1000           -5 U               10 0S9               Jeffer…    48.1   -123.     108           -8 A               # ℹ 1,448 more rows  # ℹ 1 more variable: zona_horaria_iana &lt;chr&gt; ::: :::\n\naviones entrega información de cada avión, identificado por su codigo_cola:\n\n::: {.cell}\naviones\n::: {.cell-output .cell-output-stdout} # A tibble: 3,322 × 9     codigo_cola  anio tipo           fabricante modelo motores asientos velocidad     &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;    &lt;int&gt;    &lt;int&gt;     &lt;int&gt;   1 N10156       2004 Ala fija mult… EMBRAER    EMB-1…       2       55        NA   2 N102UW       1998 Ala fija mult… AIRBUS IN… A320-…       2      182        NA   3 N103US       1999 Ala fija mult… AIRBUS IN… A320-…       2      182        NA   4 N104UW       1999 Ala fija mult… AIRBUS IN… A320-…       2      182        NA   5 N10575       2002 Ala fija mult… EMBRAER    EMB-1…       2       55        NA   6 N105UW       1999 Ala fija mult… AIRBUS IN… A320-…       2      182        NA   7 N107US       1999 Ala fija mult… AIRBUS IN… A320-…       2      182        NA   8 N108UW       1999 Ala fija mult… AIRBUS IN… A320-…       2      182        NA   9 N109UW       1999 Ala fija mult… AIRBUS IN… A320-…       2      182        NA  10 N110UW       1999 Ala fija mult… AIRBUS IN… A320-…       2      182        NA  # ℹ 3,312 more rows  # ℹ 1 more variable: tipo_motor &lt;chr&gt; ::: :::\n\nclima entrega información del clima en cada aeropuerto de Nueva York para cada hora:\n\n::: {.cell}\nclima\n::: {.cell-output .cell-output-stdout} # A tibble: 26,115 × 15     origen  anio   mes   dia  hora temperatura punto_rocio humedad     &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;   1 EWR     2013     1     1     1        39.0        26.1    59.4   2 EWR     2013     1     1     2        39.0        27.0    61.6   3 EWR     2013     1     1     3        39.0        28.0    64.4   4 EWR     2013     1     1     4        39.9        28.0    62.2   5 EWR     2013     1     1     5        39.0        28.0    64.4   6 EWR     2013     1     1     6        37.9        28.0    67.2   7 EWR     2013     1     1     7        39.0        28.0    64.4   8 EWR     2013     1     1     8        39.9        28.0    62.2   9 EWR     2013     1     1     9        39.9        28.0    62.2  10 EWR     2013     1     1    10        41          28.0    59.6  # ℹ 26,105 more rows  # ℹ 7 more variables: direccion_viento &lt;dbl&gt;, velocidad_viento &lt;dbl&gt;,  #   velocidad_rafaga &lt;dbl&gt;, precipitacion &lt;dbl&gt;, presion &lt;dbl&gt;,  #   visibilidad &lt;dbl&gt;, fecha_hora &lt;dttm&gt; ::: :::\nUna forma de mostrar las relaciones entre las diferentes tablas es mediante un diagrama:\n\n\n\n\n\nEste diagrama es un poco abrumador, ¡pero es simple comparado con algunos que verás en el exterior! La clave para entender estos diagramas es recordar que cada relación siempre involucra un par de tablas. No necesitas entender todo el diagrama, necesitas entender la cadena de relaciones entre las tablas que te interesan.\nEn estos datos:\n\nvuelos se connecta con aviones a través de la variable codigo_cola.\nvuelos se conecta con aerolineas a través de la variable codigo_carrier.\nvuelos se conecta con aeropuertos de dos formas: a través de las variables origen y destino.\nvuelos se conecta con clima a través de las variables origen (la ubicación), anio, mes, dia y hora (el horario).\n\n\n13.2.1 Ejercicios\n\nImagina que necesitas dibujar (aproximadamente) la ruta que cada avión vuela desde su origen hasta el destino. ¿Qué variables necesitarías? ¿Qué tablas necesitarías combinar?\nOlvidamos dibujar la relación entre clima y aeropuertos. ¿Cuál es la relación y cómo debería aparecer en el diagrama?\nclima únicamente contiene información de los aeropuertos de origen (Nueva York). Si incluyera registros para todos los aeropuertos de EEUU, ¿qué relación tendría con vuelos?\nSabemos que hay días “especiales” en el año y pocas personas suelen volar en ellos. ¿Cómo se representarían en un data frame? ¿Cuáles serían las claves primarias de esa tabla? ¿Cómo se conectaría con las tablas existentes?"
  },
  {
    "objectID": "13-relational-data.html#claves",
    "href": "13-relational-data.html#claves",
    "title": "13  Datos relacionales",
    "section": "13.3 Claves",
    "text": "13.3 Claves\nLas variables usadas para conectar cada par de variables se llaman claves (del inglés key). Una clave es una variable (o un conjunto de variables) que identifican de manera única una observación. En casos simples, una sola variable es suficiente para identificar una observación. Por ejemplo, cada avión está identificado de forma única por su codigo_cola. En otros casos, se pueden necesitar múltiples variables. Por ejemplo, para identificar una observación en clima se necesitan cinco variables: anio, mes, dia, hora y origen.\nExisten dos tipos de claves:\n\nUna clave primaria identifica únicamente una observación en su propia tabla. Por ejemplo, aviones$codigo_cola es una clave primaria, ya que identifica de manera única cada avión en la tabla aviones.\nUna clave foránea únicamente identifica una observación en otra tabla. Por ejemplo, vuelos$codigo_cola es una clave foránea, ya que aparece en la tabla vuelos, en la que une cada vuelo con un único avión.\n\nUna variable puede ser clave primaria y clave foránea a la vez. Por ejemplo, origen es parte de la clave primaria clima y también una clave foránea de aeropuertos.\nUna vez que identificas las claves primarias en tus tablas, es una buena práctica verificar que identifican de forma única cada observación. Una forma de hacerlo es usar count() con las claves primarias y buscar las entradas con n mayor a uno:\n\naviones %&gt;%\n  count(codigo_cola) %&gt;%\n  filter(n &gt; 1)\n\n# A tibble: 0 × 2\n# ℹ 2 variables: codigo_cola &lt;chr&gt;, n &lt;int&gt;\n\nclima %&gt;%\n  count(anio, mes, dia, hora, origen) %&gt;%\n  filter(n &gt; 1)\n\n# A tibble: 3 × 6\n   anio   mes   dia  hora origen     n\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;  &lt;int&gt;\n1  2013    11     3     1 EWR        2\n2  2013    11     3     1 JFK        2\n3  2013    11     3     1 LGA        2\n\n\nA veces una tabla puede no tener una clave primaria explícita: cada fila es una observación, pero no existe una combinación de variables que la identifique de forma confiable. Por ejemplo, ¿cuál es la clave primaria en la tabla vuelos? Quizás pienses que podría ser la fecha más el vuelo o el código de cola, pero ninguna de esas variables es única:\n\nvuelos %&gt;%\n  count(anio, mes, dia, vuelo) %&gt;%\n  filter(n &gt; 1)\n\n# A tibble: 29,768 × 5\n    anio   mes   dia vuelo     n\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     1     1     2\n 2  2013     1     1     3     2\n 3  2013     1     1     4     2\n 4  2013     1     1    11     3\n 5  2013     1     1    15     2\n 6  2013     1     1    21     2\n 7  2013     1     1    27     4\n 8  2013     1     1    31     2\n 9  2013     1     1    32     2\n10  2013     1     1    35     2\n# ℹ 29,758 more rows\n\nvuelos %&gt;%\n  count(anio, mes, dia, codigo_cola) %&gt;%\n  filter(n &gt; 1)\n\n# A tibble: 64,928 × 5\n    anio   mes   dia codigo_cola     n\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;int&gt;\n 1  2013     1     1 N0EGMQ          2\n 2  2013     1     1 N11189          2\n 3  2013     1     1 N11536          2\n 4  2013     1     1 N11544          3\n 5  2013     1     1 N11551          2\n 6  2013     1     1 N12540          2\n 7  2013     1     1 N12567          2\n 8  2013     1     1 N13123          2\n 9  2013     1     1 N13538          3\n10  2013     1     1 N13566          3\n# ℹ 64,918 more rows\n\n\nAl comenzar a trabajar con estos datos, ingenuamente asumimos que cada número de vuelo sería usado solo una vez al día: eso haría mucho más simple comunicar problemas con un vuelo específico. ¡Desafortunadamente este no es el caso! Si una tabla no tiene una clave primaria, a veces es útil incluir una con mutate() y row_number() (número de fila). Eso simplifica hacer coincidir observaciones una vez que haz hecho algunos filtros y quieres volver a verificar con los datos originales. Esto se llama clave subrogada.\nUna clave primaria y su correspondiente clave foránea en otra tabla forman una relación. Las relaciones son típicamente uno-a-muchos. Por ejemplo, cada vuelo tiene un avión, pero cada avión tiene muchos vuelos. En otros datos, ocasionalmente verás relaciones uno-a-uno. Puedes pensar esto como un caso especial de uno-a-muchos. Puedes modelar relaciones muchos-a-muchos como relaciones de la forma muchos-a-uno y uno-a-muchos. Por ejemplo, en estos datos existe una relación muchos-a-muchos entre aerolíneas y aeropuertos: cada aerolínea vuela a muchos aeropuertos, cada aeropuerto recibe a muchas aerolíneas.\n\n13.3.1 Ejercicios\n\nAgrega una clave subrogada a vuelos.\nIdentifica las claves en los siguientes conjuntos de datos\ndatos::bateadores\ndatos::nombres\ndatos::atmosfera\ndatos::vehiculos\ndatos::diamantes\n\n(Puede que necesites leer un poco de documentación.)\n\nDibuja un diagrama que ilustre las conexiones entre las tablas bateadores, personas y salarios incluidas en el paquete datos. Dibuja otro diagrama que muestre la relación entre personas, dirigentes y premios_dirigentes.\n¿Cómo caracterizarías las relación entre bateadores, lanzadores y jardineros?"
  },
  {
    "objectID": "13-relational-data.html#mutating-joins",
    "href": "13-relational-data.html#mutating-joins",
    "title": "13  Datos relacionales",
    "section": "13.4 Uniones de transformación",
    "text": "13.4 Uniones de transformación\nLa primera herramienta que miraremos para combinar pares de variables es la unión de transformación (mutating join). Una unión de transformación te permite combinar variables a partir de dos tablas. Primero busca coincidencias de observaciones de acuerdo a sus claves y luego copia las variables de una tabla en la otra.\nTal como mutate(), las funciones de unión agregan variables hacia la derecha, por lo que si tienes muchas variables inicialmente, las nuevas variables no se imprimirán. Para estos ejemplos, crearemos un conjunto de datos más angosto para que sea más fácil ver qué es lo que está ocurriendo:\n\nvuelos2 &lt;- vuelos %&gt;%\n  select(anio:dia, hora, origen, destino, codigo_cola, aerolinea)\nvuelos2\n\n# A tibble: 336,776 × 8\n    anio   mes   dia  hora origen destino codigo_cola aerolinea\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;    \n 1  2013     1     1     5 EWR    IAH     N14228      UA       \n 2  2013     1     1     5 LGA    IAH     N24211      UA       \n 3  2013     1     1     5 JFK    MIA     N619AA      AA       \n 4  2013     1     1     5 JFK    BQN     N804JB      B6       \n 5  2013     1     1     6 LGA    ATL     N668DN      DL       \n 6  2013     1     1     5 EWR    ORD     N39463      UA       \n 7  2013     1     1     6 EWR    FLL     N516JB      B6       \n 8  2013     1     1     6 LGA    IAD     N829AS      EV       \n 9  2013     1     1     6 JFK    MCO     N593JB      B6       \n10  2013     1     1     6 LGA    ORD     N3ALAA      AA       \n# ℹ 336,766 more rows\n\n\n(Recuerda que en RStudio puedes también usar View() para evitar este problema.)\nImagina que quieres incluir el nombre completo de la aerolínea en vuelos2. Puedes combinar los datos de aerolinas y vuelos2 con left_join() (union_izquierda):\n\nvuelos2 %&gt;%\n  select(-origen, -destino) %&gt;%\n  left_join(aerolineas, by = \"aerolinea\")\n\n# A tibble: 336,776 × 7\n    anio   mes   dia  hora codigo_cola aerolinea nombre                  \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;                   \n 1  2013     1     1     5 N14228      UA        United Air Lines Inc.   \n 2  2013     1     1     5 N24211      UA        United Air Lines Inc.   \n 3  2013     1     1     5 N619AA      AA        American Airlines Inc.  \n 4  2013     1     1     5 N804JB      B6        JetBlue Airways         \n 5  2013     1     1     6 N668DN      DL        Delta Air Lines Inc.    \n 6  2013     1     1     5 N39463      UA        United Air Lines Inc.   \n 7  2013     1     1     6 N516JB      B6        JetBlue Airways         \n 8  2013     1     1     6 N829AS      EV        ExpressJet Airlines Inc.\n 9  2013     1     1     6 N593JB      B6        JetBlue Airways         \n10  2013     1     1     6 N3ALAA      AA        American Airlines Inc.  \n# ℹ 336,766 more rows\n\n\nEl resultado de unir aerolineas y vuelos2 es la inclusión de una variable adicional: nombre. Esta es la razón de que llamemos unión de transformación a este tipo de unión. En este caso, podrías obtener el mismo resultado usando mutate() junto a las operaciones de filtro de R base:\n\nvuelos2 %&gt;%\n  select(-origen, -destino) %&gt;%\n  mutate(nombre = aerolineas$nombre[match(aerolinea, aerolineas$aerolinea)])\n\n# A tibble: 336,776 × 7\n    anio   mes   dia  hora codigo_cola aerolinea nombre                  \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;                   \n 1  2013     1     1     5 N14228      UA        United Air Lines Inc.   \n 2  2013     1     1     5 N24211      UA        United Air Lines Inc.   \n 3  2013     1     1     5 N619AA      AA        American Airlines Inc.  \n 4  2013     1     1     5 N804JB      B6        JetBlue Airways         \n 5  2013     1     1     6 N668DN      DL        Delta Air Lines Inc.    \n 6  2013     1     1     5 N39463      UA        United Air Lines Inc.   \n 7  2013     1     1     6 N516JB      B6        JetBlue Airways         \n 8  2013     1     1     6 N829AS      EV        ExpressJet Airlines Inc.\n 9  2013     1     1     6 N593JB      B6        JetBlue Airways         \n10  2013     1     1     6 N3ALAA      AA        American Airlines Inc.  \n# ℹ 336,766 more rows\n\n\nSin embargo, esto último es difícil de generalizar cuando necesitas hacer coincidir múltiples variables y requiere hacer una lectura detenida para entender lo que se quiere hacer.\nEn las siguientes secciones explicaremos en detalle cómo funcionan las uniones de transformación. Comenzarás aprendiendo una representación visual útil de las uniones. Luego usaremos eso para explicar las cuatro uniones de transformación: la unión interior y las tres uniones exteriores. Cuando trabajas con datos reales, las claves no siempre identifican a las observaciones de forma única. Es por eso que a continuación hablaremos de lo que ocurre cuando no existe una coincidencia única. Finalmente, aprenderás cómo decirle a dplyr qué variables son las claves para una unión determinada.\n\n13.4.1 Entendiendo las uniones\nPara ayudarte a entender las uniones, usaremos una representación gráfica:\n\n\n\n\n\n\nx &lt;- tribble(\n  ~key, ~val_x,\n  1, \"x1\",\n  2, \"x2\",\n  3, \"x3\"\n)\ny &lt;- tribble(\n  ~key, ~val_y,\n  1, \"y1\",\n  2, \"y2\",\n  4, \"y3\"\n)\n\nLa columna coloreada representa la variable “clave”: estas se usan para unir filas entre las tablas. La columa gris representa la columna “valor” que se usa en todo el proceso. En estos ejemplos te mostraremos una única clave, pero la idea es generalizable de manera directa a múltiples claves y múltiples valores.\nUna unión es una forma de conectar cada fila en x con cero, una o más filas en y. El siguiente diagrama muestra cada coincidencia potencial como una intersección de pares de líneas.\n\n\n\n\n\n(Si observas detenidamente, te darás cuenta de que hemos cambiado el orden de las columnas clave y valor en x. Esto es para enfatizar que las uniones encuentran coincidencias basadas en las claves; el valor simplemente se traslada durante el proceso.)\nEn la unión que mostramos, las coincidencias se indican con puntos. El número de puntos es igual al número de coincidencias y al número de filas en la salida.\n\n\n\n\n\n\n\n13.4.2 Unión interior\nLa forma más simple de unión es la unión interior (del inglés inner join). Una unión interior une pares de observaciones siempre que sus claves sean iguales:\n\n\n\n\n\n(Para ser precisos, esto corresponde a una unión de igualdad (o equijoin) interior, debido a que las claves se unen usando el operador de igualdad. Dado que muchas uniones son uniones de igualdad, por lo general omitimos esa especificación.)\nEl output de una unión interior es un nuevo data frame que contiene la clave, los valores de x y los valores de y. Usamos by (según) para indicar a dplyr qué variable es la clave:\n\nx %&gt;%\n  inner_join(y, by = \"key\")\n\n# A tibble: 2 × 3\n    key val_x val_y\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1     1 x1    y1   \n2     2 x2    y2   \n\n\nLa propiedad más importante de una unión interior es que las filas no coincidentes no se incluyen en el resultado. Esto significa que generalmente las uniones interiores no son apropiadas para su uso en el análisis de datos dado que es muy fácil perder observaciones.\n\n\n13.4.3 Uniones exteriores\nUna unión interior mantiene las observaciones que aparecen en ambas tablas. Una unión exterior mantiene las observaciones que aparecen en al menos una de las tablas. Existen tres tipos de uniones exteriores:\n\nUna unión izquierda (left join) mantiene todas las observaciones en x.\nUna unión derecha (right join) mantiene todas las observaciones en y.\nUna unión completa (full join) mantiene todas las observaciones en x e y.\n\nEstas uniones funcionan agregando una observación “virtual” adicional a cada tabla. Esta observación tiene una clave que siempre coincide (de no haber otras claves coincidentes) y un valor que se llena con NA.\nGráficamente corresponde a lo siguiente:\n\n\n\n\n\nLa unión que más frecuentemente se usa es la unión izquierda: úsala cuando necesites buscar datos adicionales en otra tabla, dado que preserva las observaciones originales incluso cuando no hay coincidencias. La unión izquierda debiera ser tu unión por defecto, a menos que tengas un motivo importante para preferir una de las otras.\nOtra forma de ilustrar diferentes tipos de uniones es mediante un diagrama de Venn:\n\n\n\n\n\nSin embargo, esta no es una buena representación. Puede ayudar a recordar qué uniones preservan las observaciones en qué tabla pero esto tiene una limitante importante: un diagrama de Venn no puede mostrar qué ocurre con las claves que no identifican de manera única una observación.\n\n\n13.4.4 Claves duplicadas\nHasta ahora todos los diagramas han asumido que las claves son únicas. Pero ese no siempre es así. Esta sección explica qué ocurre en esos casos. Existen dos posibilidades:\n\nUna tabla tiene claves duplicadas. Esto es útil cuando quieres agregar información adicional dado que típicamente existe una relación uno a muchos.\n\n::: {.cell} ::: {.cell-output-display}  ::: :::\nNota que hemos puesto la columna clave en una posición ligeramente distinta en el output. Esto refleja que la clave es una clave primaria en y y una clave foránea en x.\n::: {.cell}\nx &lt;- tribble(\n ~key, ~val_x,\n 1, \"x1\",\n 2, \"x2\",\n 2, \"x3\",\n 1, \"x4\"\n)\ny &lt;- tribble(\n ~key, ~val_y,\n 1, \"y1\",\n 2, \"y2\"\n)\nleft_join(x, y, by = \"key\")\n::: {.cell-output .cell-output-stdout} # A tibble: 4 × 3      key val_x val_y    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  1     1 x1    y1     2     2 x2    y2     3     2 x3    y2     4     1 x4    y1 ::: :::\n\nAmbas tablas tienen claves duplicadas. Esto es usualmente un error debido a que en ninguna de las tablas las claves identifican de manera única una observación. Cuando unes claves duplicadas, se obtienen todas las posibles combinaciones, es decir, el producto cartesiano:\n\n::: {.cell} ::: {.cell-output-display}  ::: :::\n::: {.cell}\n  x &lt;- tribble(\n ~key, ~val_x,\n 1, \"x1\",\n 2, \"x2\",\n 2, \"x3\",\n 3, \"x4\"\n  )\n  y &lt;- tribble(\n ~key, ~val_y,\n 1, \"y1\",\n 2, \"y2\",\n 2, \"y3\",\n 3, \"y4\"\n  )\n  left_join(x, y, by = \"key\")\n::: {.cell-output .cell-output-stderr} Warning in left_join(x, y, by = \"key\"): Detected an unexpected many-to-many relationship between `x` and `y`.    ℹ Row 2 of `x` matches multiple rows in `y`.    ℹ Row 2 of `y` matches multiple rows in `x`.    ℹ If a many-to-many relationship is expected, set `relationship =      \"many-to-many\"` to silence this warning. :::\n::: {.cell-output .cell-output-stdout} # A tibble: 6 × 3        key val_x val_y      &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    1     1 x1    y1       2     2 x2    y2       3     2 x2    y3       4     2 x3    y2       5     2 x3    y3       6     3 x4    y4 ::: :::\n\n\n13.4.5 Definiendo las columnas clave\nHasta ahora, los pares de tablas siempre se han unido de acuerdo a una única variable y esa variable tiene el mismo nombre en ambas tablas. Esta restricción se expresa de la forma by = \"key\". Puedes usar otros valores de by para conectar las tablas de otras maneras:\n\nPor defecto, by = NULL, usa todas las variables que aparecen en ambas tablas, lo que se conoce como unión natural. Por ejemplo, las tablas vuelos y clima coinciden en sus variables comunes: anio, mes, dia, hora y origen.\n\n::: {.cell}\nvuelos2 %&gt;%\n left_join(clima)\n::: {.cell-output .cell-output-stderr} Joining with `by = join_by(anio, mes, dia, hora, origen)` :::\n::: {.cell-output .cell-output-stdout} # A tibble: 336,776 × 18      anio   mes   dia  hora origen destino codigo_cola aerolinea temperatura     &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;           &lt;dbl&gt;   1  2013     1     1     5 EWR    IAH     N14228      UA               39.0   2  2013     1     1     5 LGA    IAH     N24211      UA               39.9   3  2013     1     1     5 JFK    MIA     N619AA      AA               39.0   4  2013     1     1     5 JFK    BQN     N804JB      B6               39.0   5  2013     1     1     6 LGA    ATL     N668DN      DL               39.9   6  2013     1     1     5 EWR    ORD     N39463      UA               39.0   7  2013     1     1     6 EWR    FLL     N516JB      B6               37.9   8  2013     1     1     6 LGA    IAD     N829AS      EV               39.9   9  2013     1     1     6 JFK    MCO     N593JB      B6               37.9  10  2013     1     1     6 LGA    ORD     N3ALAA      AA               39.9  # ℹ 336,766 more rows  # ℹ 9 more variables: punto_rocio &lt;dbl&gt;, humedad &lt;dbl&gt;, direccion_viento &lt;dbl&gt;,  #   velocidad_viento &lt;dbl&gt;, velocidad_rafaga &lt;dbl&gt;, precipitacion &lt;dbl&gt;,  #   presion &lt;dbl&gt;, visibilidad &lt;dbl&gt;, fecha_hora &lt;dttm&gt; ::: :::\n\nUn vector de caracteres, by = \"x\". Esto es similar a una unión natural, pero usa algunas de las variables comunes. Por ejemplo, vuelos y aviones tienen la variable anio, pero esta significa cosas distintas en cada tabla por lo que queremos unir por codigo_cola.\n\n::: {.cell}\nvuelos2 %&gt;%\n left_join(aviones, by = \"codigo_cola\")\n::: {.cell-output .cell-output-stdout} # A tibble: 336,776 × 16     anio.x   mes   dia  hora origen destino codigo_cola aerolinea anio.y tipo          &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;      &lt;int&gt; &lt;chr&gt;      1   2013     1     1     5 EWR    IAH     N14228      UA          1999 Ala fij…   2   2013     1     1     5 LGA    IAH     N24211      UA          1998 Ala fij…   3   2013     1     1     5 JFK    MIA     N619AA      AA          1990 Ala fij…   4   2013     1     1     5 JFK    BQN     N804JB      B6          2012 Ala fij…   5   2013     1     1     6 LGA    ATL     N668DN      DL          1991 Ala fij…   6   2013     1     1     5 EWR    ORD     N39463      UA          2012 Ala fij…   7   2013     1     1     6 EWR    FLL     N516JB      B6          2000 Ala fij…   8   2013     1     1     6 LGA    IAD     N829AS      EV          1998 Ala fij…   9   2013     1     1     6 JFK    MCO     N593JB      B6          2004 Ala fij…  10   2013     1     1     6 LGA    ORD     N3ALAA      AA            NA &lt;NA&gt;      # ℹ 336,766 more rows  # ℹ 6 more variables: fabricante &lt;chr&gt;, modelo &lt;chr&gt;, motores &lt;int&gt;,  #   asientos &lt;int&gt;, velocidad &lt;int&gt;, tipo_motor &lt;chr&gt; ::: :::\nNota que la variable anio (que aparece en los dos data frames de entrada, pero que no es igual en ambos casos) se desambigua con un sufijo en el output.\n\nUn vector de caracteres con nombres: by = c(\"a\" = \"b\"). Esto va a unir la variable a en la tabla x con la variabla b en la tabla y. Las variables de x se usarán en el output.\n\nPor ejemplo, si queremos dibujar un mapa necesitamos combinar los datos de vuelos con los datos de aeropuertos, que contienen la ubicación de cada uno (latitud y longitud). Cada vuelo tiene un aeropuerto de origen y destino, por lo que necesitamos especficar cuál queremos unir:\n::: {.cell}\nvuelos2 %&gt;%\n left_join(aeropuertos, c(\"origen\" = \"codigo_aeropuerto\"))\n::: {.cell-output .cell-output-stdout} # A tibble: 336,776 × 15      anio   mes   dia  hora origen destino codigo_cola aerolinea nombre   latitud     &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;   1  2013     1     1     5 EWR    IAH     N14228      UA        Newark …    40.7   2  2013     1     1     5 LGA    IAH     N24211      UA        La Guar…    40.8   3  2013     1     1     5 JFK    MIA     N619AA      AA        John F …    40.6   4  2013     1     1     5 JFK    BQN     N804JB      B6        John F …    40.6   5  2013     1     1     6 LGA    ATL     N668DN      DL        La Guar…    40.8   6  2013     1     1     5 EWR    ORD     N39463      UA        Newark …    40.7   7  2013     1     1     6 EWR    FLL     N516JB      B6        Newark …    40.7   8  2013     1     1     6 LGA    IAD     N829AS      EV        La Guar…    40.8   9  2013     1     1     6 JFK    MCO     N593JB      B6        John F …    40.6  10  2013     1     1     6 LGA    ORD     N3ALAA      AA        La Guar…    40.8  # ℹ 336,766 more rows  # ℹ 5 more variables: longitud &lt;dbl&gt;, altura &lt;dbl&gt;, zona_horaria &lt;dbl&gt;,  #   horario_verano &lt;chr&gt;, zona_horaria_iana &lt;chr&gt; :::\nvuelos2 %&gt;%\n left_join(aeropuertos, c(\"destino\" = \"codigo_aeropuerto\"))\n::: {.cell-output .cell-output-stdout} # A tibble: 336,776 × 15      anio   mes   dia  hora origen destino codigo_cola aerolinea nombre   latitud     &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;   1  2013     1     1     5 EWR    IAH     N14228      UA        George …    30.0   2  2013     1     1     5 LGA    IAH     N24211      UA        George …    30.0   3  2013     1     1     5 JFK    MIA     N619AA      AA        Miami I…    25.8   4  2013     1     1     5 JFK    BQN     N804JB      B6        &lt;NA&gt;        NA     5  2013     1     1     6 LGA    ATL     N668DN      DL        Hartsfi…    33.6   6  2013     1     1     5 EWR    ORD     N39463      UA        Chicago…    42.0   7  2013     1     1     6 EWR    FLL     N516JB      B6        Fort La…    26.1   8  2013     1     1     6 LGA    IAD     N829AS      EV        Washing…    38.9   9  2013     1     1     6 JFK    MCO     N593JB      B6        Orlando…    28.4  10  2013     1     1     6 LGA    ORD     N3ALAA      AA        Chicago…    42.0  # ℹ 336,766 more rows  # ℹ 5 more variables: longitud &lt;dbl&gt;, altura &lt;dbl&gt;, zona_horaria &lt;dbl&gt;,  #   horario_verano &lt;chr&gt;, zona_horaria_iana &lt;chr&gt; ::: :::\n\n\n13.4.6 Ejercicios\n\nCalcula el atraso promedio por destino y luego une los datos en aeropuertos para que puedas mostrar la distribución espacial de los atrasos. Esta es una forma fácil de dibujar un mapa de los Estados Unidos:\n\naeropuertos %&gt;%\nsemi_join(vuelos, c(\"codigo_aeropuerto\" = \"destino\")) %&gt;%\nggplot(aes(longitud, latitud)) +\nborders(\"state\") +\ngeom_point() +\ncoord_quickmap()\n\n\n(No te preocupes si no entiendes quá hace semi_join(); lo aprenderás a continuación.)\nQuizás quieras usar size o colour para editar los puntos y mostrar el atraso promedio de cada aeropuerto.\n\nAgrega la ubicación de origen y destino (por ejemplo, latitud y longitud) a vuelos.\n¿Existe una relación entre la antiguedad de un avión y sus atrasos?\n¿Qué condiciones climáticas hacen más probables los atrasos?\n¿Qué sucedió el día 13 de junio de 2013? Muestra el patrón espacial de los atrasos. Luego, usa un buscador para encontrar referencias cruzadas con el clima.\n\n\n\n13.4.7 Otras implementaciones\nbase::merge() puede realizar los cuatro tipos de uniones de transformación:\n\n\n\ndplyr\nmerge\n\n\n\n\ninner_join(x, y)\nmerge(x, y)\n\n\nleft_join(x, y)\nmerge(x, y, all.x = TRUE)\n\n\nright_join(x, y)\nmerge(x, y, all.y = TRUE),\n\n\nfull_join(x, y)\nmerge(x, y, all.x = TRUE, all.y = TRUE)\n\n\n\nLa ventaja de los verbos específicos de dplyr es que muestran de manera clara la intención del código: la diferencia entre las uniones es realmente importante pero se esconde en los argumentos de merge(). Las uniones de dplyr son considerablemente más rápidas y no generan problemas con el orden de las filas\nSQL es una inspiración para las convenciones de dplyr, por lo que su traducción es directa:\n\n\n\n\n\n\n\ndplyr\nSQL\n\n\n\n\ninner_join(x, y, by = \"z\")\nSELECT * FROM x INNER JOIN y USING (z)\n\n\nleft_join(x, y, by = \"z\")\nSELECT * FROM x LEFT OUTER JOIN y USING (z)\n\n\nright_join(x, y, by = \"z\")\nSELECT * FROM x RIGHT OUTER JOIN y USING (z)\n\n\nfull_join(x, y, by = \"z\")\nSELECT * FROM x FULL OUTER JOIN y USING (z)\n\n\n\nNota que “INNER” y “OUTER” son opcionales, por lo que a menudo se omiten.\nUnir distintas variables entre tablas, por ejemplo inner_join(x, y, by = c(\"a\" = \"b\")), usa una sintaxis ligeramente distinta en SQL: SELECT * FROM x INNER JOIN y ON x.a = y.b. Como la sintaxis sugiere, SQL soporta un rango más amplio de tipos de uniones que dplyr, ya que puedes conectar tablas usando restricciones distintas a las de igualdad (a veces llamadas de no-igualdad)."
  },
  {
    "objectID": "13-relational-data.html#filtering-joins",
    "href": "13-relational-data.html#filtering-joins",
    "title": "13  Datos relacionales",
    "section": "13.5 Uniones de filtro",
    "text": "13.5 Uniones de filtro\nLas uniones de filtro unen observaciones de la misma forma que las uniones de transformación pero afectan a las observaciones, no a las variables. Existen dos tipos:\n\nsemi_join(x, y) mantiene todas las observaciones en x con coincidencias en y.\nanti_join(x, y) descarta todas las observaciones en x con coincidencias en y.\n\nLas semi uniones son útiles para unir tablas resumen previamente filtradas con las filas originales. Por ejemplo, imagina que encontraste los diez destinos más populares:\n\ndestinos_populares &lt;- vuelos %&gt;%\n  count(destino, sort = TRUE) %&gt;%\n  head(10)\ndestinos_populares\n\n# A tibble: 10 × 2\n   destino     n\n   &lt;chr&gt;   &lt;int&gt;\n 1 ORD     17283\n 2 ATL     17215\n 3 LAX     16174\n 4 BOS     15508\n 5 MCO     14082\n 6 CLT     14064\n 7 SFO     13331\n 8 FLL     12055\n 9 MIA     11728\n10 DCA      9705\n\n\nAhora quieres encontrar cada vuelo que fue a alguno de esos destinos. Puedes construir un filtro:\n\nvuelos %&gt;%\n  filter(destino %in% destinos_populares$destino)\n\n# A tibble: 141,145 × 19\n    anio   mes   dia horario_salida salida_programada atraso_salida\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;          &lt;int&gt;             &lt;int&gt;         &lt;dbl&gt;\n 1  2013     1     1            542               540             2\n 2  2013     1     1            554               600            -6\n 3  2013     1     1            554               558            -4\n 4  2013     1     1            555               600            -5\n 5  2013     1     1            557               600            -3\n 6  2013     1     1            558               600            -2\n 7  2013     1     1            558               600            -2\n 8  2013     1     1            558               600            -2\n 9  2013     1     1            559               559             0\n10  2013     1     1            600               600             0\n# ℹ 141,135 more rows\n# ℹ 13 more variables: horario_llegada &lt;int&gt;, llegada_programada &lt;int&gt;,\n#   atraso_llegada &lt;dbl&gt;, aerolinea &lt;chr&gt;, vuelo &lt;int&gt;, codigo_cola &lt;chr&gt;,\n#   origen &lt;chr&gt;, destino &lt;chr&gt;, tiempo_vuelo &lt;dbl&gt;, distancia &lt;dbl&gt;,\n#   hora &lt;dbl&gt;, minuto &lt;dbl&gt;, fecha_hora &lt;dttm&gt;\n\n\nPero es difícil extender este enfoque a varias variables. Por ejemplo, imagina que encontraste los diez días con los atrasos promedio más altos. ¿Cómo construirías un filtro que use anio, mes y dia para buscar coincidencias con vuelos?\nPuedes, en cambio, usar semi_join(), que conecta dos tablas de manera similar a una unión de transformación, pero en lugar de agregar nuevas columnas, mantiene las filas en x que tienen coincidencias en y:\n\nvuelos %&gt;%\n  semi_join(destinos_populares)\n\nJoining with `by = join_by(destino)`\n\n\n# A tibble: 141,145 × 19\n    anio   mes   dia horario_salida salida_programada atraso_salida\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;          &lt;int&gt;             &lt;int&gt;         &lt;dbl&gt;\n 1  2013     1     1            542               540             2\n 2  2013     1     1            554               600            -6\n 3  2013     1     1            554               558            -4\n 4  2013     1     1            555               600            -5\n 5  2013     1     1            557               600            -3\n 6  2013     1     1            558               600            -2\n 7  2013     1     1            558               600            -2\n 8  2013     1     1            558               600            -2\n 9  2013     1     1            559               559             0\n10  2013     1     1            600               600             0\n# ℹ 141,135 more rows\n# ℹ 13 more variables: horario_llegada &lt;int&gt;, llegada_programada &lt;int&gt;,\n#   atraso_llegada &lt;dbl&gt;, aerolinea &lt;chr&gt;, vuelo &lt;int&gt;, codigo_cola &lt;chr&gt;,\n#   origen &lt;chr&gt;, destino &lt;chr&gt;, tiempo_vuelo &lt;dbl&gt;, distancia &lt;dbl&gt;,\n#   hora &lt;dbl&gt;, minuto &lt;dbl&gt;, fecha_hora &lt;dttm&gt;\n\n\nGráficamente, un semi_join() se ve de la siguiente forma:\n\n\n\n\n\nSolo la existencia de coincidencias es importante; da igual qué observaciones son coincidentes. Esto significa que las uniones de filtro nunca duplican filas como lo hacen las uniones de transformación:\n\n\n\n\n\nLa operación inversa de semi_join() es anti_join(). anti_join() mantiene las filas que no tienen coincidencias:\n\n\n\n\n\nLas anti uniones son útiles para encontrar desajustes. Por ejemplo, al conectar aviones y vuelos, podría interesarte saber que existen muchos vuelos que no tienen coincidencias en aviones:\n\nvuelos %&gt;%\n  anti_join(aviones, by = \"codigo_cola\") %&gt;%\n  count(codigo_cola, sort = TRUE)\n\n# A tibble: 722 × 2\n   codigo_cola     n\n   &lt;chr&gt;       &lt;int&gt;\n 1 &lt;NA&gt;         2512\n 2 N725MQ        575\n 3 N722MQ        513\n 4 N723MQ        507\n 5 N713MQ        483\n 6 N735MQ        396\n 7 N0EGMQ        371\n 8 N534MQ        364\n 9 N542MQ        363\n10 N531MQ        349\n# ℹ 712 more rows\n\n\n\n13.5.1 Ejercicios\n\n¿Qué significa que a un vuelo le falte codigo_cola? ¿Qué tienen en común los códigos de cola que no tienen registros coincidentes en aviones? (Pista: una variable explica ~90% de los problemas.)\nFiltra los vuelos para mostrar únicamente los aviones que han realizado al menos cien viajes.\nCombina datos::vehiculos y datos::comunes para encontrar los registros de los modelos más comunes.\nEncuentra las 48 horas (en el transcurso del año) que tengan los peores atrasos. Haz una referencia cruzada con la tabla clima. ¿Puedes observar patrones?\n¿Qué te indica anti_join(vuelos, aeropuertos, by = c(\"destino\" = \"codigo_aeropuerto\"))? ¿Qué te indica anti_join(aeropuertos, vuelos, by = c(\"codigo_aeropuerto\" = \"destino\"))?\nPuedes esperar que exista una relación implícita entre aviones y aerolíneas, dado que cada avión es operado por una única aerolínea. Confirma o descarta esta hipótesis usando las herramientas que aprendiste más arriba."
  },
  {
    "objectID": "13-relational-data.html#problemas-con-las-uniones",
    "href": "13-relational-data.html#problemas-con-las-uniones",
    "title": "13  Datos relacionales",
    "section": "13.6 Problemas con las uniones",
    "text": "13.6 Problemas con las uniones\nLos datos con los que has estado trabajando en este capítulo han sido limpiados de modo que tengas la menor cantidad de problemas posibles. Tus datos difícilmente estarán tan ordenados, por lo que hay algunas consideraciones y pasos a tener en cuenta para que las uniones funcionen adecuadamente sobre tus propios datos.\n\nComienza identificando las variables que forman las claves primarias en cada tabla. Usualmente debieras hacerlo considerando tus conocimientos de los datos, no observando empíricamente las combinaciones de variables que resultan en un identificador único. Si te centras en las variables sin pensar en sus significados, puedes tener la (mala) suerte de encontrar una combinación única en tus datos pero que no sea válida en general.\nPor ejemplo, la altura y la longitud identifican de manera única cada aeropuerto, ¡pero no son buenos identificadores!\n\n  aeropuertos %&gt;% count(altura, longitud) %&gt;% filter(n &gt; 1)\n\n# A tibble: 0 × 3\n# ℹ 3 variables: altura &lt;dbl&gt;, longitud &lt;dbl&gt;, n &lt;int&gt;\n\n\nVerifica que ninguna de las variables en la clave primaria esté perdida. ¡Si hay un valor faltante no podrá identificar una observación!\nVerifica que las claves foráneas coincidan con las claves primarias en otra tabla. La mejor forma de hacerlo es mediante un anti_join(). Es común que las claves no coincidan debido a errores en la entrada de datos. Arreglar este problema requiere mucho trabajo.\nSi tienes claves perdidas, debes tener cuidado en el uso de unión interior versus unión exterior y considerar cuidadosamente si quieres descartar las filas que no tengan coincidencias.\n\nTen en cuenta que verificar el número de filas antes y después de unir no es suficiente para asegurar que la unión funcionó de forma exitosa. Si tienes una unión interior con claves duplicadas en ambas tablas, puedes tener la mala suerte de que el número de filas descartadas sea igual al número de filas duplicadas."
  },
  {
    "objectID": "13-relational-data.html#set-operations",
    "href": "13-relational-data.html#set-operations",
    "title": "13  Datos relacionales",
    "section": "13.7 Operaciones de conjuntos",
    "text": "13.7 Operaciones de conjuntos\nEl tipo final de verbo para dos tablas son las operaciones de conjunto. Si bien lo usamos de manera poco frecuente, en ocasiones es útil cuando quieres dividir un filtro complejo en partes maś simples. Todas estas operaciones funcionan con una fila completa, comparando los valores de cada variable. Esto espera que los input x e y tengan las mismas variables y trata las observaciones como conjuntos:\n\nintersect(x, y): devuelve las observaciones comunes en x e y.\nunion(x, y): devuelve las observaciones únicas en x e y.\nsetdiff(x, y): devuelve las observaciones en x pero no en y.\n\nDados los siguientes datos simples:\n\ndf1 &lt;- tribble(\n  ~x, ~y,\n  1, 1,\n  2, 1\n)\ndf2 &lt;- tribble(\n  ~x, ~y,\n  1, 1,\n  1, 2\n)\n\nLas cuatro posibilidades son:\n\nintersect(df1, df2)\n\n# A tibble: 1 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1     1     1\n\n# Nota que obtenemos 3 filas, no 4\nunion(df1, df2)\n\n# A tibble: 3 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1     1     1\n2     2     1\n3     1     2\n\nsetdiff(df1, df2)\n\n# A tibble: 1 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1     2     1\n\nsetdiff(df2, df1)\n\n# A tibble: 1 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1     1     2"
  },
  {
    "objectID": "13-relational-data.html#footnotes",
    "href": "13-relational-data.html#footnotes",
    "title": "13  Datos relacionales",
    "section": "",
    "text": "NdT. El texto original se refiere al paquete nycflights13 cuya traducción se incluye en el paquete datos.↩︎"
  },
  {
    "objectID": "14-strings.html#introducción",
    "href": "14-strings.html#introducción",
    "title": "14  Cadenas de caracteres",
    "section": "14.1 Introducción",
    "text": "14.1 Introducción\nEste capítulo te introduce en la manipulación de cadenas de caracteres en R. Si bien aprenderás los aspectos básicos acerca de cómo funcionan y cómo crearlas a mano, el foco del capítulo estará puesto en las expresiones regulares (o regex). Como las cadenas de caracteres suelen contener datos no estructurados o semiestructurados, las expresiones regulares resultan útiles porque permiten describir patrones en ellas a través de un lenguaje conciso. Cuando mires por primera vez una expresión regular te parecerá que un gato caminó sobre tu teclado, pero a medida que vayas ampliando tu conocimiento pronto te empezarán a hacer sentido.\n\n14.1.1 Prerequisitos\nEste capítulo se enfocará en el paquete para manipulación de cadenas llamado stringr (del inglés string, cadena), que es parte del Tidyverse.\n\nlibrary(tidyverse)\nlibrary(datos)"
  },
  {
    "objectID": "14-strings.html#cadenas-elementos-básicos",
    "href": "14-strings.html#cadenas-elementos-básicos",
    "title": "14  Cadenas de caracteres",
    "section": "14.2 Cadenas: elementos básicos",
    "text": "14.2 Cadenas: elementos básicos\nPuedes crear una cadena utilizando comillas simples o dobles. A diferencia de otros lenguajes, no hay diferencias en su comportamiento. Nuestra recomendación es siempre utilizar \", a menos que quieras crear una cadena que contenga múltiples \".\n\nstring1 &lt;- \"Esta es una cadena de caracteres\"\nstring2 &lt;- 'Si quiero incluir \"comillas\" dentro de la cadena, uso comillas simples'\n\nSi olvidas cerrar las comillas, verás un + en la consola, que es el signo de continuación para indicar que el código no está completo:\n&gt; \"Esta es una cadena de caracteres sin comillas de cierre\n+ \n+ \n+ AYUDA, ESTOY ATASCADO\nSi esto te ocurre, ¡presiona la tecla Escape e inténtalo de nuevo!\nPara incluir comillas simples o dobles de manera literal en una cadena puedes utilizar \\ para “escaparlas” (“escapar” viene de la tecla escape):\n\ncomilla_doble &lt;- \"\\\"\" # o '\"'\ncomilla_simple &lt;- '\\'' # o \"'\"\n\nEsto quiere decir que si quieres incluir una barra invertida, necesitas duplicarla: \"\\\\\".\nTen cuidado con el hecho de que la representación impresa de una cadena no es equivalente a la cadena misma, ya que la representación muestra las barras utilizadas para “escapar” caracteres, es decir, para sean interpretados en su sentido literal, no como caracteres especiales. Para ver el contenido en bruto de una cadena utiliza writeLines():\n\nx &lt;- c(\"\\\"\", \"\\\\\")\nx\n\n[1] \"\\\"\" \"\\\\\"\n\nwriteLines(x)\n\n\"\n\\\n\n\nExiste una serie de otros caracteres especiales. Los más comunes son \"\\n\", para salto de línea, y \"\\t\", para tabulación. Puedes ver la lista completa pidiendo ayuda acerca de \": ?'\"' o ?\"'\". A veces también verás cadenas del tipo \"\\u00b5\", que es la manera de escribir caracteres que no están en inglés para que funcionen en todas las plataformas:\n\nx &lt;- \"\\u00b5\"\nx\n\n[1] \"µ\"\n\n\nUsualmente se guardan múltiples cadenas en un vector de caracteres. Puedes crearlo usando c():\n\nc(\"uno\", \"dos\", \"tres\")\n\n[1] \"uno\"  \"dos\"  \"tres\"\n\n\n\n14.2.1 Largo de cadena\nR base tiene muchas funciones para trabajar con cadenas de caracteres, pero las evitaremos porque pueden ser incosistentes, lo que hace que sean difíciles de recordar. En su lugar, utilizaremos funciones del paquete stringr. Estas tienen nombres más intuitivos y todas empienzan con str_. Por ejemplo, str_length() te dice el número de caracteres de una cadena (length en inglés es largo):\n\nstr_length(c(\"a\", \"R para Ciencia de Datos\", NA))\n\n[1]  1 23 NA\n\n\nEl prefijo común str_ es particularmente útil si utilizas RStudio, ya que al escribir str_ se activa el autocompletado, lo que te permite ver todas las funciones de stringr:\n\n\n\n\n\n\n\n14.2.2 Combinar cadenas\nPara combinar dos o más cadenas utiliza str_c():\n\nstr_c(\"x\", \"y\")\n\n[1] \"xy\"\n\nstr_c(\"x\", \"y\", \"z\")\n\n[1] \"xyz\"\n\n\nUsa el argumento sep para controlar cómo separlas:\n\nstr_c(\"x\", \"y\", sep = \", \")\n\n[1] \"x, y\"\n\n\nAl igual que en muchas otras funciones de R, los valores faltantes son contagiosos. Si quieres que se impriman como \"NA\", utiliza str_replace_na() (replace = remplazar):\n\nx &lt;- c(\"abc\", NA)\nstr_c(\"|-\", x, \"-|\")\n\n[1] \"|-abc-|\" NA       \n\nstr_c(\"|-\", str_replace_na(x), \"-|\")\n\n[1] \"|-abc-|\" \"|-NA-|\" \n\n\nComo se observa arriba, str_c() es una función vectorizada que automáticamente recicla los vectores más cortos hasta alcanzar la extensión del más largo:\n\nstr_c(\"prefijo-\", c(\"a\", \"b\", \"c\"), \"-sufijo\")\n\n[1] \"prefijo-a-sufijo\" \"prefijo-b-sufijo\" \"prefijo-c-sufijo\"\n\n\nLos objetos de extensión 0 se descartan de manera silenciosa. Esto es particularmente útil en conjunto con if (si):\n\nnombre &lt;- \"Hadley\"\nhora_del_dia &lt;- \"mañana\"\ncumpleanios &lt;- FALSE\n\nstr_c(\n  \"Que tengas una buena \", hora_del_dia, \", \", nombre,\n  if (cumpleanios) \" y ¡FELIZ CUMPLEAÑOS!\",\n  \".\"\n)\n\n[1] \"Que tengas una buena mañana, Hadley.\"\n\n\nPara colapsar un vector de cadenas en una sola, utiliza collapse:\n\nstr_c(c(\"x\", \"y\", \"z\"), collapse = \", \")\n\n[1] \"x, y, z\"\n\n\n\n\n14.2.3 Dividir cadenas\nPuedes extraer partes de una cadena utilizando str_sub(). Al igual que la cadena, str_sub() tiene como argumentos start (inicio) y end (fin), que indican la posición (inclusiva) del subconjunto que se quiere extraer:\n\nx &lt;- c(\"Manzana\", \"Plátano\", \"Pera\")\nstr_sub(x, 1, 3)\n\n[1] \"Man\" \"Plá\" \"Per\"\n\n# los números negativos cuentan de manera invertida desde el final\nstr_sub(x, -3, -1)\n\n[1] \"ana\" \"ano\" \"era\"\n\n\nTen en cuenta que str_sub() no fallará si la cadena es muy corta; simplemente devolverá todo lo que sea posible:\n\nstr_sub(\"a\", 1, 5)\n\n[1] \"a\"\n\n\nTambién puedes utilizar str_sub() en forma de asignación para modificar una cadena:\n\nstr_sub(x, 1, 1) &lt;- str_to_lower(str_sub(x, 1, 1))\nx\n\n[1] \"manzana\" \"plátano\" \"pera\"   \n\n\n\n\n14.2.4 Locales\nArriba utilizamos str_to_lower() para cambiar el texto a minúsculas. También puedes utilizar str_to_upper() o str_to_title(), si quieres modificar el texto a mayúsculas o formato título, respectivamente. Sin embargo, este tipo de cambios puede ser más complicado de lo parece a primera vista, ya que las reglas no son iguales en todos los idiomas. Puedes selecionar qué tipo de reglas aplicar especificando el entorno local o locale:\n\n# La lengua turca tiene dos i: una con punto y otra sin punto\n# Tienen diferentes reglas para convertirlas en mayúsculas\n\nstr_to_upper(c(\"i\", \"ı\"))\n\n[1] \"I\" \"I\"\n\nstr_to_upper(c(\"i\", \"ı\"), locale = \"tr\")\n\n[1] \"İ\" \"I\"\n\n\nEl entorno local o locale se especifica con un código de idioma ISO 639, que es una abreviación de dos letras. Si todavía no conoces el código para tu idioma, en Wikipedia puedes encontrar una buena lista. Si dejas el locale en blanco, se aplicará el que estés utilizando actualmente, que es provisto por tu sistema operativo.\nOtra operación importante que es afectada por el locale es ordenar. Las funciones order() y sort() de R base ordenan las cadenas usando el locale actual. Si quieres un comportamiento consistente a través de diferentes computadoras, sería preferible usar str_sort() y str_order(), que aceptan un argumento adicional para definir el locale:\n\nx &lt;- c(\"arándano\", \"espinaca\", \"banana\")\n\nstr_sort(x, locale = \"es\")  # Español\n\n[1] \"arándano\" \"banana\"   \"espinaca\"\n\nstr_sort(x, locale = \"haw\") # Hawaiano\n\n[1] \"arándano\" \"espinaca\" \"banana\"  \n\n\n\n\n14.2.5 Ejercicios\n\nEn ejemplos de código en los que no se utiliza stringr, verás usualmente paste() y paste0() (paste = pegar). ¿Cuál es la diferencia entre estas dos funciones? ¿A qué función de stringr son equivalentes? ¿Cómo difieren estas dos funciones respecto de su manejo de los NA?\nDescribe con tus propias palabras la diferencia entre los argumentos sep y collapse de la función str_c().\nUtiliza str_length() y str_sub() para extraer el caracter del medio de una cadena. ¿Qué harías si el número de caracteres es par?\n¿Qué hace str_wrap()? (wrap = envolver) ¿Cuándo podrías querer utilizarla?\n¿Qué hace str_trim()? (trim = recortar) ¿Cuál es el opuesto de str_trim()?\nEscribe una función que convierta, por ejemplo, el vector c(\"a\", \"b\", \"c\") en la cadena a, b y c. Piensa con detención qué debería hacer dado un vector de largo 0, 1 o 2.\n\n\n\n14.2.6 Buscar coincidencia de patrones con expresiones regulares\nLas expresiones regulares son un lenguaje conciso que te permite describir patrones en cadenas de caracteres. Toma un tiempo entenderlas, pero una vez que lo hagas te darás cuenta que son extremadamente útiles.\nPara aprender sobre expresiones regulares usaremos str_view() y str_view_all() (view = ver). Estas funciones toman un vector de caracteres y una expresión regular y te muestran cómo coinciden. Partiremos con expresiones regulares simples que gradualmente se irán volviendo más y más complejas. Una vez que domines la coincidencia de patrones, aprenderás cómo aplicar estas ideas con otras funciones de stringr.\n\n\n14.2.7 Coincidencias básicas\nLos patrones más simples buscan coincidencias con cadenas exactas:\n\nx &lt;- c(\"manzana\", \"banana\", \"pera\")\nstr_view(x, \"an\")\n\n[1] │ m&lt;an&gt;z&lt;an&gt;a\n[2] │ b&lt;an&gt;&lt;an&gt;a\n\n\nEl siguiente paso en complejidad es ., que coincide con cualquier caracter (excepto un salto de línea):\n\nstr_view(x, \".a.\")\n\n[1] │ &lt;man&gt;&lt;zan&gt;a\n[2] │ &lt;ban&gt;ana\n\n\nPero si “.” coincide con cualquier caracter, ¿cómo buscar una coincidencia con el caracter “.”? Necesitas utilizar un “escape” para decirle a la expresión regular que quieres hacerla coincidir de manera exacta, no usar su comportamiento especial. Al igual que en las cadenas, las expresiones regulares usan la barra invertida, \\, para “escapar” los comportamientos especiales. Por lo tanto, para hacer coincidir un ., necesitas la expresión regular \\.. Lamentablemente, esto crea una problema. Estamos usando cadenas para representar una expresión regular y en ellas \\ también se usa como símbolo de “escape”. Por lo tanto, para crear la expresión regular \\. necesitamos la cadena \"\\\\.\".\n\n# Para crear una expresión regular necesitamos \\\\\npunto &lt;- \"\\\\.\"\n\n# Pero la expresión en sí misma solo contiene una \\\nwriteLines(punto)\n\n\\.\n\n# Esto le dice a R que busque el . de manera explícita\nstr_view(c(\"abc\", \"a.c\", \"bef\"), \"a\\\\.c\")\n\n[2] │ &lt;a.c&gt;\n\n\nSi \\ se utiliza para escapar un caracter en una expresión regular, ¿cómo coincidir de manera literal una \\? Bueno, necesitarías escaparla creando la expresión regular \\\\. Para crear esa expresión regular necesitas usar una cadena, que requiere también escapar la \\. Esto quiere decir que para coincidir literalmente \\ necesitas escribir \"\\\\\\\\\" — ¡necesitas cuatro barras invertidas para coincidir una!\n\nx &lt;- \"a\\\\b\"\nwriteLines(x)\n\na\\b\n\nstr_view(x, \"\\\\\\\\\")\n\n[1] │ a&lt;\\&gt;b\n\n\nEn este libro escribiremos las expresiones regulares como \\. y las cadenas que representan a las expresiones regulares como \"\\\\.\".\n\n14.2.7.1 Ejercicios\n\nExplica por qué cada una de estas cadenas no coincide con \\: \"\\\", \"\\\\\", \"\\\\\\\".\n¿Cómo harías coincidir la secuencia \"'\\?\n¿Con qué patrones coincidiría la expresión regular\\..\\..\\..? ¿Cómo la representarías en una cadena?\n\n\n\n\n14.2.8 Anclas\nPor defecto, las expresiones regulares buscarán una coincidencia en cualquier parte de una cadena. Suele ser útil anclar una expresión regular para que solo busque coincidencias al inicio o al final. Puedes utilizar:\n\n^ para buscar la coincidencia al inicio de la cadena.\n$ para buscar la coincidencia al final de la cadena.\n\n\nx &lt;- c(\"arándano\", \"banana\", \"pera\")\nstr_view(x, \"^a\")\n\n[1] │ &lt;a&gt;rándano\n\nstr_view(x, \"a$\")\n\n[2] │ banan&lt;a&gt;\n[3] │ per&lt;a&gt;\n\n\nPara recordar cuál es cuál, puedes intentar este recurso mnemotécnico que aprendimos de Evan Misshula: si empiezas con potencia (^), terminarás con dinero ($).\nPara forzar que una expresión regular coincida con una cadena completa, ánclala usando tanto ^ como $:\n\nx &lt;- c(\"pie de manzana\", \"manzana\", \"queque de manzana\")\nstr_view(x, \"manzana\")\n\n[1] │ pie de &lt;manzana&gt;\n[2] │ &lt;manzana&gt;\n[3] │ queque de &lt;manzana&gt;\n\nstr_view(x, \"^manzana$\")\n\n[2] │ &lt;manzana&gt;\n\n\nTambién puedes coincidir el límite entre palabras con \\b. No utilizamos frecuentemente esta forma en R, pero sí a veces cuando buscamos en RStudio el nombre de una función que también compone el nombre de otras funciones. Por ejemplo, buscaríamos \\bsum\\b para evitar la coincidencia con summarise, summary, rowsum y otras.\n\n14.2.8.1 Ejercicios\n\n¿Cómo harías coincidir la cadena \"$^$\" de manera literal?\nDado el corpus de palabras comunes en datos::palabras, crea una expresión regular que busque palabras que:\n\nEmpiecen con “y”.\nTerminen con “z”\nTengan una extensión de exactamente tres letras. (¡No hagas trampa usando str_length()!)\nTengan ocho letras o más.\n\nDado que esta será una lista larga, podrías querer usar el argumento match en str_view() para mostrar solo las palabras que coincidan o no coincidan.\n\n\n\n\n14.2.9 Clases de caracteres y alternativas\nExiste una serie de patrones especiales que coinciden con más de un caracter. Ya has visto ., que coincide con cualquier caracter excepto un salto de línea. Hay otras cuatro herramientas que son de utilidad:\n\n\\d: coincide con cualquier dígito.\n\\s: coincide con cualquier espacio en blanco (por ejemplo, espacio simple, tabulador, salto de línea).\n[abc]: coincide con a, b o c.\n[^abc]: coincide con todo menos con a, b o c.\n\nRecuerda que para crear una expresión regular que contenga \\d o \\s necesitas escapar la \\ en la cadena, por lo que debes escribir \"\\\\d\" o \"\\\\s\".\nUtilizar una clase de caracter que contenga en su interior un solo caracter puede ser una buena alternativa a la barra invertida cuando quieres incluir un solo metacaracter en la expresión regular. Muchas personas encuentran que así es más fácil de leer.\n\n# Buscar de forma literal un caracter que usualmente tiene un significado especial en una expresión regular\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \"a[.]c\")\n\n[2] │ &lt;a.c&gt;\n\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \".[*]c\")\n\n[3] │ &lt;a*c&gt;\n\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \"a[ ]\")\n\n[4] │ &lt;a &gt;c\n\n\nEsto funciona para la mayoría (pero no para todos) los metacaracteres de las expresiones regulares: $ . | ? * + ( ) [ {. Desafortunadamente, existen unos pocos caracteres que tienen un significado especial incluso dentro de una clase de caracteres y deben manejarse con barras invertidas para escaparlos: ] \\ ^ y -.\nPuedes utiizar una disyunción para elegir entre uno más patrones alternativos. Por ejemplo, abc|d..a concidirá tanto con ‘“abc”’, como con \"duna\". Ten en cuenta que la precedencia de | es baja, por lo que abc|xyz coincidirá con abc o xyz, no con abcyz o abxyz. Al igual que en expresiones matemáticas, si el valor de | se vuelve confuso, utiliza paréntesis para dejar claro qué es lo que quieres:\n\nstr_view(c(\"cómo\", \"como\"), \"c(ó|o)mo\")\n\n[1] │ &lt;cómo&gt;\n[2] │ &lt;como&gt;\n\n\n\n14.2.9.1 Ejercicios\n\nCrea una expresión regular que encuentre todas las palabras que:\n\nEmpiecen con una vocal.\nSolo contengan consonantes. (Pista: piensa en cómo buscar coincidencias para “no”-vocales.)\nTerminen en ón, pero no en ión.\nTerminen con ndo o ado.\n\n¿Siempre a una “q” la sigue una “u”?\nEscribe una expresión regular que permita buscar un verbo que haya sido escrito usando voseo en segunda persona plural\n(por ejemplo, queréis en vez de quieren).\nCrea una expresión regular que coincida con la forma en que habitualmente se escriben los números de teléfono en tu país.\nEn inglés existe una regla que dice que la letra i va siempre antes de la e, excepto cuando está después de una c”. Verifica empíricamente esta regla utilizando las palabras contenidas en stringr::words.\n\n\n\n\n14.2.10 Repetición\nEl siguiente paso en términos de poder implica controlar cuántas veces queremos que se encuentre un patrón:\n\n?: 0 o 1\n+: 1 o más\n*: 0 o más\n\n\nx &lt;- \"1888 es el año más largo en números romanos: MDCCCLXXXVIII\"\nstr_view(x, \"CC?\")\n\n[1] │ 1888 es el año más largo en números romanos: MD&lt;CC&gt;&lt;C&gt;LXXXVIII\n\nstr_view(x, \"CC+\")\n\n[1] │ 1888 es el año más largo en números romanos: MD&lt;CCC&gt;LXXXVIII\n\nstr_view(x, 'C[LX]+')\n\n[1] │ 1888 es el año más largo en números romanos: MDCC&lt;CLXXX&gt;VIII\n\n\nTen en cuenta que la precedencia de este operador es alta, por lo que puedes escribir: cantái?s para encontrar tanto voseo americano como de la variante peninsular del español (es decir, cantás y cantáis). Esto quiere decir que en la mayor parte de los usos se necesitarán paréntesis, como bana(na)+.\nTambién puedes especificar el número de coincidencias que quieres encontrar de manera precisa:\n\n{n}: exactamente n\n{n,}: n o más\n{,m}: no más de m\n{n,m}: entre n y m\n\n\nstr_view(x, \"C{2}\")\n\n[1] │ 1888 es el año más largo en números romanos: MD&lt;CC&gt;CLXXXVIII\n\nstr_view(x, \"C{2,}\")\n\n[1] │ 1888 es el año más largo en números romanos: MD&lt;CCC&gt;LXXXVIII\n\nstr_view(x, \"C{2,3}\")\n\n[1] │ 1888 es el año más largo en números romanos: MD&lt;CCC&gt;LXXXVIII\n\n\nPor defecto, este tipo de coincidencias son “avaras” (greedy): tratarán de coincidir con la cadena más larga posible. También puedes hacerlas “perezosas” (lazy) para que coincidan con la cadena más corta posible, poniendo un ? después de ellas. Esta es una característica avanzada de las expresiones regulares, pero es útil saber que existe:\n\nstr_view(x, 'C{2,3}?')\n\n[1] │ 1888 es el año más largo en números romanos: MD&lt;CC&gt;CLXXXVIII\n\nstr_view(x, 'C[LX]+?')\n\n[1] │ 1888 es el año más largo en números romanos: MDCC&lt;CL&gt;XXXVIII\n\n\n\n14.2.10.1 Ejercicios\n\nDescribe los equivalentes de ?, +, * en el formato {m,n}.\nDescribe en palabras con qué coincidiría cada una de estas expresiones regulares: (lee con atención para ver si estamos utilizando una expresión regular o una cadena que define una expresión regular.)\n\n^.*$\n\"\\\\{.+\\\\}\"\n\\d{4}-\\d{2}-\\d{2}\n\"\\\\\\\\{4}\"\n\nCrea expresiones regulares para buscar todas las palabras que:\n\nEmpiecen con dos consonantes.\nTengan tres o más vocales seguidas.\nTengan tres o más pares de vocal-consonante seguidos.\n\n\n\n\n\n14.2.11 Agrupamiento y referencias previas\nAnteriormente aprendiste sobre el uso de paréntesis para desambiguar expresiones complejas. Los paréntesis también sirven para crear un grupo de captura numerado (número 1, 2, etc.). Un grupo de captura guarda la parte de la cadena que coincide con la parte de la expresión regular entre paréntesis. Puedes referirte al mismo texto tal como fue guardado en un grupo de captura utilizando referencias previas, como \\1, \\2 etc. Por ejemplo, la siguiente expresión regular busca todas las frutas que tengan un par de letras repetido.\n\nstr_view(frutas, \"(..)\\\\1\", match = TRUE)\n\n [1] │ b&lt;anan&gt;a\n [2] │ &lt;papa&gt;ya\n [8] │ &lt;anan&gt;á\n[23] │ &lt;coco&gt;\n\n\n(En breve, también verás cómo esto es útil en conjunto con str_match().)\n\n14.2.11.1 Ejercicios\n\nDescribe en palabras con qué coinciden estas expresiones:\n\n(.)\\1\\1\n\"(.)(.)\\\\2\\\\1\"\n(..)\\1\n\"(.).\\\\1.\\\\1\"\n\"(.)(.)(.).*\\\\3\\\\2\\\\1\"\n\nConstruye una expresión regular que coincida con palabras que:\n\nEmpiecen y terminen con el mismo caracter.\nContengan un par de letras repetido (p. ej. “nacional” tiene “na” repetido dos veces.)\nContengan una letra repetida en al menos tres lugares (p. ej. “característica” tiene tres “a”.)"
  },
  {
    "objectID": "14-strings.html#herramientas",
    "href": "14-strings.html#herramientas",
    "title": "14  Cadenas de caracteres",
    "section": "14.3 Herramientas",
    "text": "14.3 Herramientas\nAhora que has aprendido los elementos básicos de las expresiones regulares, es tiempo de aprender cómo aplicarlos en problemas reales. En esta sección aprenderás una amplia variedad de funciones de stringr que te permitirán:\n\nDeterminar qué cadenas coinciden con un patrón.\nEncontrar la posición de una coincidencia.\nExtraer el contenido de las coincidencias.\nRemplazar coincidencias con nuevos valores.\nDividir una cadena de acuerdo a una coincidencia.\n\nUna advertencia antes de continuar: debido a que las expresiones regulares son tan poderosas, es fácil intentar resolver todos los problemas con una sola expresión regular. En palabras de Jamie Zawinski:\n\nCuando se enfrentan a un problema, algunas personas piensan “Lo sé, usaré expresiones regulares.” Ahora tienen dos problemas.\n\nComo advertencia, revisa esta expresión regular que chequea si una dirección de correo electrónico es válida:\n(?:(?:\\r\\n)?[ \\t])*(?:(?:(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t]\n)+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\n\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(\n?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \n\\t]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\0\n31]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\\n](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+\n(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:\n(?:\\r\\n)?[ \\t])*))*|(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z\n|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)\n?[ \\t])*)*\\&lt;(?:(?:\\r\\n)?[ \\t])*(?:@(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\\nr\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[\n \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)\n?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t]\n)*))*(?:,@(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[\n \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*\n)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t]\n)+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*)\n*:(?:(?:\\r\\n)?[ \\t])*)?(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+\n|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\n\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\n\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t\n]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031\n]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](\n?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?\n:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?\n:\\r\\n)?[ \\t])*))*\\&gt;(?:(?:\\r\\n)?[ \\t])*)|(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?\n:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?\n[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)*:(?:(?:\\r\\n)?[ \\t])*(?:(?:(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \n\\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\n\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;\n@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\"\n(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t]\n)*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\n\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?\n:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\n\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*|(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\n\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(\n?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)*\\&lt;(?:(?:\\r\\n)?[ \\t])*(?:@(?:[^()&lt;&gt;@,;\n:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([\n^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\"\n.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\\n]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*(?:,@(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\\n[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\\nr\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \n\\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]\n|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*)*:(?:(?:\\r\\n)?[ \\t])*)?(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\0\n00-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\\n.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,\n;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\"(?\n:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*\n(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\n\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[\n^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]\n]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*\\&gt;(?:(?:\\r\\n)?[ \\t])*)(?:,\\s*(\n?:(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\n\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(\n?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\n\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t\n])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t\n])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?\n:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\n\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*|(?:\n[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\\n]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)*\\&lt;(?:(?:\\r\\n)\n?[ \\t])*(?:@(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"\n()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)\n?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;\n@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*(?:,@(?:(?:\\r\\n)?[\n \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,\n;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t]\n)*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\n\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*)*:(?:(?:\\r\\n)?[ \\t])*)?\n(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\n\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\n\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\n\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])\n*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])\n+|\\Z|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\\n.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z\n|(?=[\\[\"()&lt;&gt;@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*\\&gt;(?:(\n?:\\r\\n)?[ \\t])*))*)?;\\s*)\nEn cierto sentido, este es un ejemplo “patológico” (porque las direcciones de correo electrónico son de verdad sorpresivamente complejas), pero se usa en código real. Mira esta discusión (en inglés) en Stack Overflow http://stackoverflow.com/a/201378 para más detalles.\nNo olvides que estás trabajando en un lenguaje de programación y que tienes otras herramientas a tu disposición. En vez de crear una sola expresión regular compleja, usualmente es más fácil crear una serie de expresiones regulares más simples. Si te atascaste tratando de crear una sola expresión regular que resuelva tu problema, da un paso atrás y piensa cómo podrías dividir el problema en partes más pequeñas. Esto te permitirá ir resolviendo cada desafío antes de moverte al siguiente.\n\n14.3.1 Detectar coincidencias\nPara determinar si un vector de caracteres coincide con un patrón de búsqueda, puedes utilizar str_detect(). Este devuelve un vector lógico del mismo largo que el input:\n\nx &lt;- c(\"manzana\", \"plátano\", \"pera\")\nstr_detect(x, \"e\")\n\n[1] FALSE FALSE  TRUE\n\n\nRecuerda que cuando usas vectores lógicos en un contexto numérico, FALSE (falso) se convierte en 0 y TRUE (verdadero) se convierte en 1. Eso hace que sum() (suma) y mean() (media) sean funciones útiles si quieres responder preguntas sobre coincidencias a lo largo de un vector más extenso:\n\n# ¿Cuántas palabras comunes empiezan con m?\nsum(str_detect(palabras, \"^m\"))\n\n[1] 81\n\n# ¿Qué proporción de palabras comunes terminan con una vocal?\nmean(str_detect(palabras, \"[aáeéiéoéuú]$\"))\n\n[1] 0.546\n\n\nCuando tienes condiciones lógicas complejas, (p. ej., encontrar a o b pero no c, salvo que d) suele ser más fácil combinar múltiples llamadas a str_detect() con operadores lógicos, que tratar de crear una sola expresión regular. Por ejemplo, hay dos maneras de buscar todas las palabras que no contengan ninguna vocal:\n\n# Encuentra todas las palabras que contengan al menos una vocal, y luego niégalo\nsin_vocales_1 &lt;- !str_detect(palabras, \"[aáeéiíoóuúúü]\")\n# Encuentra todas las palabras consistentes solo en consonantes (no vocales)\nsin_vocales_2 &lt;- str_detect(palabras, \"^[^aáeéiíoóuúúü]+$\")\nidentical(sin_vocales_1, sin_vocales_2)\n\n[1] TRUE\n\n\nLos resultados son idénticos; sin embargo, creemos que la primera aproximación es significativamente más fácil de entender. Si tu expresión regular se vuelve extremadamente compleja, trata de dividirla en partes más pequeñas, dale un nombre a cada parte y luego combínalas en operaciones lógicas.\nUn uso común de str_detect() es para seleccionar elementos que coincidan con un patrón. Puedes hacer eso con subdivisiones lógicas o utilizando str_subset(), que es un “envoltorio” (wrapper) de esas operaciones.\n\npalabras[str_detect(palabras, \"x$\")]\n\n[1] \"ex\"\n\nstr_subset(palabras, \"x$\")\n\n[1] \"ex\"\n\n\nEn todo caso, lo más habitual es que tus cadenas de caracteres sean una columna de un data frame y que prefieras utilizar la función filter() (filtrar):\n\ndf &lt;- tibble(\n  palabra = palabras, \n  i = seq_along(palabra)\n)\ndf %&gt;% \n  filter(str_detect(palabras, \"x$\"))\n\n# A tibble: 1 × 2\n  palabra     i\n  &lt;chr&gt;   &lt;int&gt;\n1 ex        338\n\n\nUna varación de str_detect() es str_count() (count = contar): más que un simple sí o no, te indica cuántas coincidencias hay en una cadena:\n\nx &lt;- c(\"manzana\", \"plátano\", \"pera\")\nstr_count(x, \"a\")\n\n[1] 3 1 1\n\n# En promedio, ¿cuántas vocales hay por palabra?\nmean(str_count(palabras, \"[aáeéiíoóuúü]\"))\n\n[1] 2.72\n\n\nEs natural usar str_count() junto con mutate():\n\ndf %&gt;% \n  mutate(\n    vocales = str_count(palabra, \"[aáeéiíoóuúü]\"),\n    consonantes = str_count(palabra, \"[^aáeéiíoóuúü]\")\n  )\n\n# A tibble: 1,000 × 4\n   palabra         i vocales consonantes\n   &lt;chr&gt;       &lt;int&gt;   &lt;int&gt;       &lt;int&gt;\n 1 a               1       1           0\n 2 abril           2       2           3\n 3 acción          3       3           3\n 4 acciones        4       4           4\n 5 acerca          5       3           3\n 6 actitud         6       3           4\n 7 actividad       7       4           5\n 8 actividades     8       5           6\n 9 acto            9       2           2\n10 actual         10       3           3\n# ℹ 990 more rows\n\n\nTen en cuenta que las coincidencias nunca se superponen. Por ejemplo, en \"abababa\", ¿cuántas veces se encontrará una coincidencia con el patrón \"aba\"? Las expresiones regulares dicen que dos, no tres:\n\nstr_count(\"abababa\", \"aba\")\n\n[1] 2\n\nstr_view_all(\"abababa\", \"aba\")\n\nWarning: `str_view()` was deprecated in stringr 1.5.0.\nℹ Please use `str_view_all()` instead.\n\n\n[1] │ &lt;aba&gt;b&lt;aba&gt;\n\n\nToma nota sobre el uso de str_view_all(). Como aprenderás dentro de poco, muchas funciones de stringr vienen en pares: una función trabaja con una sola coincidencia y la otra con todas. La segunda función tendrá el sufijo _all (todas).\n\n\n14.3.2 Ejercicios\n\nPara cada uno de los siguientes desafíos, intenta buscar una solución utilizando tanto una expresión regular simple como una combinación de múltiples llamadas a str_detect().\n\nEncuentra todas las palabras que empiezan o terminan con y.\nEncuentra todas las palabras que empiezan con una vocal y terminan con una consonante.\n¿Existen palabras que tengan todas las vocales?\n\n¿Qué palabra tiene el mayor número de vocales? ¿Qué palabra tiene la mayor proporción de vocales? (Pista: ¿cuál es el denominador?)\n\n\n\n14.3.3 Extraer coincidencias\nPara extraer el texto de una coincidencia utiliza str_extract(). Para mostrar cómo funciona, necesitaremos un ejemplo más complicado. Para ello, usaremos una selección y adaptación al español de las oraciones disponibles originalmente en stringr::sentences y que puedes encontrar en datos::oraciones:\n\nlength(oraciones)\n\n[1] 50\n\nhead(oraciones)\n\n[1] \"Las casas están construidas de ladrillos de arcilla roja.\"\n[2] \"La caja fue arrojada al lado del camión estacionado.\"     \n[3] \"El domingo es la mejor parte de la semana.\"               \n[4] \"Agrega a la cuenta de la tienda hasta el último centavo.\" \n[5] \"Nueve hombres fueron contratados para excavar las ruinas.\"\n[6] \"Pega la hoja en el fondo azul oscuro.\"                    \n\n\nImagina que quieres encontrar todas las oraciones que tengan el nombre de un color. Primero, creamos un vector con nombres de colores y luego lo convertimos en una sola expresión regular:\n\ncolores &lt;- c(\"rojo\", \"amarillo\", \"verde\", \"azul\", \"marrón\")\ncoincidencia_color &lt;- str_c(colores, collapse = \"|\")\ncoincidencia_color\n\n[1] \"rojo|amarillo|verde|azul|marrón\"\n\n\nAhora, podemos seleccionar las oraciones que contienen un color y extraer luego el color para saber de cuál se trata:\n\ntiene_color &lt;- str_subset(oraciones, coincidencia_color)\ncoincidencia &lt;- str_extract(tiene_color, coincidencia_color)\nhead(coincidencia)\n\n[1] \"azul\"   \"azul\"   \"rojo\"   \"azul\"   \"azul\"   \"marrón\"\n\n\nTen en cuenta que str_extract() solo extrae la primera coincidencia. Podemos ver eso de manera sencilla seleccionando primero todas las oraciones que tengan más de una coincidencia:\n\nmas &lt;- oraciones[str_count(oraciones, coincidencia_color) &gt; 1]\nstr_view_all(mas, coincidencia_color)\n\n[1] │ Instalaron &lt;azul&gt;ejos &lt;verde&gt;s en la cocina.\n[2] │ Si ar&lt;rojo&gt; la taza &lt;azul&gt; al suelo se romperá.\n[3] │ Las hojas se vuelven de color &lt;marrón&gt; y &lt;amarillo&gt; en el otoño.\n[4] │ La luz &lt;verde&gt; en la caja &lt;marrón&gt; parpadeaba.\n\nstr_extract(mas, coincidencia_color)\n\n[1] \"azul\"   \"rojo\"   \"marrón\" \"verde\" \n\n\nEste es un patrón de coincidencia común para las funciones de stringr, ya que trabajar con una sola coincidencia te permite utilizar estructuras de datos más simples. Para obtener todas las coincidencias, utiliza str_extract_all(). Esta función devuelve una lista:\n\nstr_extract_all(mas, coincidencia_color)\n\n[[1]]\n[1] \"azul\"  \"verde\"\n\n[[2]]\n[1] \"rojo\" \"azul\"\n\n[[3]]\n[1] \"marrón\"   \"amarillo\"\n\n[[4]]\n[1] \"verde\"  \"marrón\"\n\n\nAprenderás más sobre listas en el capítulo sobre [vectores] y en el sobre [iteración].\nSi utilizas simplify = TRUE (es decir, simplificar = VERDADERO), str_extract_all() devolverá una matriz con las coincidencias más cortas expandidas hasta el largo de las más extensas:\n\nstr_extract_all(mas, coincidencia_color, simplify = TRUE)\n\n     [,1]     [,2]      \n[1,] \"azul\"   \"verde\"   \n[2,] \"rojo\"   \"azul\"    \n[3,] \"marrón\" \"amarillo\"\n[4,] \"verde\"  \"marrón\"  \n\nx &lt;- c(\"a\", \"a b\", \"a b c\")\nstr_extract_all(x, \"[a-z]\", simplify = TRUE)\n\n     [,1] [,2] [,3]\n[1,] \"a\"  \"\"   \"\"  \n[2,] \"a\"  \"b\"  \"\"  \n[3,] \"a\"  \"b\"  \"c\" \n\n\n\n14.3.3.1 Ejercicios\n\nTe habrás dado cuenta que en el ejemplo anterior la expresión regular que utilizamos también devolvió como resultado “arrojo” y “azulejos”, que no son nombres de colores. Modifica la expresión regular para resolver ese problema.\nDe datos::oraciones extrae:\n\nLa primera palabra de cada oración.\nTodas las palabras que terminen en ción.\nTodos los plurales.\n\n\n\n\n\n14.3.4 Coincidencias agrupadas\nAntes en este capítulo hablamos sobre el uso de paréntesis para aclarar la precedencia y las referencias previas al buscar coincidencias. También puedes utilizar los paréntesis para extraer una coincidencia compleja. Por ejemplo, imagina que quieres extraer los sustantivos de una oración. Como heurística, buscaremos cualquier palabra que venga después de un artículo (el, la, un, una, etc.). Definir qué es una palabra en una expresión regular es un poco complicado, así que aquí utilizaremos una aproximación simple: una secuencia de al menos un caracter que no sea un espacio.\n\nsustantivo &lt;- \"(el|la|los|las|lo|un|una|unos|unas) ([^ ]+)\"\n\ntiene_sustantivo &lt;- oraciones %&gt;%\n  str_subset(sustantivo) %&gt;%\n  head(10)\ntiene_sustantivo %&gt;% \n  str_extract(sustantivo)\n\n [1] \"los de\"      \"el camión\"   \"la mejor\"    \"la cuenta\"   \"las ruinas.\"\n [6] \"la hoja\"     \"la cocina.\"  \"la taza\"     \"el tanque.\"  \"el calor\"   \n\n\nstr_extract() nos devuelve la coincidencia completa; str_match() nos entrega cada componente. En vez de un vector de caracteres, devuelve una matriz con una columna para la coincidencia completa y una columna para cada grupo:\n\ntiene_sustantivo %&gt;% \n  str_match(sustantivo)\n\n      [,1]          [,2]  [,3]     \n [1,] \"los de\"      \"los\" \"de\"     \n [2,] \"el camión\"   \"el\"  \"camión\" \n [3,] \"la mejor\"    \"la\"  \"mejor\"  \n [4,] \"la cuenta\"   \"la\"  \"cuenta\" \n [5,] \"las ruinas.\" \"las\" \"ruinas.\"\n [6,] \"la hoja\"     \"la\"  \"hoja\"   \n [7,] \"la cocina.\"  \"la\"  \"cocina.\"\n [8,] \"la taza\"     \"la\"  \"taza\"   \n [9,] \"el tanque.\"  \"el\"  \"tanque.\"\n[10,] \"el calor\"    \"el\"  \"calor\"  \n\n\n(Como era de esperarse, nuestra heurística para detectar sustantivos es pobre, ya que también selecciona adjetivos como “mejor” y preposiciones como “de”).\nSi tus datos están en un tibble, suele ser más fácil utilizar tidyr::extract(). Funciona como str_match() pero requiere ponerle un nombre a las coincidencias, las que luego son puestas en columnas nuevas:\n\ntibble(oracion = oraciones) %&gt;% \n  tidyr::extract(\n    oracion, c(\"articulo\", \"sustantivo\"), \"(el|la|los|las|un|una|unos|unas) ([^ ]+)\", \n    remove = FALSE\n  )\n\n# A tibble: 50 × 3\n   oracion                                                   articulo sustantivo\n   &lt;chr&gt;                                                     &lt;chr&gt;    &lt;chr&gt;     \n 1 Las casas están construidas de ladrillos de arcilla roja. los      de        \n 2 La caja fue arrojada al lado del camión estacionado.      el       camión    \n 3 El domingo es la mejor parte de la semana.                la       mejor     \n 4 Agrega a la cuenta de la tienda hasta el último centavo.  la       cuenta    \n 5 Nueve hombres fueron contratados para excavar las ruinas. las      ruinas.   \n 6 Pega la hoja en el fondo azul oscuro.                     la       hoja      \n 7 Instalaron azulejos verdes en la cocina.                  la       cocina.   \n 8 Si arrojo la taza azul al suelo se romperá.               la       taza      \n 9 Dos peces azules nadaban en el tanque.                    el       tanque.   \n10 El ancho camino brillaba bajo el calor del sol.           el       calor     \n# ℹ 40 more rows\n\n\nAl igual que con str_extract(), si quieres todas las coincidencias para cada cadena, tienes que utilizar str_match_all().\n\n14.3.4.1 Ejercicios\n\nBusca en datos::oraciones todas las palabras que vengan después de un “número”, como “un(o|a)”, “dos”, “tres”, etc. Extrae tanto el número como la palabra.\nEn español a veces se utiliza el guión para unir adjetivos, establecer relaciones entre conceptos o para unir gentilicios (p. ej., teórico-práctico, precio-calidad, franco-porteña). ¿Cómo podrías encontrar esas palabras y separar lo que viene antes y después del guión?\n\n\n\n\n14.3.5 Remplazar coincidencias\nstr_replace() y str_replace_all() te permiten remplazar coincidencias en una nueva cadena. Su uso más simple es para remplazar un patrón con una cadena fija:\n\nx &lt;- c(\"manzana\", \"pera\", \"banana\")\nstr_replace(x, \"[aeiou]\", \"-\")\n\n[1] \"m-nzana\" \"p-ra\"    \"b-nana\" \n\nstr_replace_all(x, \"[aeiou]\", \"-\")\n\n[1] \"m-nz-n-\" \"p-r-\"    \"b-n-n-\" \n\n\nCon str_replace_all() puedes realizar múltiples remplazos a través de un vector cuyos elementos tiene nombre (named vector):\n\nx &lt;- c(\"1 casa\", \"2 autos\", \"3 personas\")\nstr_replace_all(x, c(\"1\" = \"una\", \"2\" = \"dos\", \"3\" = \"tres\"))\n\n[1] \"una casa\"      \"dos autos\"     \"tres personas\"\n\n\nEn vez de hacer remplazos con una cadena fija, puedes utilizar referencias previas para insertar componentes de la coincidencia. En el siguiente código invertimos el orden de la segunda y la tercera palabra:\n\noraciones %&gt;% \n  str_replace(\"([^ ]+) ([^ ]+) ([^ ]+)\", \"\\\\1 \\\\3 \\\\2\") %&gt;% \n  head(5)\n\n[1] \"Las están casas construidas de ladrillos de arcilla roja.\"\n[2] \"La fue caja arrojada al lado del camión estacionado.\"     \n[3] \"El es domingo la mejor parte de la semana.\"               \n[4] \"Agrega la a cuenta de la tienda hasta el último centavo.\" \n[5] \"Nueve fueron hombres contratados para excavar las ruinas.\"\n\n\n\n14.3.5.1 Ejercicios\n\nRemplaza en una cadena todas las barras por barras invertidas.\nImplementa una versón simple de str_to_lower() (a minúsculas) usando replace_all().\nCambia la primera y la última letra en palabras. ¿Cuáles de esas cadenas siguen siendo palabras?\n\n\n\n\n14.3.6 Divisiones\nUsa str_split() para dividir una cadena en partes. Por ejemplo, podemos dividir oraciones en palabras:\n\noraciones %&gt;%\n  head(5) %&gt;% \n  str_split(\" \")\n\n[[1]]\n[1] \"Las\"         \"casas\"       \"están\"       \"construidas\" \"de\"         \n[6] \"ladrillos\"   \"de\"          \"arcilla\"     \"roja.\"      \n\n[[2]]\n[1] \"La\"           \"caja\"         \"fue\"          \"arrojada\"     \"al\"          \n[6] \"lado\"         \"del\"          \"camión\"       \"estacionado.\"\n\n[[3]]\n[1] \"El\"      \"domingo\" \"es\"      \"la\"      \"mejor\"   \"parte\"   \"de\"     \n[8] \"la\"      \"semana.\"\n\n[[4]]\n [1] \"Agrega\"   \"a\"        \"la\"       \"cuenta\"   \"de\"       \"la\"      \n [7] \"tienda\"   \"hasta\"    \"el\"       \"último\"   \"centavo.\"\n\n[[5]]\n[1] \"Nueve\"       \"hombres\"     \"fueron\"      \"contratados\" \"para\"       \n[6] \"excavar\"     \"las\"         \"ruinas.\"    \n\n\nComo cada componente podría tener un número diferente de elementos, esto devuelve una lista. Si estás trabajando con vectores de extensión 1, lo más fácil es extraer el primer elemento de la lista:\n\n\"a|b|c|d\" %&gt;% \n  str_split(\"\\\\|\") %&gt;% \n  .[[1]]\n\n[1] \"a\" \"b\" \"c\" \"d\"\n\n\nOtra opción es, al igual que con otras funciones de stringr que devuelven una lista, utilizar simplify = TRUE para obtener una matriz:\n\noraciones %&gt;%\n  head(5) %&gt;% \n  str_split(\" \", simplify = TRUE)\n\n     [,1]     [,2]      [,3]     [,4]          [,5]    [,6]        [,7]    \n[1,] \"Las\"    \"casas\"   \"están\"  \"construidas\" \"de\"    \"ladrillos\" \"de\"    \n[2,] \"La\"     \"caja\"    \"fue\"    \"arrojada\"    \"al\"    \"lado\"      \"del\"   \n[3,] \"El\"     \"domingo\" \"es\"     \"la\"          \"mejor\" \"parte\"     \"de\"    \n[4,] \"Agrega\" \"a\"       \"la\"     \"cuenta\"      \"de\"    \"la\"        \"tienda\"\n[5,] \"Nueve\"  \"hombres\" \"fueron\" \"contratados\" \"para\"  \"excavar\"   \"las\"   \n     [,8]      [,9]           [,10]    [,11]     \n[1,] \"arcilla\" \"roja.\"        \"\"       \"\"        \n[2,] \"camión\"  \"estacionado.\" \"\"       \"\"        \n[3,] \"la\"      \"semana.\"      \"\"       \"\"        \n[4,] \"hasta\"   \"el\"           \"último\" \"centavo.\"\n[5,] \"ruinas.\" \"\"             \"\"       \"\"        \n\n\nTambién puedes indicar un número máximo de elementos:\n\ncampos &lt;- c(\"Nombre: Hadley\", \"País: NZ\", \"Edad: 35\")\ncampos %&gt;% str_split(\": \", n = 2, simplify = TRUE)\n\n     [,1]     [,2]    \n[1,] \"Nombre\" \"Hadley\"\n[2,] \"País\"   \"NZ\"    \n[3,] \"Edad\"   \"35\"    \n\n\nEn vez de dividir una cadena según patrones, puedes hacerlo según caracter, línea, oración o palabra. Para ello, puedes utilizar la función boundary() (límite). En el siguiente ejemplo la división se hace por palabra (word):\n\nx &lt;- \"Esta es una oración. Esta es otra oración.\"\nstr_view_all(x, boundary(\"word\"))\n\n[1] │ &lt;Esta&gt; &lt;es&gt; &lt;una&gt; &lt;oración&gt;. &lt;Esta&gt; &lt;es&gt; &lt;otra&gt; &lt;oración&gt;.\n\nstr_split(x, \" \")[[1]]\n\n[1] \"Esta\"     \"es\"       \"una\"      \"oración.\" \"Esta\"     \"es\"       \"otra\"    \n[8] \"oración.\"\n\nstr_split(x, boundary(\"word\"))[[1]]\n\n[1] \"Esta\"    \"es\"      \"una\"     \"oración\" \"Esta\"    \"es\"      \"otra\"   \n[8] \"oración\"\n\n\n\n14.3.6.1 Ejercicios\n\nDivide una cadena como \"manzanas, peras y bananas\" en elementos individuales.\n¿Por qué es mejor dividir utilizando boundary(\"word\") en vez de \" \"?\n¿Qué pasa si dividimos con una cadena vacía (\"\")? Experimenta y luego lee la documentación\n\n\n\n\n14.3.7 Buscar coincidencias\nstr_locate() y str_locate_all() te indican la posición inicial y final de una coincidencia. Son particularmente útiles cuando ninguna otra función hace exactamente lo que quieres. Puedes utilizar str_locate() para encontrar los patrones de coincidencia y str_sub() para extraerlos y/o modificarlos."
  },
  {
    "objectID": "14-strings.html#otro-tipo-de-patrones",
    "href": "14-strings.html#otro-tipo-de-patrones",
    "title": "14  Cadenas de caracteres",
    "section": "14.4 Otro tipo de patrones",
    "text": "14.4 Otro tipo de patrones\nCuando utilizas un patrón que es una cadena, este automáticamente es encapsulado en la función regex() (regex es la forma abreviada de regular expression, es decir, expresión regular):\n\n# La manera regular en que escribimos el patrón\nstr_view(frutas, \"nana\")\n# Es un atajo de\nstr_view(frutas, regex(\"nana\"))\n\nPuedes utilizar los otros argumentos de regex() para controlar los detalles de la coincidencia:\n\nignore_case = TRUE permite que la búsqueda coincida tanto con caracteres en mayúscula como en minúscula. Este argumento siempre utiliza los parámetros de tu locale.\n\nbananas &lt;- c(\"banana\", \"Banana\", \"BANANA\")\nstr_view(bananas, \"banana\")\n\n[1] │ &lt;banana&gt;\n\nstr_view(bananas, regex(\"banana\", ignore_case = TRUE))\n\n[1] │ &lt;banana&gt;\n[2] │ &lt;Banana&gt;\n[3] │ &lt;BANANA&gt;\n\n\nmultiline = TRUE permite que ^ y $ coincidan con el inicio y fin de cada línea, en vez del inicio y fin de la cadena completa.\n\nx &lt;- \"Línea 1\\nLínea 2\\nLínea 3\"\nstr_extract_all(x, \"^Línea\")[[1]]\n\n[1] \"Línea\"\n\nstr_extract_all(x, regex(\"^Línea\", multiline = TRUE))[[1]]\n\n[1] \"Línea\" \"Línea\" \"Línea\"\n\n\ncomments = TRUE te permite utilizar comentarios y espacios en blanco para hacer más entendibles las expresiones regulares complejas. Los espacios son ignorados, al igual que todo lo que está después de #. Para coincidir un espacio de manera literal, tendrías que “escaparlo: \"\\\\ \".\n\ntelefono &lt;- regex(\"\n  \\\\(?     # paréntesis inicial opcional\n  (\\\\d{3}) # código de área\n  [) -]?   # paréntesis, espacio o guión inicial opcional\n  (\\\\d{3}) # otros tres números\n  [ -]?    # espacio o guión opcional\n  (\\\\d{3}) # otros tres números\n  \", comments = TRUE)\n\nstr_match(\"514-791-8141\", telefono)\n\n     [,1]          [,2]  [,3]  [,4] \n[1,] \"514-791-814\" \"514\" \"791\" \"814\"\n\n\ndotall = TRUE permite que . coincida con todo, incluidos los saltos de línea (\\n).\n\nExisten otras tres funciones que puedes utilizar en vez de regex():\n\nfixed(): busca una coincidencia exacta de la secuencia de bytes especificada. Ignora todas las expresiones regulares especiales y opera a un nivel muy bajo. Esto te permite evitar formas de “escapado” complejas y puede ser mucho más rápida que las expresiones regulares. La comparación utilizando microbenchmark muestra que fixed() es casi dos veces más rápida.\n\n#install.packages(microbenchmark)\nmicrobenchmark::microbenchmark(\n  fixed = str_detect(oraciones, fixed(\"la\")),\n  regex = str_detect(oraciones, \"la\"),\n  times = 20\n)\n\nUnit: microseconds\n  expr    min     lq     mean  median      uq     max neval cld\n fixed 18.737 19.639 32.65360 20.2145 21.7845 240.371    20   a\n regex 20.707 21.161 27.10185 22.5515 26.8100  82.757    20   a\n\n\nIMPORTANTE: ten precaución al utilizar fixed() con datos que no estén en inglés. Puede causar problemas porque muchas veces existen múltiples formas de representar un mismo caracter. Por ejemplo, hay dos formas de difinir “á”: como un solo caracter o como una “a” con un acento:\n\na1 &lt;- \"\\u00e1\"\na2 &lt;- \"a\\u0301\"\nc(a1, a2)\n\n[1] \"á\" \"á\"\n\na1 == a2\n\n[1] FALSE\n\n\nAmbas se renderean de manera idéntica, pero como están definidas de manera distinta, fixed() no encuentra una coincidencia. En su lugar, puedes utilizar coll(), que definiremos a continuación, ya que respeta las reglas humanas de comparación de caracteres:\n\nstr_detect(a1, fixed(a2))\n\n[1] FALSE\n\nstr_detect(a1, coll(a2))\n\n[1] TRUE\n\n\ncoll(): compara cadenas usando reglas de secuenciación (collation) estándar. Esto es útil para buscar coincidencias que sean insensibles a mayúsculas y minúsculas. Ten en cuenta que coll() incluye un parámetro para el locale, Lamentablemente, se utilizan diferentes reglas en diferentes partes del mundo.\n\n# Esto quiere decir que también tienes que prestar atención a esas \n# diferencias al buscar coincidencias insensibles a mayúsculas y\n# minúsculas\ni &lt;- c(\"I\", \"İ\", \"i\", \"ı\")\ni\n\n[1] \"I\" \"İ\" \"i\" \"ı\"\n\nstr_subset(i, coll(\"i\", ignore_case = TRUE))\n\n[1] \"I\" \"i\"\n\nstr_subset(i, coll(\"i\", ignore_case = TRUE, locale = \"tr\"))\n\n[1] \"İ\" \"i\"\n\n\nTanto fixed() como regex() tienen argumentos para ignorar la diferencia entre mayúsculas y minúsculas (ignore_case); sin embargo, no te permiten elegir tu locale: siempre utilizan el que está definido por defecto. Puedes ver cuál se está usando con el siguiente código. Pronto hablaremos más sobre el paquete stringi.\n\nstringi::stri_locale_info()\n\n$Language\n[1] \"en\"\n\n$Country\n[1] \"CA\"\n\n$Variant\n[1] \"\"\n\n$Name\n[1] \"en_CA\"\n\n\nUna desventaja de coll() es la velocidad. Debido a que las reglas para reconocer qué caracteres son iguales suelen ser complicadas, coll() es relativamente más lenta al compararla con regex() y fixed().\nComo viste con str_split(), puedes utilizar boundary() para coincidir límites. También puedes utilizarla con otras funciones:\n\nx &lt;- \"Esta es una oración.\"\nstr_view_all(x, boundary(\"word\"))\n\n[1] │ &lt;Esta&gt; &lt;es&gt; &lt;una&gt; &lt;oración&gt;.\n\nstr_extract_all(x, boundary(\"word\"))\n\n[[1]]\n[1] \"Esta\"    \"es\"      \"una\"     \"oración\"\n\n\n\n\n14.4.1 Ejercicios\n\n¿Cómo buscarías todas las cadenas que contienen \\ con regex() vs. con fixed()?\n¿Cuáles son las cinco palabras más comunes en oraciones?"
  },
  {
    "objectID": "14-strings.html#otros-usos-de-las-expresiones-regulares.",
    "href": "14-strings.html#otros-usos-de-las-expresiones-regulares.",
    "title": "14  Cadenas de caracteres",
    "section": "14.5 Otros usos de las expresiones regulares.",
    "text": "14.5 Otros usos de las expresiones regulares.\nExisten dos funciones útiles en R base que también utilizan expresiones regulares:\n\napropos() busca todos los objetos disponibles en el ambiente global (global environment). Esto es útil si no recuerdas bien el nombre de una función.\n\napropos(\"replace\")\n\n[1] \"%+replace%\"       \"replace\"          \"replace_na\"       \"setReplaceMethod\"\n[5] \"str_replace\"      \"str_replace_all\"  \"str_replace_na\"   \"theme_replace\"   \n\n\ndir() entrega una lista con todos los archivos en un directorio. El argumento pattern recibe una expresión regular y retorna solo los nombres de archivos que coinciden con ese patrón. Por ejemplo, puedes encontrar todos los archivos de R Markdown en el directorio actual con:\n\nhead(dir(pattern = \"\\\\.Rmd$\"))\n\ncharacter(0)\n\n\n(Si te resulta más cómodo trabajar con “globs”, es decir, especificar los nombres de archivo utilizando comodines, como en *.Rmd, puedes convertirlos a expresiones regulares con la función glob2rx())"
  },
  {
    "objectID": "14-strings.html#stringi",
    "href": "14-strings.html#stringi",
    "title": "14  Cadenas de caracteres",
    "section": "14.6 stringi",
    "text": "14.6 stringi\nstringr está construido sobre la base del paquete stringi. stringr es útil cuando estás aprendiendo, ya que presenta un set mínimo de funciones, que han sido elegidas cuidadosamente para manejar las funciones de manipulación de cadenas más comunes. stringi, por su parte, está diseñado para ser comprehensivo. Contiene casi todas las funciones que podrías necesitar: stringi tiene 256 funciones, frente a las 59 de stringr.\nSi en algún momento te encuentras en dificultades para hacer algo en stringr , vale la pena darle una mirada a stringi. Ambos paquetes funcionan de manera muy similar, por lo que deberías poder traducir tu conocimiento sobre stringr de manera natural. La principal diferencia es el prefijo: str_ vs. stri_.\n\n14.6.1 Ejercicios\n\nBusca la función de stringi que:\n\nCuenta el número de palabras.\nBusca cadenas duplicadas.\nGenera texto aleatorio.\n\n¿Cómo puedes controlar qué lengua usa stri_sort() para ordenar?"
  },
  {
    "objectID": "15-factors.html#introducción",
    "href": "15-factors.html#introducción",
    "title": "15  Factores",
    "section": "15.1 Introducción",
    "text": "15.1 Introducción\nEn R, los factores se usan para trabajar con variables categóricas, es decir, variables que tienen un conjunto fijo y conocido de valores posibles. También son útiles cuando quieres mostrar vectores de caracteres en un orden no alfabético.\nHistóricamente, los factores eran más sencillos de trabajar que los caracteres. Como resultado, muchas de las funciones de R base automáticamente convierten los caracteres a factores. Esto significa que, a menudo, los factores aparecen en lugares donde no son realmente útiles. Afortunadamente, no tienes que preocuparte de eso en el tidyverse y puedes concentrarte en situaciones en las que los factores son genuinamente útiles.\n\n15.1.1 Prerrequisitos\nPara trabajar con factores, vamos a usar el paquete forcats, que es parte del tidyverse. Este paquete provee herramientas para lidiar con variables categóricas (¡y es un anagrama de factores en inglés!) y ofrece un amplio rango de ayudas para trabajar con factores.\n\nlibrary(tidyverse)\nlibrary(datos)\n\n\n\n15.1.2 Aprendiendo más\nSi quieres aprender más sobre factores, te recomendamos leer el artículo de Amelia McNamara y Nicholas Horton, Wrangling categorical data in R (el nombre significa Domando/Manejando Datos Categóricos en R). Este artículo cuenta parte de la historia discutida en stringsAsFactors: An unauthorized biography (del inglés cadenasComoFactores: Una Biografía No Autorizada) y stringsAsFactors = &lt;sigh&gt; (del inglés cadenasComoFactores = &lt;suspiro&gt;), y compara las propuestas tidy para los datos categóricos demostrados en este libro, en comparación a los métodos de R base. Una versión temprana de este artículo ayudó a motivar y definir el alcance del paquete forcats. ¡Gracias Amelia y Nick!"
  },
  {
    "objectID": "15-factors.html#creando-factores",
    "href": "15-factors.html#creando-factores",
    "title": "15  Factores",
    "section": "15.2 Creando factores",
    "text": "15.2 Creando factores\nImagina que tienes una variable que registra meses:\n\nx1 &lt;- c(\"Dic\", \"Abr\", \"Ene\", \"Mar\")\n\nUsar una cadena de caracteres (o string, en inglés) para guardar esta variable tiene dos problemas:\n\nSolo hay doce meses posibles y no hay nada que te resguarde de errores de tipeo:\n\n\nx2 &lt;- c(\"Dic\", \"Abr\", \"Eme\", \"Mar\")\n\n\nNo se ordena de una forma útil:\n\n\nsort(x1)\n\n[1] \"Abr\" \"Dic\" \"Ene\" \"Mar\"\n\n\nPuedes solucionar ambos problemas con un factor. Para crearlo, debes empezar definiendo una lista con los niveles válidos:\n\nniveles_meses &lt;- c(\n  \"Ene\", \"Feb\", \"Mar\", \"Abr\", \"May\", \"Jun\",\n  \"Jul\", \"Ago\", \"Sep\", \"Oct\", \"Nov\", \"Dic\"\n)\n\nAhora puedes crear un factor:\n\ny1 &lt;- factor(x1, levels = niveles_meses)\ny1\n\n[1] Dic Abr Ene Mar\nLevels: Ene Feb Mar Abr May Jun Jul Ago Sep Oct Nov Dic\n\nsort(y1)\n\n[1] Ene Mar Abr Dic\nLevels: Ene Feb Mar Abr May Jun Jul Ago Sep Oct Nov Dic\n\n\nCualquier valor no fijado en el conjunto será convertido a NA de forma silenciosa:\n\ny2 &lt;- factor(x2, levels = niveles_meses)\ny2\n\n[1] Dic  Abr  &lt;NA&gt; Mar \nLevels: Ene Feb Mar Abr May Jun Jul Ago Sep Oct Nov Dic\n\n\nSi quieres una advertencia, puedes usar readr::parse_factor() (segmentar un factor, en inglés):\n\ny2 &lt;- parse_factor(x2, levels = niveles_meses)\n\nWarning: 1 parsing failure.\nrow col           expected actual\n  3  -- value in level set    Eme\n\n\nSi omites los niveles, se van a definir a partir de los datos en orden alfabético:\n\nfactor(x1)\n\n[1] Dic Abr Ene Mar\nLevels: Abr Dic Ene Mar\n\n\nA veces es preferible que el orden de los niveles se corresponda con su primera aparición en los datos. Puedes hacer esto cuando creas el factor, al definir los niveles con unique(x) único) o después con fct_inorder() (factores en orden):\n\nf1 &lt;- factor(x1, levels = unique(x1))\nf1\n\n[1] Dic Abr Ene Mar\nLevels: Dic Abr Ene Mar\n\nf2 &lt;- x1 %&gt;% factor() %&gt;% fct_inorder()\nf2\n\n[1] Dic Abr Ene Mar\nLevels: Dic Abr Ene Mar\n\n\nSi alguna vez necesitas acceso directo al conjunto de niveles válidos, puedes hacerlo con levels() (niveles):\n\nlevels(f2)\n\n[1] \"Dic\" \"Abr\" \"Ene\" \"Mar\""
  },
  {
    "objectID": "15-factors.html#encuesta-social-general",
    "href": "15-factors.html#encuesta-social-general",
    "title": "15  Factores",
    "section": "15.3 Encuesta Social General",
    "text": "15.3 Encuesta Social General\nPor el resto del capítulo, nos vamos a concentrar en datos::encuesta. Esta es la versión traducida al español de un conjunto de datos de ejemplo de la General Social Survey, una encuesta realizada en Estados Unidos desde hace mucho tiempo, conducida por la organización de investigación independiente llamada NORC, en la Universidad de Chicago. La encuesta tiene miles de preguntas, así que en el conjunto de datos hemos seleccionado aquellas que ilustran algunos de los desafíos comunes que encontrarás al trabajar con factores.\n\nencuesta\n\n# A tibble: 21,483 × 9\n    anio estado_civil  edad raza  ingreso partido religion denominacion horas_tv\n   &lt;int&gt; &lt;fct&gt;        &lt;int&gt; &lt;fct&gt; &lt;fct&gt;   &lt;fct&gt;   &lt;fct&gt;    &lt;fct&gt;           &lt;int&gt;\n 1  2000 Nunca se ha…    26 Blan… 8000 -… Ind, p… Protest… Bautistas d…       12\n 2  2000 Divorciado      48 Blan… 8000 -… No fue… Protest… Bautista, n…       NA\n 3  2000 Viudo           67 Blan… No apl… Indepe… Protest… No denomina…        2\n 4  2000 Nunca se ha…    39 Blan… No apl… Ind, p… Cristia… No aplica           4\n 5  2000 Divorciado      25 Blan… No apl… No fue… Ninguna  No aplica           1\n 6  2000 Casado          25 Blan… 20000 … Fuerte… Protest… Bautistas d…       NA\n 7  2000 Nunca se ha…    36 Blan… 25000 … No fue… Cristia… No aplica           3\n 8  2000 Divorciado      44 Blan… 7000 -… Ind, p… Protest… Sínodo lute…       NA\n 9  2000 Casado          44 Blan… 25000 … No fue… Protest… Otra                0\n10  2000 Casado          47 Blan… 25000 … Fuerte… Protest… Bautistas d…        3\n# ℹ 21,473 more rows\n\n\n(Recuerda que como este conjunto de datos está provisto por un paquete, puedes obtener más información de las variables con ?encuesta.)\nCuando los factores están almacenados en un tibble no puedes ver sus niveles tan fácilmente. Una forma de verlos es con count() (contar):\n\nencuesta %&gt;%\n  count(raza)\n\n# A tibble: 3 × 2\n  raza       n\n  &lt;fct&gt;  &lt;int&gt;\n1 Otra    1959\n2 Negra   3129\n3 Blanca 16395\n\n\nO con un gráfico de barras:\n\nggplot(encuesta, aes(raza)) +\n  geom_bar()\n\n\n\n\nPor defecto, ggplot2 retira los niveles que no tienen valores. Puedes forzarlos para que se visualicen con:\n\nggplot(encuesta, aes(raza)) +\n  geom_bar() +\n  scale_x_discrete(drop = FALSE)\n\n\n\n\nEstos niveles representan valores válidos que simplemente no tuvieron ocurrencias en este dataset. Para mostrarlos, en dplyr::count() agrega el argumento .drop con la opción FALSE.\n\nencuesta %&gt;% \n  count(raza, \n        .drop = FALSE)\n\n# A tibble: 4 × 2\n  raza          n\n  &lt;fct&gt;     &lt;int&gt;\n1 Otra       1959\n2 Negra      3129\n3 Blanca    16395\n4 No aplica     0\n\n\nCuando se trabaja con factores, las dos operaciones más comunes son cambiar el orden de los niveles y cambiar sus valores. Estas operaciones se describen en las siguientes secciones.\n\n15.3.1 Ejercicios\n\nExplora la distribución de ingreso. ¿Qué hace que el gráfico de barras por defecto sea tan difícil de comprender? ¿Cómo podrías mejorarlo?\n¿Cuál es la religion más común en esta encuesta? ¿Cuál es el partido más común?\n¿A qué religion se aplica cada denominacion? ¿Cómo puedes descubrirlo con una tabla? ¿Cómo lo puedes descubrir con una visualización?"
  },
  {
    "objectID": "15-factors.html#modificar-el-orden-de-los-factores",
    "href": "15-factors.html#modificar-el-orden-de-los-factores",
    "title": "15  Factores",
    "section": "15.4 Modificar el orden de los factores",
    "text": "15.4 Modificar el orden de los factores\nA menudo resulta útil cambiar el orden de los niveles de factores en una visualización. Por ejemplo, imagina que quieres explorar el número promedio de horas consumidas mirando televisión por día, para cada religión:\n\nresumen_religion &lt;- encuesta %&gt;%\n  group_by(religion) %&gt;%\n  summarise(\n    edad = mean(edad, na.rm = TRUE),\n    horas_tv = mean(horas_tv, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(resumen_religion, aes(horas_tv, religion)) + geom_point()\n\n\n\n\nEste gráfico resulta dificil de interpretar porque no hay un patrón general. Podemos mejorarlo al ordenar los niveles de religion usando fct_reorder() ( reordenar factores). fct_reorder() requiere tres argumentos:\n\nf, el factor cuyos niveles quieres modificar.\nx, un vector numérico que quieres usar para reordenar los niveles.\nOpcionalmente, fun, una función que se usa si hay múltiples valores de x para cada valor de f. El valor por defecto es median (mediana).\n\n\nggplot(resumen_religion, aes(horas_tv, fct_reorder(religion, horas_tv))) +\n  geom_point()\n\n\n\n\nReordenar la columna religión (religion) hace que sea más sencillo ver que las personas en la categoría “No sabe” ven más televisión, mientras que “Hinduismo” y “Otra religión oriental” ven mucho menos.\nCuando haces transformaciones más complicadas, recomendamos que las remuevas de aes() hacia un paso de transformación separado usando mutate(). Por ejemplo, puedes reescribir el gráfico anterior de la siguiente forma:\n\nresumen_religion %&gt;%\n  mutate(religion = fct_reorder(religion, horas_tv)) %&gt;%\n  ggplot(aes(horas_tv, religion)) +\n  geom_point()\n\n¿Qué sucede si creamos un gráfico para observar cómo varía la edad promedio para cada ingreso reportado?\n\nresumen_ingreso &lt;- encuesta %&gt;%\n  group_by(ingreso) %&gt;%\n  summarise(\n    edad = mean(edad, na.rm = TRUE),\n    horas_tv = mean(horas_tv, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(resumen_ingreso, aes(edad, fct_reorder(ingreso, edad))) + geom_point()\n\n\n\n\nEn ete caso, ¡reordenar los niveles arbitrariamente no es una buena idea! Eso es porque ingreso ya tiene un orden basado en un principio determinado, con el cual no deberíamos meternos. Reserva fct_reorder() para factores cuyos niveles están ordenados arbitrariamente.\nSin embargo, sí tiene sentido mover “No Aplica” al frente, junto a los otros niveles especiales. Puedes usar fct_relevel() (cambiar niveles). Esta función recibe como argumento un factor, f y luego cualquier número de niveles que quieras mover al principio de la línea.\n\nggplot(resumen_ingreso, aes(edad, fct_relevel(ingreso, \"No aplica\"))) +\n  geom_point()\n\n\n\n\n¿Por qué crees que la edad promedio para “No aplica” es tan alta?\nEs otro el tipo de reordenamiento que resulta útil cuando estás coloreando las líneas de un gráfico. fct_reorder2() reordena el factor mediante los valores y asociados con los valores x más grandes. Esto hace que el gráfico sea más sencillo de leer, porque los colores de líneas se ajustan con la leyenda.\n\npor_edad &lt;- encuesta %&gt;%\n  filter(!is.na(edad)) %&gt;%\n  count(edad, estado_civil) %&gt;%\n  group_by(edad) %&gt;%\n  mutate(prop = n / sum(n))\n\nggplot(por_edad, aes(edad, prop, colour = estado_civil)) +\n  geom_line(na.rm = TRUE)\n\n\n\nggplot(por_edad, aes(edad, prop, colour = fct_reorder2(estado_civil, edad, prop))) +\n  geom_line() +\n  labs(colour = \"estado_civil\")\n\n\n\n\nFinalmente, para los gráficos de barra puedes usar fct_infreq() (frecuencia incremental de factores) para ordenar los niveles incrementalmente según su frecuencia: este es el ordenamiento más sencillo porque no requiere de variables adicionales. Puedes querer combinarlo con fct_rev() (invertir factores).\n\nencuesta %&gt;%\n  mutate(estado_civil = estado_civil %&gt;% fct_infreq() %&gt;% fct_rev()) %&gt;%\n  ggplot(aes(estado_civil)) +\n  geom_bar()\n\n\n\n\n\n15.4.1 Ejercicios\n\nHay algunos números sospechosamente grandes en horas_tv. ¿Es la media un buen resumen?\nIdentifica para cada factor en encuesta si el orden de los niveles es arbitrario o responde a algún principio.\n¿Por qué mover “No aplica” al inicio de los niveles lo llevó al final del gráfico?"
  },
  {
    "objectID": "15-factors.html#modificar-los-niveles-de-los-factores",
    "href": "15-factors.html#modificar-los-niveles-de-los-factores",
    "title": "15  Factores",
    "section": "15.5 Modificar los niveles de los factores",
    "text": "15.5 Modificar los niveles de los factores\nMás poderoso que cambiar el orden de los niveles es cambiar sus valores. Esto te permite clarificar etiquetas para publicación y colapsar niveles para visualizaciones de alto nivel. La herramienta más general y más poderosa es fct_recode() (recodificar factores). Esta función te permite recodificar o cambiar el valor de cada nivel. Por ejemplo, toma la columna encuesta$partido:\n\nencuesta %&gt;% count(partido)\n\n# A tibble: 10 × 2\n   partido                        n\n   &lt;fct&gt;                      &lt;int&gt;\n 1 Sin respuesta                154\n 2 No sabe                        1\n 3 Otro partido                 393\n 4 Fuertemente republicano     2314\n 5 No fuertemente republicano  3032\n 6 Ind, pro rep                1791\n 7 Independiente               4119\n 8 Ind, pro dem                2499\n 9 No fuertemente demócrata    3690\n10 Fuertemente demócrata       3490\n\n\nLos niveles son concisos e inconsistentes. Modifiquémoslos un poco para que sean más largos y para poder usar una construcción paralela.\n\nencuesta %&gt;%\n  mutate(partido = fct_recode(partido,\n    \"Republicano duro\" = \"Fuertemente republicano\",\n    \"Republicano moderado\" = \"No fuertemente republicano\",\n    \"Independiente pro republicano\" = \"Ind, pro rep\",\n    \"Independiente pro demócrata\" = \"Ind, pro dem\",\n    \"Demócrata moderado\" = \"No fuertemente demócrata\",\n    \"Demócrata duro\" = \"Fuertemente demócrata\"\n  )) %&gt;%\n  count(partido)\n\n# A tibble: 10 × 2\n   partido                           n\n   &lt;fct&gt;                         &lt;int&gt;\n 1 Sin respuesta                   154\n 2 No sabe                           1\n 3 Otro partido                    393\n 4 Republicano duro               2314\n 5 Republicano moderado           3032\n 6 Independiente pro republicano  1791\n 7 Independiente                  4119\n 8 Independiente pro demócrata    2499\n 9 Demócrata moderado             3690\n10 Demócrata duro                 3490\n\n\nfct_recode() no modificará los niveles que no han sido mencionados explícitamente y te advertirá si accidentalmente te refieres a un nivel que no existe.\nPara combinar grupos, puedes asignar múltiples niveles viejos al mismo nivel nuevo:\n\nencuesta %&gt;%\n  mutate(partido = fct_recode(partido,\n    \"Republicano duro\" = \"Fuertemente republicano\",\n    \"Republicano moderado\" = \"No fuertemente republicano\",\n    \"Independiente pro republicano\" = \"Ind, pro rep\",\n    \"Independiente pro demócrata\" = \"Ind, pro dem\",\n    \"Demócrata moderado\" = \"No fuertemente demócrata\",\n    \"Demócrata duro\" = \"Fuertemente demócrata\",\n    \"Otro\" = \"Sin respuesta\",\n    \"Otro\" = \"No sabe\",\n    \"Otro\" = \"Otro partido\"\n  )) %&gt;%\n  count(partido)\n\n# A tibble: 8 × 2\n  partido                           n\n  &lt;fct&gt;                         &lt;int&gt;\n1 Otro                            548\n2 Republicano duro               2314\n3 Republicano moderado           3032\n4 Independiente pro republicano  1791\n5 Independiente                  4119\n6 Independiente pro demócrata    2499\n7 Demócrata moderado             3690\n8 Demócrata duro                 3490\n\n\nDebes usar esta técnica con cuidado: si agrupas categorías que son realmente diferentes, obtendrás resultados confusos y/o engañosos.\nSi quieres colapsar muchos niveles, fct_collapse() (colapsar factores) es una variante muy útil de fct_recode(). Para cada nueva variable puedes proveer un vector de niveles viejos:\n\nencuesta %&gt;%\n  mutate(partido = fct_collapse(partido,\n    otro = c(\"Sin respuesta\", \"No sabe\", \"Otro partido\"),\n    republicano = c(\"Fuertemente republicano\", \"No fuertemente republicano\"),\n    independiente = c(\"Ind, pro rep\", \"Independiente\", \"Ind, pro dem\"),\n    demócrata = c(\"No fuertemente demócrata\", \"Fuertemente demócrata\")\n  )) %&gt;%\n  count(partido)\n\n# A tibble: 4 × 2\n  partido           n\n  &lt;fct&gt;         &lt;int&gt;\n1 otro            548\n2 republicano    5346\n3 independiente  8409\n4 demócrata      7180\n\n\nA veces, simplemente quieres agrupar todos los grupos pequeños para simplificar un gráfico o tabla. Ese es un trabajo para fct_lump() (agrupar factores):\n\nencuesta %&gt;%\n  mutate(religion = fct_lump(religion, other_level = \"Otra\")) %&gt;%\n  count(religion)\n\n# A tibble: 2 × 2\n  religion        n\n  &lt;fct&gt;       &lt;int&gt;\n1 Protestante 10846\n2 Otra        10637\n\n\nEl comportamiento por defecto es agrupar los grupos pequeños de forma progresiva, asegurando que la agregación continúa siendo el grupo más pequeño. En este caso, esto no resulta demasiado útil: es cierto que la mayoría de los estadounidenses en esta encuesta son protestantes, pero probablemente hemos colapsado en exceso.\nEn cambio, podemos usar el parámetro n para especificar cuántos grupos (excluyendo otros) queremos colapsar:\n\nencuesta %&gt;%\n  mutate(religion = fct_lump(religion, n = 10, other_level = \"Otra\")) %&gt;%\n  count(religion, sort = TRUE) %&gt;%\n  print(n = Inf)\n\n# A tibble: 10 × 2\n   religion                   n\n   &lt;fct&gt;                  &lt;int&gt;\n 1 Protestante            10846\n 2 Católica                5124\n 3 Ninguna                 3523\n 4 Cristiana                689\n 5 Otra                     458\n 6 Judía                    388\n 7 Budismo                  147\n 8 Inter o no confesional   109\n 9 Musulmana/Islam          104\n10 Cristiana ortodoxa        95\n\n\n\n15.5.1 Ejercicios\n\n¿Cómo han cambiado en el tiempo las proporciones de personas que se identifican como demócratas, republicanas e independientes?\n¿Cómo podrías colapsar ingreso en un grupo más pequeño de categorías?"
  },
  {
    "objectID": "16-datetimes.html#introducción",
    "href": "16-datetimes.html#introducción",
    "title": "16  Fechas y horas",
    "section": "16.1 Introducción",
    "text": "16.1 Introducción\nEste capítulo te mostrará cómo trabajar con fechas y horas en R. A primera vista, esto parece sencillo. Las usas en todo momento en tu vida regular y no parecen causar demasiada confusión. Sin embargo, cuanto más aprendes de fechas y horas, más complicadas se vuelven. Para prepararnos, intenta estas preguntas sencillas:\n\n¿Todos los años tienen 365 días?\n¿Todos los días tienen 24 horas?\n¿Cada minuto tiene 60 segundos?\n\nEstamos seguros que sabes que no todos los años tienen 365 días, ¿pero acaso conoces la regla entera para determinar si un año es bisiesto? (Tiene tres partes, de hecho). Puedes recordar que muchas partes del mundo usan horarios de verano, así que algunos días tienen 23 horas y otros tienen 25. Puede ser que no supieras que algunos minutos tienen 61 segundos, porque de vez en cuando se agregan segundos adicionales ya que la rotación de la tierra se hace cada vez más lenta.\nLas fechas y las horas son complicadas porque tienen que reconciliar dos fenómenos físicos (la rotación de la Tierra y su órbita alrededor del sol), con todo un conjunto de fenómenos geopolíticos que incluyen a los meses, los husos horarios y los horarios de verano. Este capítulo no te enseñará cada detalle sobre fechas y horas, pero te dará un sólido fundamento de habilidades prácticas que te ayudarán con los desafíos más comunes de análisis de datos.\n\n16.1.1 Requisitos previos\nEste capítulo se centra en el paquete lubridate, que simplifica el trabajo con fechas y horas en R. lubridate no es parte de los paquetes centrales de tidyverse porque solo se necesita al trabajar con fechas/horas. A su vez, necesitaremos los datos sobre vuelos contenidos en el paquete datos.\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(datos)"
  },
  {
    "objectID": "16-datetimes.html#creando-fechashoras",
    "href": "16-datetimes.html#creando-fechashoras",
    "title": "16  Fechas y horas",
    "section": "16.2 Creando fechas/horas",
    "text": "16.2 Creando fechas/horas\nHay tres tipos de datos de fechas/horas que se refieren a un instante en el tiempo:\n\nUna fecha o date. Un tibble lo imprime como &lt;date&gt;.\nUna hora o time dentro de un día. Los tibbles lo imprimen como &lt;time&gt;.\nUna fecha-hora o date-time es una fecha con una hora adjunta: identifica de forma única un instante en el tiempo (típicamente al segundo más cercano). Los tibbles imprimen esto como &lt;dttm&gt;. En otras partes de R se les llama POSIXct, pero no creemos que sea un nombre muy útil.\n\nEn este capítulo solo nos concentraremos en fechas (dates) y fechas-horas (date-times), ya que R no tiene una clase nativa para almacenar horas. Si necesitas una, puedes usar el paquete hms.\nSiempre deberías usar el tipo de datos más sencillo que se ajuste a tus necesidades. Esto significa que si puedes usar date en lugar de date-time, deberías hacerlo. Las fechas-horas son sustancialmente más complicadas porque necesitas gestionar los husos horarios, a los que volveremos al final del capítulo.\nPara obtener la fecha o fecha-hora actual, puedes usar today() (hoy) o now() (ahora):\n\ntoday()\n\n[1] \"2023-06-06\"\n\nnow()\n\n[1] \"2023-06-06 15:39:49 EDT\"\n\n\nHay tres modos en los que puedes crear una fecha/hora:\n\nDesde una cadena de caracteres (o string, en inglés).\nDesde componentes de fecha-hora individuales.\nDesde un objeto fecha-hora existente.\n\nEstos funcionan de la siguiente manera.\n\n16.2.1 Desde cadenas de caracteres\nLos datos de fecha/hora a menudo vienen como cadenas de caracteres. Ya has visto una forma de segmentarlas como date-times en el capítulo sobre importación de datos. Otra forma es usar las ayudas provistas por lubridate. Estas trabajan automáticamente el formato una vez que especificas el orden de los componentes. Para usarlas, identifica el orden en el que el año, mes y día aparecen en tus fechas, y luego ordena “y” (del inglés year), “m” (mes) y “d” (día) en el mismo orden. Esto te dará el nombre de la función lubridate que segmetará tu fecha. Por ejemplo:\n\nymd(\"2017-01-31\")\n\n[1] \"2017-01-31\"\n\nmdy(\"Enero 31, 2017\")\n\nWarning: All formats failed to parse. No formats found.\n\n\n[1] NA\n\ndmy(\"31-Ene-2017\")\n\nWarning: All formats failed to parse. No formats found.\n\n\n[1] NA\n\n\nEstas funciones también reciben números sin comillas. Esta es la forma más concisa de crear un único objeto fecha-hora, tal como podrías necesitarla cuando filtras datos temporales. ymd() (año-mes-día) es corta y no ambigüa:\n\nymd(20170131)\n\n[1] \"2017-01-31\"\n\n\nymd() y sus funciones amigas crean fechas (date). Para generar una fecha-hora, agrega un guión bajo y al menos un “h”, “m” y “s” al nombre de la función de segmentación:\n\nymd_hms(\"2017-01-31 20:11:59\")\n\n[1] \"2017-01-31 20:11:59 UTC\"\n\nmdy_hm(\"01/31/2017 08:01\")\n\n[1] \"2017-01-31 08:01:00 UTC\"\n\n\nTambién puedes forzar la creación de una fecha-hora desde una fecha, al proveer un huso horario:\n\nymd(20170131, tz = \"UTC\")\n\n[1] \"2017-01-31 UTC\"\n\n\n\n\n16.2.2 Desde componentes individuales\nEn lugar de una cadena de caracteres simple, a veces tienes los componentes individuales de una fecha-hora repartidos en múltiples columnas. Esto es lo que tenemos en los datos de vuelos:\n\nvuelos %&gt;%\n  select(anio, mes, dia, hora, minuto)\n\n# A tibble: 336,776 × 5\n    anio   mes   dia  hora minuto\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1  2013     1     1     5     15\n 2  2013     1     1     5     29\n 3  2013     1     1     5     40\n 4  2013     1     1     5     45\n 5  2013     1     1     6      0\n 6  2013     1     1     5     58\n 7  2013     1     1     6      0\n 8  2013     1     1     6      0\n 9  2013     1     1     6      0\n10  2013     1     1     6      0\n# ℹ 336,766 more rows\n\n\nPara crear una fecha-hora desde este tipo de input, usa make_date() (crear fecha) para las fechas, o make_datetime() (crear fecha-hora) para las fechas-horas:\n\nvuelos %&gt;%\n  select(anio, mes, dia, hora, minuto) %&gt;%\n  mutate(salida = make_datetime(anio, mes, dia, hora, minuto))\n\n# A tibble: 336,776 × 6\n    anio   mes   dia  hora minuto salida             \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;             \n 1  2013     1     1     5     15 2013-01-01 05:15:00\n 2  2013     1     1     5     29 2013-01-01 05:29:00\n 3  2013     1     1     5     40 2013-01-01 05:40:00\n 4  2013     1     1     5     45 2013-01-01 05:45:00\n 5  2013     1     1     6      0 2013-01-01 06:00:00\n 6  2013     1     1     5     58 2013-01-01 05:58:00\n 7  2013     1     1     6      0 2013-01-01 06:00:00\n 8  2013     1     1     6      0 2013-01-01 06:00:00\n 9  2013     1     1     6      0 2013-01-01 06:00:00\n10  2013     1     1     6      0 2013-01-01 06:00:00\n# ℹ 336,766 more rows\n\n\nHagamos esto mismo para cada una de las cuatro columnas de tiempo en vuelos. Las horas están representadas en un formato ligeramente más extraño, así que usaremos el módulo aritmético para extraer los componentes de horas y minutos. Una vez que hayamos creado las variables fecha-hora, nos centraremos en las variables que usaremos por el resto del capítulo.\n\nhacer_fechahora_100 &lt;- function(anio, mes, dia, tiempo) {\n  make_datetime(anio, mes, dia, tiempo %/% 100, tiempo %% 100)\n}\n\nvuelos_dt &lt;- vuelos %&gt;%\n  filter(!is.na(horario_salida), !is.na(horario_llegada)) %&gt;%\n  mutate(\n    horario_salida = hacer_fechahora_100(anio, mes, dia, horario_salida),\n    horario_llegada = hacer_fechahora_100(anio, mes, dia, horario_llegada),\n    salida_programada = hacer_fechahora_100(anio, mes, dia, salida_programada),\n    llegada_programada = hacer_fechahora_100(anio, mes, dia, llegada_programada)\n  ) %&gt;%\n  select(origen, destino, starts_with(\"atraso\"), starts_with(\"horario\"), ends_with(\"programada\"), tiempo_vuelo)\n\nvuelos_dt\n\n# A tibble: 328,063 × 9\n   origen destino atraso_salida atraso_llegada horario_salida     \n   &lt;chr&gt;  &lt;chr&gt;           &lt;dbl&gt;          &lt;dbl&gt; &lt;dttm&gt;             \n 1 EWR    IAH                 2             11 2013-01-01 05:17:00\n 2 LGA    IAH                 4             20 2013-01-01 05:33:00\n 3 JFK    MIA                 2             33 2013-01-01 05:42:00\n 4 JFK    BQN                -1            -18 2013-01-01 05:44:00\n 5 LGA    ATL                -6            -25 2013-01-01 05:54:00\n 6 EWR    ORD                -4             12 2013-01-01 05:54:00\n 7 EWR    FLL                -5             19 2013-01-01 05:55:00\n 8 LGA    IAD                -3            -14 2013-01-01 05:57:00\n 9 JFK    MCO                -3             -8 2013-01-01 05:57:00\n10 LGA    ORD                -2              8 2013-01-01 05:58:00\n# ℹ 328,053 more rows\n# ℹ 4 more variables: horario_llegada &lt;dttm&gt;, salida_programada &lt;dttm&gt;,\n#   llegada_programada &lt;dttm&gt;, tiempo_vuelo &lt;dbl&gt;\n\n\nCon estos datos, podemos visualizar la distribución de las horas de salida a lo largo del año:\n\nvuelos_dt %&gt;%\n  ggplot(aes(horario_salida)) +\n  geom_freqpoly(binwidth = 86400) # 86400 segundos = 1 día\n\n\n\n\nO para un solo día:\n\nvuelos_dt %&gt;%\n  filter(horario_salida &lt; ymd(20130102)) %&gt;%\n  ggplot(aes(horario_salida)) +\n  geom_freqpoly(binwidth = 600) # 600 segundos = 10 minutos\n\n\n\n\nTen en cuenta que cuando usas fechas-hora en un contexto numérico (como en un histograma), 1 significa un segundo, por lo tanto, un binwidth (ancho del contenedor) de 86400 significa un día. Para las fechas, 1 significa un día.\n\n\n16.2.3 Desde otros tipos\nPuedes querer cambiar entre una fecha-hora y una fecha. Ese es el trabajo de as_datetime() (como fecha-hora) y as_date() (como fecha):\n\nas_datetime(today())\n\n[1] \"2023-06-06 UTC\"\n\nas_date(now())\n\n[1] \"2023-06-06\"\n\n\nA veces tendrás fechas/horas como desfases numéricos de la “Época Unix” similares a 1970-01-01. Si el desfase es en segundos, usa as_datetime(); si es en días, usa as_date().\n\nas_datetime(60 * 60 * 10)\n\n[1] \"1970-01-01 10:00:00 UTC\"\n\nas_date(365 * 10 + 2)\n\n[1] \"1980-01-01\"\n\n\n\n\n16.2.4 Ejercicios\n\n¿Qué sucede si analizas una cadena de caracteres que contiene fechas inválidas?\n\n  ymd(c(\"2010-10-10\", \"bananas\"))\n\n¿Qué hace el argumento tzone (time zone = huso horario) para today()? ¿Por qué es importante?\nUtiliza la función de lubridate apropiada para analizar las siguientes fechas:\n\n::: {.cell}\nd1 &lt;- \"Enero 1, 2010\"\nd2 &lt;- \"2015-Mar-07\"\nd3 &lt;- \"06-Jun-2017\"\nd4 &lt;- c(\"Agosto 19 (2015)\", \"Julio 1 (2015)\")\nd5 &lt;- \"12/30/14\" # Diciembre 30, 2014\n:::"
  },
  {
    "objectID": "16-datetimes.html#componentes-de-fecha-hora",
    "href": "16-datetimes.html#componentes-de-fecha-hora",
    "title": "16  Fechas y horas",
    "section": "16.3 Componentes de fecha-hora",
    "text": "16.3 Componentes de fecha-hora\nAhora que ya conoces cómo tener datos de fechas y horas en las estructuras de datos de R, vamos a explorar qué puedes hacer con ellos. Esta sección se concentrará en las funciones de acceso (accessor functions) que te permiten obtener y configurar componentes individuales. La siguiente sección se centrará en cómo funciona el trabajo con fechas-horas.\n\n16.3.1 Obteniendo los componentes\nPuedes obtener las partes individuales de una fecha con las funciones de acceso year() (año), month() (mes), mday() (día del mes), yday() (día del año), wday() (día de la semana), hour() (hora), minute() (minuto), y second() (segundo).\n\nfechahora &lt;- ymd_hms(\"2016-07-08 12:34:56\")\n\nyear(fechahora)\n\n[1] 2016\n\nmonth(fechahora)\n\n[1] 7\n\nmday(fechahora)\n\n[1] 8\n\nyday(fechahora)\n\n[1] 190\n\nwday(fechahora)\n\n[1] 6\n\n\nPara month() y wday() puedes configurar label = TRUE para retornar el nombre abreviado del mes o del día de la semana. Usa abbr = FALSE para retornar el nombre completo.\n\nmonth(fechahora, label = TRUE)\n\n[1] Jul\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\nwday(fechahora, label = TRUE, abbr = FALSE)\n\n[1] Friday\n7 Levels: Sunday &lt; Monday &lt; Tuesday &lt; Wednesday &lt; Thursday &lt; ... &lt; Saturday\n\n\nPodemos usar wday() para ver que son más los vuelos que salen durante la semana que durante el fin de semana:\n\nvuelos_dt %&gt;%\n  mutate(dia_semana = wday(horario_salida, label = TRUE)) %&gt;%\n  ggplot(aes(x = dia_semana)) +\n  geom_bar()\n\n\n\n\nHay un patrón interesante si miramos la demora promedio por minuto dentro de la hora. ¡Parece que los vuelos que salen en los minutos 20-30 y 50-60 tienen mucho menos demora que en el resto de la hora!\n\nvuelos_dt %&gt;%\n  mutate(minuto = minute(horario_salida)) %&gt;%\n  group_by(minuto) %&gt;%\n  summarise(\n    atraso_promedio = mean(atraso_llegada, na.rm = TRUE),\n    n = n()\n  ) %&gt;%\n  ggplot(aes(minuto, atraso_promedio)) +\n  geom_line()\n\n\n\n\nEs interesante que si miramos el horario programado de salida, no vemos un patrón tan prominente:\n\nsalida_programada &lt;- vuelos_dt %&gt;%\n  mutate(minuto = minute(salida_programada)) %&gt;%\n  group_by(minuto) %&gt;%\n  summarise(\n    atraso_promedio = mean(atraso_llegada, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(salida_programada, aes(minuto, atraso_promedio)) +\n  geom_line()\n\n\n\n\nEntonces, ¿por qué vemos ese patrón con los horarios reales de salida? Bueno, como muchos datos recolectados por los humanos, hay un sesgo importante hacia los vuelos que salen en horas “agradables”. ¡Mantente siempre alerta respecto a este tipo de patrón cada vez que trabajes con datos que involucran juicio humano!\n\nggplot(salida_programada, aes(minuto, n)) +\n  geom_line()\n\n\n\n\n\n\n16.3.2 Redondeo\nUn método alternativo para graficar los componentes individuales es redondear la fecha a una unidad de tiempo cercana, con floor_date() (fecha hacia abajo), round_date() (redondear fecha), y ceiling_date() (fecha hacia arriba). Cada función toma un vector de fechas a ajustar y luego el nombre de la unidad redondeada (con round), redondeada hacia abajo (con floor) o hacia arriba (con ceiling). Esto, por ejemplo, nos permite graficar el número de vuelos por semana:\n\nvuelos_dt %&gt;%\n  count(semana = floor_date(horario_salida, \"week\")) %&gt;%\n  ggplot(aes(semana, n)) +\n  geom_line()\n\n\n\n\nCalcular la diferencia entre una fecha redondeada y una sin redondear puede ser particularmente útil.\n\n\n16.3.3 Configurando componentes\nTambién puedes usar las funciones de acceso para darle un valor a los componentes de las fechas/horas:\n\n(fechahora &lt;- ymd_hms(\"2016-07-08 12:34:56\"))\n\n[1] \"2016-07-08 12:34:56 UTC\"\n\nyear(fechahora) &lt;- 2020\nfechahora\n\n[1] \"2020-07-08 12:34:56 UTC\"\n\nmonth(fechahora) &lt;- 01\nfechahora\n\n[1] \"2020-01-08 12:34:56 UTC\"\n\nhour(fechahora) &lt;- hour(fechahora) + 1\nfechahora\n\n[1] \"2020-01-08 13:34:56 UTC\"\n\n\nAlternativamente, en lugar de modificar en un solo lugar, puedes crear una nueva fecha-hora con update() (actualizar). Esto también te permite configurar múltiples valores al mismo tiempo.\n\nupdate(fechahora, year = 2020, month = 2, mday = 2, hour = 2)\n\n[1] \"2020-02-02 02:34:56 UTC\"\n\n\nSi los valores son demasiado grandes, darán la vuelta:\n\nymd(\"2015-02-01\") %&gt;% update(mday = 30)\n\n[1] \"2015-03-02\"\n\nymd(\"2015-02-01\") %&gt;% update(hour = 400)\n\n[1] \"2015-02-17 16:00:00 UTC\"\n\n\nPuedes utilizar update() para mostrar la distribución de los vuelos a lo largo del día para cada día del año:\n\nvuelos_dt %&gt;%\n  mutate(horario_salida = update(horario_salida, yday = 1)) %&gt;%\n  ggplot(aes(horario_salida)) +\n  geom_freqpoly(binwidth = 300)\n\n\n\n\nFijar los componentes más grandes de una fecha con una constante es una técnica que te permite explorar patrones en los componentes más pequeños.\n\n\n16.3.4 Ejercicios\n\n¿Cómo cambia la distribución de las horas de los vuelos dentro de un día a lo largo del año?\nCompara horario_salida, salida_programada y atraso_salida. ¿Son consistentes? Explica tus hallazgos.\nCompara tiempo_vuelo con la duración entre la salida y la llegada. Explica tus hallazgos. (Pista: considera la ubicación del aeropuerto).\n¿Cómo cambia la demora promedio durante el curso de un día? ¿Deberías usar horario_salida o salida_programada? ¿Por qué?\n¿En qué día de la semana deberías salir si quieres minimizar las posibilidades de una demora?\n¿Qué hace que la distribución de diamantes$quilate y vuelos$salida_programada sea similar?\nConfirma nuestra hipótesis de que las salidas programadas en los minutos 20-30 y 50-60 están casuadas por los vuelos programados que salen más temprano. Pista: crea una variable binaria que te diga si un vuelo tuvo o no demora."
  },
  {
    "objectID": "16-datetimes.html#lapsos-de-tiempo",
    "href": "16-datetimes.html#lapsos-de-tiempo",
    "title": "16  Fechas y horas",
    "section": "16.4 Lapsos de tiempo",
    "text": "16.4 Lapsos de tiempo\nAhora, aprenderás cómo trabaja la aritmética con fechas, incluyendo la sustracción, adición y división. En el camino, aprenderás sobre tres importantes clases que representan períodos de tiempo:\n\ndurations (duraciones), que representa un número exacto de segundos.\nperiods (períodos), que representan unidades humanas como semanas o meses.\nintervals (intervalos), que representan un punto de inicio y uno de finalización.\n\n\n16.4.1 Duraciones\nCuando restas dos fechas en R obtienes un objeto de diferencia temporal (en inglés, difftimes):\n\n# ¿Qué edad tiene Hadley?\nedad_h &lt;- today() - ymd(19791014)\nedad_h\n\nTime difference of 15941 days\n\n\nUn objeto de clase difftime registra un lapso de tiempo de segundos, minutos, horas, días o semanas. Esta ambiguedad hace que los difftimes sean un poco complicados de trabajar, por lo que lubridate provee una alternativa que siempre usa segundos: la duración.\n\nas.duration(edad_h)\n\n[1] \"1377302400s (~43.64 years)\"\n\n\nLas duraciones traen un conveniente grupo de constructores:\n\ndseconds(15)\n\n[1] \"15s\"\n\ndminutes(10)\n\n[1] \"600s (~10 minutes)\"\n\ndhours(c(12, 24))\n\n[1] \"43200s (~12 hours)\" \"86400s (~1 days)\"  \n\nddays(0:5)\n\n[1] \"0s\"                \"86400s (~1 days)\"  \"172800s (~2 days)\"\n[4] \"259200s (~3 days)\" \"345600s (~4 days)\" \"432000s (~5 days)\"\n\ndweeks(3)\n\n[1] \"1814400s (~3 weeks)\"\n\ndyears(1)\n\n[1] \"31557600s (~1 years)\"\n\n\nLas duraciones siempre registran el lapso de tiempo en segundos. Las unidades más grandes se crean al convertir minutos, horas, días, semanas y años a segundos, mediante una conversión estándar (60 segundos en un minuto, 60 minutos en una hora, 24 horas en un día, 7 días en una semana, 365 días en un año).\nPuedes agregar y multiplicar duraciones:\n\n2 * dyears(1)\n\n[1] \"63115200s (~2 years)\"\n\ndyears(1) + dweeks(12) + dhours(15)\n\n[1] \"38869200s (~1.23 years)\"\n\n\nPuedes sumar y restar duraciones a días:\n\nayer &lt;- today() + ddays(1)\nanio_pasado &lt;- today() - dyears(1)\n\nSin embargo, como las duraciones representan un número exacto de segundos, a veces puedes obtener un resultado inesperado:\n\nuna_pm &lt;- ymd_hms(\"2016-03-12 13:00:00\", tz = \"America/New_York\")\n\nuna_pm\n\n[1] \"2016-03-12 13:00:00 EST\"\n\nuna_pm + ddays(1)\n\n[1] \"2016-03-13 14:00:00 EDT\"\n\n\n¡¿Por qué un día después de la 1 pm del 12 de marzo son las 2 pm del 13 de marzo!? Si miras con cuidado la fecha, te darás cuenta de que los husos horarios han cambiado. Debido al horario de verano (EDT es el horario de verano de la Costa Este de EE. UU.), el 12 de marzo solo tiene 23 horas, por lo que si agregamos un día entero de segundos terminamos con una hora diferente.\n\n\n16.4.2 Períodos\nPara resolver este problema, lubridate provee periodos. Estos son plazos de tiempo que no tienen un largo fijo en segundos, sino que funcionan con tiempos “humanos”, como días o meses. Esto les permite trabajar en una forma más intuitiva:\n\nuna_pm\n\n[1] \"2016-03-12 13:00:00 EST\"\n\nuna_pm + days(1)\n\n[1] \"2016-03-13 13:00:00 EDT\"\n\n\nAl igual que las duraciones, los períodos pueden ser creados mediante un número de funciones constructoras amigables.\n\nseconds(15)\n\n[1] \"15S\"\n\nminutes(10)\n\n[1] \"10M 0S\"\n\nhours(c(12, 24))\n\n[1] \"12H 0M 0S\" \"24H 0M 0S\"\n\ndays(7)\n\n[1] \"7d 0H 0M 0S\"\n\nmonths(1:6)\n\n[1] \"1m 0d 0H 0M 0S\" \"2m 0d 0H 0M 0S\" \"3m 0d 0H 0M 0S\" \"4m 0d 0H 0M 0S\"\n[5] \"5m 0d 0H 0M 0S\" \"6m 0d 0H 0M 0S\"\n\nweeks(3)\n\n[1] \"21d 0H 0M 0S\"\n\nyears(1)\n\n[1] \"1y 0m 0d 0H 0M 0S\"\n\n\nPuedes sumar y multiplicar períodos:\n\n10 * (months(6) + days(1))\n\n[1] \"60m 10d 0H 0M 0S\"\n\ndays(50) + hours(25) + minutes(2)\n\n[1] \"50d 25H 2M 0S\"\n\n\nY, por supuesto, puedes sumarlos a las fechas. Comparados con las duraciones, los períodos son más propensos a hacer lo que esperas que hagan:\n\n# Un año bisiesto\nymd(\"2016-01-01\") + dyears(1)\n\n[1] \"2016-12-31 06:00:00 UTC\"\n\nymd(\"2016-01-01\") + years(1)\n\n[1] \"2017-01-01\"\n\n# Horarios de verano\nuna_pm + ddays(1)\n\n[1] \"2016-03-13 14:00:00 EDT\"\n\nuna_pm + days(1)\n\n[1] \"2016-03-13 13:00:00 EDT\"\n\n\nUsemos los períodos para arreglar una rareza relacionada a nuestras fechas de vuelos. Algunos aviones parecen arribar a su destino antes de salir de la ciudad de Nueva York.\n\nvuelos_dt %&gt;%\n  filter(horario_llegada &lt; horario_salida)\n\n# A tibble: 10,633 × 9\n   origen destino atraso_salida atraso_llegada horario_salida     \n   &lt;chr&gt;  &lt;chr&gt;           &lt;dbl&gt;          &lt;dbl&gt; &lt;dttm&gt;             \n 1 EWR    BQN                 9             -4 2013-01-01 19:29:00\n 2 JFK    DFW                59             NA 2013-01-01 19:39:00\n 3 EWR    TPA                -2              9 2013-01-01 20:58:00\n 4 EWR    SJU                -6            -12 2013-01-01 21:02:00\n 5 EWR    SFO                11            -14 2013-01-01 21:08:00\n 6 LGA    FLL               -10             -2 2013-01-01 21:20:00\n 7 EWR    MCO                41             43 2013-01-01 21:21:00\n 8 JFK    LAX                -7            -24 2013-01-01 21:28:00\n 9 EWR    FLL                49             28 2013-01-01 21:34:00\n10 EWR    FLL                -9            -14 2013-01-01 21:36:00\n# ℹ 10,623 more rows\n# ℹ 4 more variables: horario_llegada &lt;dttm&gt;, salida_programada &lt;dttm&gt;,\n#   llegada_programada &lt;dttm&gt;, tiempo_vuelo &lt;dbl&gt;\n\n\nEstos son vuelos nocturnos. Usamos la misma información de fecha para los horarios de salida y llegada, pero estos vuelos llegaron al día siguiente. Podemos arreglarlo al sumar days(1) a la fecha de llegada de cada vuelo nocturno.\n\nvuelos_dt &lt;- vuelos_dt %&gt;%\n  mutate(\n    nocturno = horario_llegada &lt; horario_salida,\n    horario_llegada = horario_llegada + days(nocturno * 1),\n    llegada_programada = llegada_programada + days(nocturno * 1)\n  )\n\nAhora todos los vuelos obedecen a las leyes de la física.\n\nvuelos_dt %&gt;%\n  filter(nocturno, horario_llegada &lt; horario_salida)\n\n# A tibble: 0 × 10\n# ℹ 10 variables: origen &lt;chr&gt;, destino &lt;chr&gt;, atraso_salida &lt;dbl&gt;,\n#   atraso_llegada &lt;dbl&gt;, horario_salida &lt;dttm&gt;, horario_llegada &lt;dttm&gt;,\n#   salida_programada &lt;dttm&gt;, llegada_programada &lt;dttm&gt;, tiempo_vuelo &lt;dbl&gt;,\n#   nocturno &lt;lgl&gt;\n\n\n\n\n16.4.3 Intervalos\nResulta obvio lo que dyears(1) / ddays(365) debería retornar: uno, porque las duraciones siempre se representan por un número de segundos y la duración de un año se define como 365 días convertidos a segundos.\n¿Qué debería devolver years(1) / days(1)? Bueno, si el año fuera 2015 debería retornar 365, ¡pero si fuera 2016 debería retornar 366! No hay suficiente información para que lubridate nos dé una sola respuesta sencilla. Por ello, lo que hace es darnos una estimación con una advertencia:\n\nyears(1) / days(1)\n\n[1] 365.25\n\n\nSi quieres una medida más precisa, tendrás que usar un intervalo. Un intervalo es una duración con un punto de partida: eso lo hace preciso, por lo que puedes determinar exactamente cuán largo es:\n\nsiguiente_anio &lt;- today() + years(1)\n(today() %--% siguiente_anio) / ddays(1)\n\n[1] 366\n\n\nPara encontrar cuántos períodos caen dentro de un intervalo, tienes que usar la división entera:\n\n(today() %--% siguiente_anio) %/% days(1)\n\n[1] 366\n\n\n\n\n16.4.4 Resumen\n¿Cómo eliges entre duraciones, períodos e intervalos? Como siempre, selecciona la estructura de datos más sencilla que resuelva tu problema. Si solo te interesa el tiempo físico, usa una duración; si necesitas agregar tiempos humanos, usa un período; si tienes que deducir cuán largo es un lapso de tiempo en unidades humanas, usa un intervalo.\nLa figura @ref(fig:dt-algebra) resume las operaciones artiméticas permitidas entre los tipos de datos.\n\n\n\n\n\nLas operaciones artiméticas permitidas entre pares de clases fecha/hora.\n\n\n\n\n\n\n16.4.5 Ejercicios\n\n¿Por qué hay months() pero no dmonths() (días del mes)?\nExplica days(nocturno * 1) a alguien que apenas comienza a aprender R. ¿Cómo funciona?\nCrea un vector de fechas dando el primer día de cada mes de 2015. Crea un vector de fechas dando el primer día de cada mes del año actual.\nCrea una función en la que, dado tu cumpleaños (como una fecha), retorne qué edad tienes en años.\n¿Por qué no funciona (today() %--% (today() + years(1)) / months(1) ?"
  },
  {
    "objectID": "16-datetimes.html#husos-horarios",
    "href": "16-datetimes.html#husos-horarios",
    "title": "16  Fechas y horas",
    "section": "16.5 Husos horarios",
    "text": "16.5 Husos horarios\nLos husos horarios son un tema enormemente complicado debido a su interacción con entidades geopolíticas. Afortunadamente, no necesitamos escarbar en todos los detalles, ya que no todos son necesarios para el análisis de datos. Sin embargo, hay algunos desafíos que tendremos que enfrentar.\nEl primer desafío es que los nombres comunes de los husos horarios tienden a ser ambiguos. Por ejemplo, si eres estadounidense, probablemente te sea familiar la sigla EST, (del inglés de Tiempo Este Estándar). Sin embargo, ¡Canadá y Australia también tienen EST! Para evitar la confusión, R usa el estándar internacional IANA para husos horarios. Estos tienen un esquema de nombres que sigue el formato “&lt;área&gt;/”, típicamente escrito como “&lt;continente&gt;/&lt;ciudad&gt;”, en idioma inglés (hay algunas pocas excepciones porque no todos los países están sobre un continente). Algunos ejemplos: “America/New_York”, “Europe/Paris”, “Pacific/Auckland”, “America/Bogota”.\nPuede que te preguntes por qué un huso horario usa una ciudad, cuando típicamente piensas en ellos como asociados a un país o a una región dentro de un país. Esto se debe a que la base de datos de IANA tiene que registrar décadas de reglamentos sobre husos horarios. En el curso de las décadas, los países cambian nombres (o desaparecen) de forma bastante frecuente, pero los nombres de las ciudades tienden a mantenerse igual. Otro problema es que los nombres tienen que reflejar no solo el comportamiento actual, sino también la historia completa. Por ejemplo, hay husos horarios tanto para “America/New_York” como para “America/Detroit”. Actualmente, ambas ciudades usan el EST, pero entre 1969 y 1972, Michigan (el estado en el que está ubicado Detroit), no empleaba el horario de verano, así que necesita un nombre diferente. ¡Vale la pena leer la base de datos sobre husos horarios (disponible en http://www.iana.org/time-zones) solo para enterarse de algunas de estas historias!\nPuedes encontrar cuál es tu huso horario actual para R, usando Sys.timezone():\n\nSys.timezone()\n\n[1] \"America/Toronto\"\n\n\n(Si R no lo sabe, obtendrás un NA.)\nY puedes ver la lista completa de todos los husos horarios con OlsonNames():\n\nlength(OlsonNames())\n\n[1] 597\n\nhead(OlsonNames())\n\n[1] \"Africa/Abidjan\"     \"Africa/Accra\"       \"Africa/Addis_Ababa\"\n[4] \"Africa/Algiers\"     \"Africa/Asmara\"      \"Africa/Asmera\"     \n\n\nEn R, el huso horario es un atributo de la fecha-hora (date-time) que solo controla la impresión. Por ejemplo, estos tres objetos representan el mismo instante en el tiempo:\n\n(x1 &lt;- ymd_hms(\"2015-06-01 12:00:00\", tz = \"America/New_York\"))\n\n[1] \"2015-06-01 12:00:00 EDT\"\n\n(x2 &lt;- ymd_hms(\"2015-06-01 18:00:00\", tz = \"Europe/Copenhagen\"))\n\n[1] \"2015-06-01 18:00:00 CEST\"\n\n(x3 &lt;- ymd_hms(\"2015-06-02 04:00:00\", tz = \"Pacific/Auckland\"))\n\n[1] \"2015-06-02 04:00:00 NZST\"\n\n\nPuedes verificar que son lo mismo al usar una resta:\n\nx1 - x2\n\nTime difference of 0 secs\n\nx1 - x3\n\nTime difference of 0 secs\n\n\nExcepto que se especifique otra cosa, lubridate siempre usa UTC. UTC (Tiempo Universal Coordinado) es el huso horario estándar empleado por la comunidad científica y es aproximadamente equivalente a su predecesor GMT (siglas en inglés de Tiempo del Meridiano de Greenwich). UTC no tiene horario de verano, por lo que resulta una representación conveniente para la computación. Las operaciones que combinan fechas y horas, como c(), a menudo descartan el huso horario. En ese caso, las fechas y horas se muestran en tu huso local:\n\nx4 &lt;- c(x1, x2, x3)\nx4\n\n[1] \"2015-06-01 12:00:00 EDT\" \"2015-06-01 12:00:00 EDT\"\n[3] \"2015-06-01 12:00:00 EDT\"\n\n\nPuedes cambiar el huso horario de dos formas:\n\nMantener el instante en el tiempo igual y cambiar solo cómo se representa. Usa esto cuando el instante es correcto, pero quieres una visualización más natural.\n::: {.cell}\n  x4a &lt;- with_tz(x4, tzone = \"Australia/Lord_Howe\")\n  x4a\n::: {.cell-output .cell-output-stdout} [1] \"2015-06-02 02:30:00 +1030\" \"2015-06-02 02:30:00 +1030\"  [3] \"2015-06-02 02:30:00 +1030\" :::\n  x4a - x4\n::: {.cell-output .cell-output-stdout} Time differences in secs  [1] 0 0 0 ::: :::\n(Esto también ilustra otro desafío de los husos horarios: ¡no todos los desfasajes son horas como números enteros!)\nCambia el instante en el tiempo subyacente. Usa esto cuando tienes un instante que ha sido etiquetado con un huso horario incorrecto y necesitas arreglarlo.\n::: {.cell}\n  x4b &lt;- force_tz(x4, tzone = \"Australia/Lord_Howe\")\n  x4b\n::: {.cell-output .cell-output-stdout} [1] \"2015-06-01 12:00:00 +1030\" \"2015-06-01 12:00:00 +1030\"  [3] \"2015-06-01 12:00:00 +1030\" :::\n  x4b - x4\n::: {.cell-output .cell-output-stdout} Time differences in hours  [1] -14.5 -14.5 -14.5 ::: :::"
  },
  {
    "objectID": "17-program.html#aprendiendo-más",
    "href": "17-program.html#aprendiendo-más",
    "title": "17  Introducción",
    "section": "17.1 Aprendiendo más",
    "text": "17.1 Aprendiendo más\nEl objetivo de estos capítulos es enseñarte lo mínimo acerca de programación que necesitas para hacer ciencia de datos, lo que resulta una cantidad considerable de información. Una vez que hayas dominado el material de este libro, creemos firmemente que deberías invertir tiempo en mejorar tus habilidades de programación. Aprender más sobre programación es una inversión a largo plazo: no obtendrás resultados inmediatos, pero a la larga te permitirá resolver nuevos problemas más rápidamente y te permitirá reutilizar el conocimiento que adquiriste en nuevos escenarios.\nPara profundizar necesitas estudiar R como un lenguaje de programación, no solo como un ambiente interactivo para ciencia de datos. Escribimos dos libros que te ayudarán con esto, aunque actualmente están disponibles solo en inglés:\n\nHands on Programming with R, de Garrett Grolemund. Esta es una introducción a R como lenguaje de programación y es un buen lugar para empezar si R es el primer lenguaje que aprendes. Cubre casi el mismo material que estos capítulos, pero con un estilo diferente y con distintos ejemplos de motivación (basados en el casino). Es un complemento muy útil si consideras que estos cuatros capítulos van demasiado rápido.\nAdvanced R de Hadley Wickham. Este libro se sumerge en los detalles del lenguaje de programación R. Este es un buen punto por donde empezar si ya tienes experiencia en programación. Es también una buena manera de seguir una vez que hayas internalizado las ideas de estos cuatro capítulos. Puedes leerlo online en el sitio https://adv-r.hadley.nz/."
  },
  {
    "objectID": "18-pipes.html#introducción",
    "href": "18-pipes.html#introducción",
    "title": "18  Pipes",
    "section": "18.1 Introducción",
    "text": "18.1 Introducción\nLos pipes son una herramienta poderosa para expresar claramente una secuencia de múltiples operaciones. Hasta aquí, has venido usándolos sin saber cómo funcionan o qué alternativas existen. En este capítulo ya es tiempo de explorarlos en más detalle. En él aprenderás qué alternativas existen, cuándo no deberías utilizarlos y algunas herramientas útiles relacionadas.\n\n18.1.1 Prerequisitos\nEl pipe, %&gt;%, viene del paquete magrittr de Stefan Milton Bache. Los paquetes del Tidyverse cargan %&gt;% automáticamente, por lo que usualmente no tendrás que cargar magrittr de forma explícita. Sin embargo, como acá nos enfocaremos en el uso de pipes y no usaremos otros paquetes del tidyverse, lo cargaremos explícitamente.\n\nlibrary(magrittr)\nlibrary(datos)"
  },
  {
    "objectID": "18-pipes.html#alternativas-a-los-pipes",
    "href": "18-pipes.html#alternativas-a-los-pipes",
    "title": "18  Pipes",
    "section": "18.2 Alternativas a los pipes",
    "text": "18.2 Alternativas a los pipes\nEl objetivo de un pipe es ayudarte a escribir código de una manera que sea más fácil de leer y entender. Para ver por qué un pipe es tan útil, vamos a explorar diferentes formas de escribir el mismo código. Usemos código para contar una historia acerca de un pequeño conejito llamado Foo Foo:\n\nEl pequeño conejito Foo Foo Fue saltando por el bosque Recogiendo ratones del campo Y golpeándolos en la cabeza\n\nEste es un poema popular para niños que se acompaña mediante gestos con las manos.\nEmpezaremos por definir un objeto que represente al pequeño conejito Foo Foo:\n\nfoo_foo &lt;- pequeño_conejito()\n\nY usaremos una función para cada verbo clave: saltar(), recoger(), y golpear(). Usando este objeto y estos verbos, existen (al menos) cuatro maneras en las que podemos volver a contar la historia en código:\n\nGuardar cada paso intermedio como un nuevo objeto.\nSobreescribir el objeto original muchas veces.\nComponer funciones.\nUsar un pipe.\n\nDesarrollaremos cada uno de estos enfoques, mostrándote el código y hablando de las ventajas y desventajas.\n\n18.2.1 Pasos intermedios\nEl enfoque más sencillo es guardar cada paso como un nuevo objeto:\n\nfoo_foo_1 &lt;- saltar(foo_foo, a_traves = bosque)\nfoo_foo_2 &lt;- recoger(foo_foo_1, que = ratones_del_campo)\nfoo_foo_3 &lt;- golpear(foo_foo_2, en = cabeza)\n\nLa principal desventaja de esta manera es que te obliga a nombrar cada paso intermedio. Si hay nombres naturales, es una buena idea y deberías hacerlo. Pero muchas veces, como en este ejemplo, no hay nombres naturales, por lo que agregas sufijos numéricos para hacer los nombres únicos. Esto conduce a dos problemas:\n\nEl código está abarrotado con nombres poco importantes.\nHay que incrementar cuidadosamente el sufijo en cada línea.\n\nCada vez que escribimos código como este, nos ocurre que inevitablemente usamos el número incorrecto en una línea y luego perdemos 10 minutos rascándonos la cabeza tratándo de darnos cuenta por qué no funciona. Probablemente te preocupa también que esta forma crea muchas copias de tus datos y ocupa demasiada memoria. Sorprendentemente, este no es el caso. Primero, ten en cuenta que preocuparse proactivamente de la memoria no es una manera útil de invertir tu tiempo: preocúpate acerca de ello cuando se convierta en un problema (es decir, cuando te quedes sin memoria), no antes. En segundo lugar, R no es estúpido y compartirá las columnas a lo largo de los dataframes cuando sea posible. Echemos un vistazo a un pipe de manipulación de datos en el que agregamos una nueva columna a datos::diamantes:\n\ndiamantes2 &lt;- diamantes %&gt;%\n  dplyr::mutate(precio_por_quilate = precio / quilate)\n\npryr::object_size(diamantes)\n\n3.46 MB\n\npryr::object_size(diamantes2)\n\n3.89 MB\n\npryr::object_size(diamantes, diamantes2)\n\n3.89 MB\n\n\npryr::object_size() (tamaño de objeto) devuelve la cantidad de memoria ocupada por todos los argumentos de un objeto. Los resultados parecen contraintuitivos al principio:\n\ndiamantes ocupa 3.46 MB,\ndiamantes2 ocupa 3.89 MB,\n¡diamantes y diamantes2 juntos ocupan 3.89 MB!\n\n¿Cómo es que funciona esto? Bien, diamantes2 tiene 10 columnas en común con diamantes: no hay necesidad de duplicar los datos, así que ambos data frames tienen variables en común. Estas variables solo serán copiadas si modificas una de ellas. En el siguiente ejemplo, modificamos un solo valor en diamantes$quilate. Esto significa que la variable quilate no podrá ser compartida entre los dos data frames, por lo que se debe realizar una copia. El tamaño de cada data frame no cambia, pero el tamaño colectivo se incrementa:\n\ndiamantes$quilate[1] &lt;- NA\npryr::object_size(diamantes)\n\n3.46 MB\n\npryr::object_size(diamantes2)\n\n3.89 MB\n\npryr::object_size(diamantes, diamantes2)\n\n4.32 MB\n\n\n(Fíjate que aquí usamos pryr::object_size(), no la versión de object.size() ya precargada. object.size() toma un solo objeto, por lo que no puede computar cómo los datos son compartidos a través de múltiples objetos.)\n\n\n18.2.2 Sobrescribir el original\nEn vez de crear objetos en cada paso intermedio, podemos sobrescribir el objeto original:\n\nfoo_foo &lt;- saltar(foo_foo, a_traves = bosque)\nfoo_foo &lt;- recoger(foo_foo, que = ratones_del_campo)\nfoo_foo &lt;- golpear(foo_foo, en = cabeza)\n\nEsto es menos tipeo (y menos que pensar), así que es menos probable que cometas errores. Sin embargo, hay dos problemas:\n\nDepurar es doloroso: si cometes un error vas a necesitar correr de nuevo todo el código desde el principio.\nLa repetición del objeto a medida que es transformado (¡hemos escrito foo_foo 6 veces!) hace poco transparente lo que está siendo cambiado en cada línea.\n\n\n\n18.2.3 Composición de funciones\nOtro enfoque es abandonar la asignación y encadenar todas las llamadas a las funciones:\n\ngolpear(\n  recoger(\n    saltar(foo_foo, a_traves = bosque),\n    que = raton_de_campo\n  ),\n  en = la_cabeza\n)\n\nAquí la desventaja es que se debe leer de adentro hacia afuera, de derecha a izquierda y que los argumentos terminan separados (problema que se conoce como Dagwood sandwich). En resumen, este código es difícil de leer para un ser humano.\n\n\n18.2.4 Uso de pipe\nFinalmente, podemos usar el pipe:\n\nfoo_foo %&gt;%\n  saltar(a_traves = bosque) %&gt;%\n  recoger(que = ratones_campo) %&gt;%\n  golpear(en = cabeza)\n\nEsta es nuestra forma preferida, ya que se enfoca en los verbos, no en los sustantivos. Puedes leer esta secuencia de composición de funciones como si fuera un conjunto de acciones imperativas. Foo salta, luego recoge, luego golpea. La desventaja, por supuesto, es que necesitas estar familiarizado con el uso de los pipes. Si nunca has visto %&gt;% antes, no tendrás idea acerca de lo que realiza el código. Afortunadamente, la mayoría de la gente entiende la idea fácilmente, así que cuando compartes tu código con otros que no están familiarizados con los pipes, puedes enseñárselos fácilmente.\nEl pipe trabaja realizando una “transformación léxica”: detrás de escena, magrittr reensambla el código en el pipe a una forma que funciona sobrescribiendo un objeto intermedio. Cuando se ejecuta un pipe como el de arriba, magrittr hace algo como esto:\n\nmi_pipe &lt;- function(.) {\n  . &lt;- saltar(., a_traves = bosque)\n  . &lt;- recoger(., que = ratones_campo)\n  golpear(., en = la_cabeza)\n}\nmi_pipe(foo_foo)\n\nEsto significa que un pipe no funcionará con dos clases de funciones: 1. Funciones que usan el entorno actual. Por ejemplo, assign() (asignar) creará una nueva variable con el nombre dado en el entorno actual:\n\nassign(\"x\", 10)\nx\n\n[1] 10\n\n\"x\" %&gt;% assign(100)\nx\n\n[1] 10\n\n\nEl uso de la asignación con el pipe no funcionará porque lo asigna a un entorno temporal usado por %&gt;%. Si quieres usar la asignación con un pipe, debes explicitar el entorno:\n\nenv &lt;- environment()\n\"x\" %&gt;% assign(100, envir = env)\nx\n\n[1] 100\n\n\nOtras funciones con este problema incluyen get() y load().\n\nFunciones que usan lazy evaluation (evaluación diferida o “perezosa”). En R, los argumentos de las funciones son solamente computados cuando la función los usa, no antes de llamar a la función. El pipe computa cada elemento por turno, por lo que no puedes confiar en este comportamiento.\n\nUn caso en el cual esto es un problema es el de tryCatch(), que te permite capturar y manejar errores:\n\ntryCatch(stop(\"!\"), error = function(e) \"Un error\")\n\n[1] \"Un error\"\n\nstop(\"!\") %&gt;%\n  tryCatch(error = function(e) \"Un error\")\n\n[1] \"Un error\"\n\n\nHay una cantidad relativamente grande de funciones con este comportamiento, que incluye a try(), suppressMessages() y suppressWarnings() en R base."
  },
  {
    "objectID": "18-pipes.html#cuándo-no-usar-el-pipe",
    "href": "18-pipes.html#cuándo-no-usar-el-pipe",
    "title": "18  Pipes",
    "section": "18.3 Cuándo no usar el pipe",
    "text": "18.3 Cuándo no usar el pipe\nEl pipe es una herramienta poderosa, pero no es la única herramienta a tu disposición ¡y no soluciona todos los problemas! Los pipes son mayoritariamente usados para reescribir una secuencia lineal bastante corta de operaciones. Creemos que deberías buscar otra herramienta cuando:\n\nTus pipes son más largos que (digamos) 10 pasos. En ese caso, crea objetos intermedios con nombres significativos. Esto hará la depuración más fácil, porque puedes chequear con mayor facilidad los resultados intermedios. Además, hace más simple entender tu código, ya que los nombres de las variables pueden ayudar a comunicar la intención.\nTienes múltiples inputs y outputs. Si no hay un objeto principal para ser transformado, sino dos o más objetos siendo combinados juntos, no uses el pipe.\nSi estás empezando a pensar acerca de un grafo dirigido con una estructura de dependencia compleja. Los pipes son fundamentalmente lineales y usarlos para expresar relaciones complejas, típicamente llevarán a un código confuso."
  },
  {
    "objectID": "18-pipes.html#otras-herramientas-de-magrittr",
    "href": "18-pipes.html#otras-herramientas-de-magrittr",
    "title": "18  Pipes",
    "section": "18.4 Otras herramientas de magrittr",
    "text": "18.4 Otras herramientas de magrittr\nTodos los paquetes del tidyverse automáticamente harán que %&gt;% esté disponible, por lo que normalmente no será necesario cargar magrittr explícitamente. De todas formas, hay otras herramientas útiles dentro de magrittr que podrías querer utilizar:\n\nCuando se trabaja en un pipe más complejo, a veces es útil llamar a una función por sus efectos secundarios. Tal vez quieras imprimir el objeto actual, o graficarlo, o guardarlo en el disco. Muchas veces, estas funciones no devuelven nada, efectivamente terminando el pipe.\n\nPara solucionar este problema, puedes usar el pipe “T”. %T&gt;%trabaja igual que %&gt;%, excepto que devuelve el lado izquierdo en vez del lado derecho. Se lo llama “T” porque literalmente tiene la forma de una T.\n\nrnorm(100) %&gt;%\n  matrix(ncol = 2) %&gt;%\n  plot() %&gt;%\n  str()\n\n\n\n\n NULL\n\nrnorm(100) %&gt;%\n  matrix(ncol = 2) %T&gt;%\n  plot() %&gt;%\n  str()\n\n\n\n\n num [1:50, 1:2] 0.8451 0.2949 1.002 1.5592 -0.0969 ...\n\n\n\nSi estás trabajando con funciones que no tienen una API basada en data frames (esto es, pasas vectores individuales, no un data frame o expresiones que serán evaluadas en el contexto de un data frame), puedes encontrar %$% útil. Este operador “explota” las variables en un dataframe para que te puedas referir a ellas de manera explícita. Esto es útil cuando se trabaja con muchas funciones en R base:\n\n\nmtautos %$%\n  cor(cilindrada, millas)\n\n[1] -0.8475514\n\n\n\nPara asignaciones, magrittr provee el operador %&lt;&gt;% que te permite reemplazar el código de la siguiente forma:\n\n\nmtautos &lt;- mtautos %&gt;%\n  transform(cilindros = cilindros * 2)\n\ncon\n\nmtautos %&lt;&gt;% transform(cilindros = cilindros * 2)\n\nNo somos partidarios de este operador porque creemos que una asignación es una operación especial que siempre debe ser clara cuando sucede. En nuestra opinión, un poco de duplicación (esto es, repetir el nombre de un objeto dos veces) está bien para lograr hacer la asignación más explícita."
  },
  {
    "objectID": "19-functions.html#introducción",
    "href": "19-functions.html#introducción",
    "title": "19  Funciones",
    "section": "19.1 Introducción",
    "text": "19.1 Introducción\nUna de las mejores maneras de lograr tener mayor alcance haciendo ciencia de datos es escribir funciones. Las funciones te permitirán automatizar algunas tareas comunes de una forma más poderosa y general que copiar-y-pegar. Escribir funciones tiene tres grandes ventajas sobre copiar-y-pegar:\n\nPuedes dar a la función un nombre evocador que hará tu código más fácil de entender.\nA medida que cambien los requerimientos, solo necesitarás cambiar tu código en un solo lugar, en vez de en varios lugares.\nEliminas las probabilidades de errores accidentales cuando copias y pegas (por ej., al actualizar el nombre de una variable en un lugar, pero no en otro).\n\nEscribir funciones es un viaje de toda una vida. Incluso después de usar R por varios años, seguimos aprendiendo nuevas técnicas y mejores formas de abordar viejos problemas. El objetivo de este capítulo no es enseñarte cada detalle esotérico de las funciones, sino introducirte en este tema con consejos pragmáticos que puedas aplicar inmediatamente.\nAdemás de consejos prácticos para escribir funciones, este capítulo también te entregará consejos de estilo para tu código. Escribir código con buen estilo es como utilizar la puntuación correcta. Puedesmanejartesinella, pero utilizarla hace las cosas más fáciles de leer. Al igual que con los estilos de puntuación, hay muchas posibles variaciones. Si bien aquí presentamos el estilo que nosotros usamos en nuestro código, lo más importante es que seas consistente.\n\n19.1.1 Prerrequisitos\nEl foco de este capítulo es escribir funciones en R base, por lo que no necesitarás ningún paquete extra."
  },
  {
    "objectID": "19-functions.html#cuándo-deberías-escribir-una-función",
    "href": "19-functions.html#cuándo-deberías-escribir-una-función",
    "title": "19  Funciones",
    "section": "19.2 ¿Cuándo deberías escribir una función?",
    "text": "19.2 ¿Cuándo deberías escribir una función?\nDeberías considerar escribir una función cuando has copiado y pegado un bloque de código más de dos veces (es decir, ahora tienes tres copias del mismo). Mira, por ejemplo, el siguiente código. ¿Qué es lo que hace?\n\ndf &lt;- tibble::tibble(\n a = rnorm(10),\n b = rnorm(10),\n c = rnorm(10),\n d = rnorm(10)\n)\n\ndf$a &lt;- (df$a - min(df$a, na.rm = TRUE)) /\n (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))\ndf$b &lt;- (df$b - min(df$b, na.rm = TRUE)) /\n (max(df$b, na.rm = TRUE) - min(df$a, na.rm = TRUE))\ndf$c &lt;- (df$c - min(df$c, na.rm = TRUE)) /\n (max(df$c, na.rm = TRUE) - min(df$c, na.rm = TRUE))\ndf$d &lt;- (df$d - min(df$d, na.rm = TRUE)) /\n (max(df$d, na.rm = TRUE) - min(df$d, na.rm = TRUE))\n\nEs posible que hayas podido descifrar que lo que hace es reescalar cada columna para que tenga un rango de 0 a 1. Pero ¿has encontrado el error? Ocurrió copiando-y-pegando el código para df$b: Hemos olvidado de cambiar a a b. Extraer el código repetido en una función es una buena idea, ya que previene que cometas errores como este.\nPara escribir una función, lo primero que necesitas hacer es analizar el código. ¿Cuantos inputs tiene?\n\n(df$a - min(df$a, na.rm = TRUE)) /\n (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))\n\nEste código tiene un solo input df$a. (Si te sorprende que TRUE no es un input, puedes explorar el ejercicio de abajo). Para hacer los inputs más claros, es buena idea reescribir el código usando variables temporales con nombres generales. Acá el código requiere un solo vector numérico, por lo que lo llamaremos x:\n\nx &lt;- df$a\n(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n\n [1] 1.0000000 0.4740799 0.6292862 0.4008204 0.7961103 0.8447679 0.0000000\n [8] 0.5368927 0.7331723 0.4591778\n\n\nHay algo de duplicación en este código. Estamos computando el rango de datos tres veces, así que tiene sentido hacerlo en un solo paso:\n\nrng &lt;- range(x, na.rm = TRUE)\n(x - rng[1]) / (rng[2] - rng[1])\n\n [1] 1.0000000 0.4740799 0.6292862 0.4008204 0.7961103 0.8447679 0.0000000\n [8] 0.5368927 0.7331723 0.4591778\n\n\nSacar cálculos intermedios en variables nombradas es una buena práctica porque deja más claro qué es lo que está haciendo el código. Ahora que hemos simplificado el código y chequeado de que aún funciona, podemos convertirlo en una función:\n\nrescale01 &lt;- function(x) {\n rng &lt;- range(x, na.rm = TRUE)\n (x - rng[1]) / (rng[2] - rng[1])\n}\nrescale01(c(0, 5, 10))\n\n[1] 0.0 0.5 1.0\n\n\nHay tres pasos claves para crear una función nueva:\n\nNecesitas elegir un nombre para la función. Aquí hemos usado rescale01, ya que esta función reescala (rescale, en inglés) un vector para que se ubique entre 0 y 1.\nListar los inputs, o argumentos, de la función dentro de function. Aquí solo tenemos un argumento. Si tenemos más, la llamada se vería como function(x, y, z).\nSituar el código que has creado en el cuerpo de una función, un bloque de { que sigue inmediatamente a function(...).\n\nTen en cuenta el proceso general: solo hemos creado la función después de darnos cuenta cómo funciona con un input simple. Es más fácil empezar con código que funciona y luego convertirlo en una función; es más difícil crear la función y luego tratar que funcione.\nEn este punto es una buena idea chequear tu función con algunos inputs diferentes:\n\nrescale01(c(-10, 0, 10))\n\n[1] 0.0 0.5 1.0\n\nrescale01(c(1, 2, 3, NA, 5))\n\n[1] 0.00 0.25 0.50   NA 1.00\n\n\nA medida que escribas más y más funciones eventualmente querrás convertir estos tests interactivos informales en tests formales y automatizados. Este proceso se llama pruebas unitarias (unit testing). Desafortunadamente, este tema está más allá del alcance de este libro, pero puedes aprender sobre él en https://r-pkgs.org/tests.html.\nPodemos simplificar el ejemplo original ahora que tenemos una función:\n\ndf$a &lt;- rescale01(df$a)\ndf$b &lt;- rescale01(df$b)\ndf$c &lt;- rescale01(df$c)\ndf$d &lt;- rescale01(df$d)\n\nComparado al original, este código es fácil de entender y hemos eliminado erorres del tipo copiar-y-pegar. Existe aún un poco de duplicación, ya que estamos relizando lo mismo en diferentes columnas. Aprenderemos cómo eliminar esta duplicación en el capítulo sobre [iteración], una vez que hayas aprendido más sobre las estructuras de R en el capítulo sobre [vectores].\nOtra ventaja de las funcioens es que si nuestros requerimientos cambian, solo necesitamos hacer modificaciones en un solo lugar. Por ejemplo, podríamos descubrir que algunas de nuestras variables incluyen valores infinitos, lo que hará que rescale01() falle:\n\nx &lt;- c(1:10, Inf)\nrescale01(x)\n\n [1]   0   0   0   0   0   0   0   0   0   0 NaN\n\n\nDebido a que hemos extraído el código en una función, solo necesitamos corregirlo en un lugar:\n\nrescale01 &lt;- function(x) {\n rng &lt;- range(x, na.rm = TRUE, finite = TRUE)\n (x - rng[1]) / (rng[2] - rng[1])\n}\nrescale01(x)\n\n [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n [8] 0.7777778 0.8888889 1.0000000       Inf\n\n\nEsta es una importante parte del principio de “no repetirse a uno mismo” (conocido como DRY: del inglés “Do not Repeat Yourself”). Cuanta más repetición tengas en tu código, más lugares tendrás que recordar de actualizar cuando las cosas cambien (¡y eso siempre sucede!), y es más probable que crees errores (bugs) a lo largo del tiempo.\n\n19.2.1 Ejercicios\n\n¿Por qué TRUE no es un parámetro para rescale01()? ¿Qué pasaría si x está contenido en un valor único perdido y na.rm fuese FALSE?\nEn la segunda variante de rescale01(), los valores infinitos se dejan sin cambio. Reescribe rescale01() para que -Inf sea convertido a 0, e Inf a 1.\nPractica convertir los siguientes fragmentos de código en funciones. Piensa en lo que hace cada función. ¿Cómo la llamarías? ¿Cuántos argumentos necesita? ¿Puedes reescribirla para ser más expresiva o con menos duplicación de código?\n  ::: {.cell}\n\n  ```{.r .cell-code}\n  mean(is.na(x))\n\n  x / sum(x, na.rm = TRUE)\n\n  sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)\n  ```\n  :::\nEscribe tus propias funciones para computar la varianza y la inclinación de un vector numérico. La varianza se define como \\[\n\\mathrm{Var}(x) = \\frac{1}{n - 1} \\sum_{i=1}^n (x_i - \\bar{x}) ^2 \\text{,}\n\\] donde \\(\\bar{x} = (\\sum_i^n x_i) / n\\) es la media de la muestra. La inclinación se define como \\[\n\\mathrm{Skew}(x) = \\frac{\\frac{1}{n-2}\\left(\\sum_{i=1}^n(x_i - \\bar x)^3\\right)}{\\mathrm{Var}(x)^{3/2}} \\text{.}\n\\]\nEscribe both_na() (ambos_na()), una función que toma dos vectores de la misma longitud y retorna el número de posiciones que tienen NA en ambos vectores.\n¿Qué hacen las siguientes funciones? ¿Por qué son tan útiles pese a ser tan cortas?\n  ::: {.cell}\n\n  ```{.r .cell-code}\n  is_directory &lt;- function(x) file.info(x)$isdir\n  is_readable &lt;- function(x) file.access(x, 4) == 0\n  ```\n  :::\nLee la letra completa de “Pequeño Conejito Foo Foo”. Como ves, hay mucha duplicación en la letra de la canción. Extiende el ejemplo inicial de pipes para recrear la canción completa usando funciones para reducir la duplicación."
  },
  {
    "objectID": "19-functions.html#las-funciones-son-para-los-seres-humanos-y-para-las-computadoras",
    "href": "19-functions.html#las-funciones-son-para-los-seres-humanos-y-para-las-computadoras",
    "title": "19  Funciones",
    "section": "19.3 Las funciones son para los seres humanos y para las computadoras",
    "text": "19.3 Las funciones son para los seres humanos y para las computadoras\nEs importante recordar que las funciones no son solo para las computadoras, sino también para los seres humanos. A R no le importa el nombre de tu función ni los comentarios que tiene, pero estos sí serán importantes para los seres humanos que la lean. En esta sección se discutirán algunas cosas que debes tener en mente a la hora de escribir funciones entendibles para otras personas.\nEl nombre de una función es importante. Idealmente, debería ser corto, pero que evoque claramente lo que la función hace. ¡Eso es difícil! Es mejor que sea claro a que sea corto, considerando que la función de autocompletar de RStudio hace más fácil tipear nombres largos.\nGeneralmente, los nombres de las funciones deberían ser verbos y los argumentos sustantivos. Hay algunas excepciones: usar un sustantivo está bien si la función computa el valor de un sustantivo muy conocido (por ejemplo, mean() — (del inglés media) es mejor que compute_mean()— (del inglés computar media)), o accede a alguna propiedad del objeto (por ejemplo, coef()— (abreviatura en inglés de coeficientes) es mejor que get_coefficients()— (en inglés, obtener coeficientes)). Una buena señal de que un sustantivo puede ser una mejor elección es analizar si estás usando un verbo muy amplio como “obtener”, “computar”, “calcular” o “determinar”. Utiliza tu criterio y no tengas miedo de renombrar tu función si encuentras un nombre mejor más tarde.\n\n# Muy corto\nf()\n\n# No es un verbo y es poco descriptivo\nmy_awesome_function()\n\n# Largos, pero descriptivos\nimputar_faltantes()\ncolapsar_anios()\n\nSi el nombre de tu función está compuesto por múltiples palabras, te recomendamos usar el formato serpiente, o “snake_case”, en el que cada palabra en minúscula está separada por un guión bajo. Otra alternativa popular es es camelCase, o formato camello. No importa realmente cuál elijas, lo importante es que seas consistente: elije uno o el otro y quédate con él. R mismo no es muy consistente, pero no hay nada que puedas hacer al respecto. Asegúrate de no caer en la misma trampa haciendo tu código lo más consistente posible.\n\n# ¡Nunca hagas esto!\ncol_mins &lt;- function(x, y) {}\nrowMaxes &lt;- function(y, x) {}\n\nSi tienes una familia de funciones que hacen cosas similares, asegúrate de que tengan nombres y argumentos consistentes. Utiliza un prefijo común para indicar que están conectadas. Eso es mejor que usar un sufijo común, ya que el autocompletado te permite escribir el prefijo y ver todos los otros miembros de la familia.\n\n# Bien\ninput_select()\ninput_checkbox()\ninput_text()\n\n# No tan bien\nselect_input()\ncheckbox_input()\ntext_input()\n\nUn buen ejemplo de este diseño es el paquete stringr: si no recuerdas exactamente qué función necesitas, puedes escribir str_y el autocompletado te ayudará a refrescar tu memoria. Siempre que sea posible, evita sobrescribir funciones y variables ya existentes. No siempre es posible hacer esto, ya que hay un montón de nombres buenos que ya han sido utilizados por otros paquetes. De todas maneras, evitar el uso de los nombres más comunes de R base ahorrará confusiones.\n\n# ¡No hagas esto!\nT &lt;- FALSE\nc &lt;- 10\nmean &lt;- function(x) sum(x)\n\nUsa comentarios, esto es, líneas que comienzan con #, para explicar el “porqué” de tu código. En general deberías evitar comentarios que expliquen el “qué” y el “cómo”. Si no se entiende qué es lo que hace el código leyéndolo, deberías pensar cómo reescribirlo de manera que sea más claro. ¿Necesitas agregar algunas variables intermedias con nombres útiles? ¿Deberías dividir una función larga en subcomponentes para que pueda ser nombrada? Sin embargo, tu código nunca podrá capturar la razón detrás de tus decisiones: ¿Por qué elegiste este enfoque frente a otras alternativas? ¿Qué otra cosa probaste que no funcionó? Es una gran idea capturar este tipo de pensamientos en un comentario.\nOtro uso importante de los comentarios es para dividir tu archivo en partes, de modo que resulte más fácil de leer. Utiliza líneas largas de- y = para que resulte más fácil detectar los fragmentos.\n\n# Cargar los datos --------------------------------------\n\n# Graficar los datos --------------------------------------\n\nRStudio proporciona un método abreviado de teclado para crear estos encabezados (Cmd/Ctrl + Shift + R), y los mostrará en el menú desplegable de navegación de código en la parte inferior izquierda del editor:\n\n\n\n\n\n\n19.3.1 Ejercicios\n\nLee el código fuente para cada una de las siguientes tres funciones, interpreta qué hacen y luego propone nombres mejores.\n  ::: {.cell}\n\n  ```{.r .cell-code}\n  f1 &lt;- function(string, prefix) {\n  substr(string, 1, nchar(prefix)) == prefix\n  }\n  f2 &lt;- function(x) {\n  if (length(x) &lt;= 1) return(NULL)\n  x[-length(x)]\n  }\n  f3 &lt;- function(x, y) {\n  rep(y, length.out = length(x))\n  }\n  ```\n  :::\nToma una función que hayas escrito recientemente y tómate 5 minutos para pensar un mejor nombre para la función y para sus argumentos.\nCompara y contrasta rnorm() y MASS::mvrnorm(). ¿Cómo podrías hacerlas más consistentes?\nArgumenta por qué norm_r(),norm_d(), etc. sería una mejor opción que rnorm(), dnorm(). Argumenta lo contrario."
  },
  {
    "objectID": "19-functions.html#ejecución-condicional",
    "href": "19-functions.html#ejecución-condicional",
    "title": "19  Funciones",
    "section": "19.4 Ejecución condicional",
    "text": "19.4 Ejecución condicional\nUna sentencia if (si) te permite ejecutar un código condicional. Por ejemplo:\n\nif (condition) {\n # el código que se ejecuta cuando la condición es verdadera (TRUE)\n} else {\n # el código que se ejecuta cuando la condición es falsa (FALSE)\n}\n\nPara obtener ayuda acerca de if necesitas ponerlo entre acentos graves: ?`if`. La ayuda no es especialmente útil si aún no tienens tanta experiencia programando. ¡Pero al menos puedes saber cómo llegar a ella!\nAquí se presenta una función simple que utiliza una sentencia if. El objetivo de esta función es devolver un vector lógico que describa si cada elemento de un vector tiene nombre (name).\n\ntiene_nombre &lt;- function(x) {\n nms &lt;- names(x)\n if (is.null(nms)) {\n rep(FALSE, length(x))\n } else {\n !is.na(nms) & nms != \"\"\n }\n}\n\nEsta función aprovecha la regla de retorno estándar: una función devuelve el último valor que calculó. Este es uno de los dos usos de la declaración if.\n\n19.4.1 Condiciones\nLa condición debe evaluar como TRUE o FALSE. Si es un vector, recibirás un mensaje de advertencia; si es una NA, obtendrás un error. Ten cuidado con estos mensajes en tu propio código:\n\nif (c(TRUE, FALSE)) {}\n\nError in if (c(TRUE, FALSE)) {: the condition has length &gt; 1\n\nif (NA) {}\n\nError in if (NA) {: missing value where TRUE/FALSE needed\n\n\nPuedes usar || (o) y &&(y) para combinar múltiples expresiones lógicas. Estos operadores hacen “cortocircuito”: tan pronto como || vea el primer TRUE devolverá TRUE sin calcular nada más. Tan pronto como && vea el primer FALSE, devolverá FALSE. Nunca debes usar|o & en una sentencia if: estas son operaciones vectorizadas que se aplican a valores múltiples (es por eso que las usas en filter()). Si tienes un vector lógico, puedes utilizar any() (cualquier) o all() (todo) para juntarlo en un único valor.\nTen cuidado al comprobar igualdad.== está vectorizado, lo que significa que es fácil obtener más de un output. Comprueba si la longitud ya es 1 y junta con all() o any(), o usa la función no vectorizada identical() (indéntico). identical() es una función muy estricta: siempre devuelve un solo TRUE o un solo FALSE, y no fuerza tipos de estructuras de datos. Esto significa que debes tener cuidado al comparar enteros y dobles:\n\nidentical(0L, 0)\n\n[1] FALSE\n\n\nTambién hay que tener cuidado con los números de punto flotante:\n\nx &lt;- sqrt(2) ^ 2\nx\n\n[1] 2\n\nx == 2\n\n[1] FALSE\n\nx - 2\n\n[1] 4.440892e-16\n\n\nEn su lugar, utiliza dplyr::near() para comparaciones, como se describe en la sección sobre [comparaciones].\nY recuerda, ¡x == NA no hace nada útil!\n\n\n19.4.2 Condiciones múltiples\nPuedes encadenar múltiples sentencias if juntas:\n\nif (this) {\n # haz aquello\n} else if (that) {\n # haz otra cosa\n} else {\n #\n}\n\nPero si terminas con una larga serie de sentencias if encadenadas, deberías considerar reescribir el código. Una técnica útil es la función switch() . Esta te permite evaluar el código seleccionado según la posición o el nombre.\n\n\nfunction(x, y, op) {\n switch(op,\n plus = x + y,\n minus = x - y,\n times = x * y,\n divide = x / y,\n stop(\"¡operación desconocida!\")\n )\n}\n\n\nOtra función útil que a menudo puede eliminar largas cadenas de sentencias if es cut() (cortar). Esta es utilizada para convertir en categóricas variables que son continuas.\n\n\n19.4.3 Estilo del código\nTanto if como function deberían ir (casi) siempre entre llaves ({}) y el contenido debería tener una sangría de dos espacios. Esto hace que sea más fácil distinguir la jerarquía dentro de tu código al mirar el margen izquierdo.\nLa llave de apertura nunca debe ir en su propia línea y siempre debe ir seguida de una línea nueva. Una llave de cierre siempre debe ir en su propia línea, a menos que sea seguida por else. Siempre ponle sangría al código que va dentro de las llaves.\n\n# Bien\nif (y &lt; 0 && debug) {\n message(\"Y es negativo\")\n}\n\nif (y == 0) {\n log(x)\n} else {\n y ^ x\n}\n\n# Mal\nif (y &lt; 0 && debug)\nmessage(\"Y is negative\")\n\nif (y == 0) {\n log(x)\n}\nelse {\n y ^ x\n}\n\nEstá bien evitar las llaves si tienes una sentencia if muy corta que cabe en una sola línea:\n\ny &lt;- 10\nx &lt;- if (y &lt; 20) \"Too low\" else \"Too high\"\n\nEsto se recomienda solo para sentencias if muy breves. De lo contrario, la sentencia completa es más fácil de leer:\n\nif (y &lt; 20) {\n x &lt;- \"Muy bajo\"\n} else {\n x &lt;- \"Muy alto\"\n}\n\n\n\n19.4.4 Ejercicios\n\n¿Cuál es la diferencia entre if e ifelse()? Lee cuidadosamente la ayuda y construye tres ejemplos que ilustren las diferencias clave.\nEscribe una función de saludo que diga “buenos días”, “buenas tardes” o “buenas noches”, según la hora del día. (Sugerencia: usa un argumento de tiempo que por defecto sea lubridate::now(); eso hará que sea más fácil testear tu función).\nImplementa una función fizzbuzz que tenga un solo número como input. Si el número es divisible por tres, devuelve “fizz”. Si es divisible por cinco, devuelve “buzz”. Si es divisible por tres y cinco, devuelve “fizzbuzz”. De lo contrario, devuelve el número. Asegúrate de escribir primero código que funcione antes de crear la función.\n¿Cómo podrías usar cut() (cortar()) para simplificar este conjunto de sentencias if-else anidadas?\n\n::: {.cell}\nif (temp &lt;= 0) {\n\"congelado\"\n} else if (temp &lt;= 10) {\n\"helado\"\n} else if (temp &lt;= 20) {\n\"fresco\"\n} else if (temp &lt;= 30) {\n\"tibio\"\n} else {\n\"caluroso\"\n}\n:::\n    ¿Cómo cambiarías la llamada a `cut()` si hubieras usado `&lt;`en lugar de `&lt;=`? ¿Cuál es la otra ventaja principal de `cut()` para este problema? (Pista: ¿qué sucede si tienes muchos valores en `temp`?)\n\n¿Qué sucede si usas switch() con un valor numérico?\n¿Qué hace la llamada a switch()? ¿Qué sucede si x fuera “e”?\n  ::: {.cell}\n\n  ```{.r .cell-code}\n  switch(x,\n  a = ,\n  b = \"ab\",\n  c = ,\n  d = \"cd\"\n  )\n  ```\n  :::\n\n\n Experimenta, luego lee cuidadosamente la documentación."
  },
  {
    "objectID": "19-functions.html#argumentos-de-funciones",
    "href": "19-functions.html#argumentos-de-funciones",
    "title": "19  Funciones",
    "section": "19.5 Argumentos de funciones",
    "text": "19.5 Argumentos de funciones\nLos argumentos de las funciones normalmente están dentro de dos conjuntos amplios: un conjunto provee los datos a computar y el otro los argumentos que controlan los detalles de la computación. Por ejemplo:\n\nEn log(), los datos son x, y los detalles son la base del algoritmo.\nEn mean(), los datos son x, y los detalles son la cantidad de datos para recortar de los extremos (trim) y cómo lidiar con los valores faltantes (na.rm).\nEn t.test(), los datos son x e y, y los detalles del test son alternative, mu, paired, var.equal, y conf.level.\nEn str_c() puedes suministrar cualquier número de caracteres a ..., y los detalles de la concatenación son contralos por sep y collapse.\n\nGeneralmente, argumentos relativos a los datos deben ir primero. El detalle de los mismos podría estar al final y con valores por defecto. Se especifica un valor por defecto de la misma manera en la que se llama a una función con un argumento nombrado:\n\n# Computar intervalo de confianza alrededor de la media usando la aproximación normal \nmean_ci &lt;- function(x, conf = 0.95) {\n se &lt;- sd(x) / sqrt(length(x))\n alpha &lt;- 1 - conf\n mean(x) + se * qnorm(c(alpha / 2, 1 - alpha / 2))\n}\n\nx &lt;- runif(100)\nmean_ci(x)\n\n[1] 0.4097739 0.5230831\n\nmean_ci(x, conf = 0.99)\n\n[1] 0.3919718 0.5408852\n\n\nEl valor por defecto debería ser casi siempre el valor más común. Las pocas excepciones que existen a esta regla deben realizarse con cuidado. Por ejemplo, tiene sentido que na.rm por defecto sea FALSE porque los valores faltantes son importantes. Aunque na.rm = TRUE es lo que usualmente pones en tu codigo, es una mala idea que el comportamiento por defecto sea ignorar silenciosamente los valores faltantes.\nCuando llamas una función, generalmente omites los nombres de los argumentos de datos justamente porque son los más comúnmente usados. Si quieres usar un valor distinto al por defecto en de un argumento de detalle, debes usar el nombre completo:\n\n# Bien\nmean(1:10, na.rm = TRUE)\n\n# Mal\nmean(x = 1:10, , FALSE)\nmean(, TRUE, x = c(1:10, NA))\n\nPuedes referirte a un argumento por su prefijo único (ej. mean(x, n = TRUE)), pero generalmente es mejor evitarlo dadas las posibilidades de confusión.\nTen en cuenta que cuando llamas a una función, debes colocar un espacio alrededor de = y siempre poner un espacio después de la coma, no antes (como cuando escribes en español). El uso del espacio en blanco hace más fácil echar un vistazo a la función para identificar los componentes importantes.\n\n# Bien\npromedio &lt;- mean(pies / 12 + pulgadas, na.rm = TRUE)\n\n# Mal\npromedio&lt;-mean(pies/12+pulgadas,na.rm=TRUE)\n\n\n19.5.1 Elección de nombres\nLos nombres de los argumentos también son importantes. A R no le importa, pero sí a quienes leen tu código (¡incluyéndo a tu futuro-yo!). En general, deberías preferir nombres largos y más descriptivos, aunque hay un puñado de nombres muy comunes y muy cortos. Vale la pena memorizar estos:\n\nx, y, z: vectores.\nw: un vector de pesos.\ndf: un data frame.\ni, j: índices numéricos (usualmente filas y columnas).\nn: longitud, o número de filas.\np: número de columnas.\n\nEn caso contrario, deberías considerar hacerlos coincidir con nombres de argumentos de funciones de R que ya existen. Por ejemplo, usa na.rm para determinar si los valores faltantes deberían ser eliminados.\n\n\n19.5.2 Chequear valores\nA medida que vayas escribiendo más funciones, eventualmente llegarás al punto en el que no recordarás cómo opera una determinada función. En este punto es común que llames a la función con inputs inválidos. Para evitar este problema, a menudo es útil hacer las restricciones explícitas. Por ejemplo, imagina que has escrito algunas funciones para calcular estadísticos de resumen ponderados:\n\nwt_mean &lt;- function(x, w) {\n sum(x * w) / sum(w)\n}\nwt_var &lt;- function(x, w) {\n mu &lt;- wt_mean(x, w)\n sum(w * (x - mu) ^ 2) / sum(w)\n}\nwt_sd &lt;- function(x, w) {\n sqrt(wt_var(x, w))\n}\n\n¿Qué pasa si x y w no son de la misma longitud?\n\nwt_mean(1:6, 1:3)\n\n[1] 7.666667\n\n\nEn este caso, debido a las reglas de reciclado de vectores de R, no obtenemos un error.\nEs una buena práctica verificar las condiciones previas importantes y arrojar un error (con stop(), parar), si estas no son verdaderas:\n\nwt_mean &lt;- function(x, w) {\n if (length(x) != length(w)) {\n stop(\"`x` y `w` deben tener la misma extensión\", call. = FALSE)\n }\n sum(w * x) / sum(w)\n}\n\nTen cuidado de no llevar esto demasiado lejos. Debe haber un equilibrio entre la cantidad de tiempo que inviertes en hacer que tu función sea sólida y la cantidad de tiempo que pasas escribiéndola. Por ejemplo, si además agregas a la función un argumento na.rm, probablemente no lo verificaste con cuidado:\n\nwt_mean &lt;- function(x, w, na.rm = FALSE) {\n if (!is.logical(na.rm)) {\n stop(\"`na.rm` debe ser lógico\")\n }\n if (length(na.rm) != 1) {\n stop(\"`na.rm` debe tener extensión 1\")\n }\n if (length(x) != length(w)) {\n stop(\"`x` y `w` deben tener la misma extensión\", call. = FALSE)\n }\n\n if (na.rm) {\n miss &lt;- is.na(x) | is.na(w)\n x &lt;- x[!miss]\n w &lt;- w[!miss]\n }\n sum(w * x) / sum(w)\n}\n\nEsto es mucho trabajo con poca ganancia adicional. Una opción útil es incorporar stopifnot(): esto comprueba que cada argumento sea TRUE. En caso contrario genera un mensaje de error.\n\nwt_mean &lt;- function(x, w, na.rm = FALSE) {\n stopifnot(is.logical(na.rm), length(na.rm) == 1)\n stopifnot(length(x) == length(w))\n\n if (na.rm) {\n miss &lt;- is.na(x) | is.na(w)\n x &lt;- x[!miss]\n w &lt;- w[!miss]\n }\n sum(w * x) / sum(w)\n}\nwt_mean(1:6, 6:1, na.rm = \"foo\")\n\nError in wt_mean(1:6, 6:1, na.rm = \"foo\"): is.logical(na.rm) is not TRUE\n\n\nTen en cuenta que al usar stopifnot() afirmas lo que debería ser cierto en lugar de verificar lo que podría estar mal.\n\n\n19.5.3 Punto-punto-punto (…)\nMuchas funciones en R tienen un número arbitrario de inputs:\n\nsum(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\n[1] 55\n\nstringr::str_c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\")\n\n[1] \"abcdef\"\n\n\n¿Cómo operan estas funciones? Estas se sostienen en un argumento especial: ... (llamado punto-punto-punto). Este argumento especial captura cualquier número de argumentos que no estén contemplados de otra forma.\nEs práctico porque puedes enviar estos ... a otra función. Este es un argumento multipropósito útil si tu función principalmente envuelve (wraps) a otra función. Por ejemplo, usualmente creamos estas funciones de ayuda alrededor de str_c():\n\ncommas &lt;- function(...) stringr::str_c(..., collapse = \", \")\ncommas(letters[1:10])\n\n[1] \"a, b, c, d, e, f, g, h, i, j\"\n\nrule &lt;- function(..., pad = \"-\") {\n title &lt;- paste0(...)\n width &lt;- getOption(\"width\") - nchar(title) - 5\n cat(title, \" \", stringr::str_dup(pad, width), \"\\n\", sep = \"\")\n}\nrule(\"Important output\")\n\nImportant output -----------------------------------------------------------\n\n\nAquí ... nos permite enviar cualquier argumento con el que no queramos lidiar hacia str_c(). Esto es muy conveniente, pero tiene un costo asociado: cualquier argumento mal escrito no generará un error. Esto hace que sea más fácil que los errores de tipeo pasen inadvertidos:\n\nx &lt;- c(1, 2)\nsum(x, na.mr = TRUE)\n\n[1] 4\n\n\nSi solo quieres capturar los valores de ..., entonces utiliza list(...).\n\n\n19.5.4 Evaluación diferida\nLos argumentos en R se evalúan de forma “perezosa”: no se computan hasta que se los necesita. Esto significa que si nunca se los usa, nunca son llamados. Esta es una propiedad importante de R como lenguaje de programación, pero generalmente no es fundamental cuando escribes tus propias funciones para el análisis de datos. Puedes leer más acerca de la evaluación diferida en https://adv-r.hadley.nz/functions.html#lazy-evaluation.\n\n\n19.5.5 Ejercicios\n\n¿Qué realiza commas(letters, collapse = \"-\")? ¿Por qué?\nSería bueno si se pudiera suministrar múltiples caracteres al argumento pad, por ejemplo, rule(\"Title\", pad = \"-+\"). ¿Por qué esto actualmente no funciona? ¿Cómo podrías solucionarlo?\n¿Qué realiza el argumento trim a la función mean()? ¿Cuándo podrías utilizarlo?\nEl valor de defecto del argumento method para cor() es c(\"pearson\", \"kendall\", \"spearman\"). ¿Qué significa esto? ¿Qué valor se utiliza por defecto?"
  },
  {
    "objectID": "19-functions.html#valores-de-retorno",
    "href": "19-functions.html#valores-de-retorno",
    "title": "19  Funciones",
    "section": "19.6 Valores de retorno",
    "text": "19.6 Valores de retorno\nDarse cuenta qué es lo que tu función debería devolver suele ser bastante directo: ¡es el porqué de crear la función en primer lugar! Hay dos cosas que debes considerar al retornar un valor:\n\n¿Devolver un valor antes hace que tu función sea más fácil de leer?\n¿Puedes hacer tu función apta para utilizarla con pipes (%&gt;%)?\n\n\n19.6.1 Sentencias de retorno explícitas\nEl valor devuelto por una función suele ser la última sentencia que esta evalúa; sin embargo, puedes optar por devolver algo anticipadamente haciendo uso de la función return() (retornar o devolver en inglés). Creemos que es mejor reservar el uso de la función return() para los casos en los que es posible devolver anticipadamente una solución más simple. Una razón común para hacer esto es que los argumentos estén vacíos:\n\ncomplicated_function &lt;- function(x, y, z) {\n if (length(x) == 0 || length(y) == 0) {\n return(0)\n }\n # Código complicado aquí\n}\n\nOtra razón puede ser porque tienes una sentencia if con un bloque complicado y uno sencillo. Por ejemplo, podrías escribir una sentencia if de esta manera:\n\nf &lt;- function() {\n if (x) {\n # Haz\n # algo\n # que\n # tome\n # muchas\n # líneas\n # para\n # ser\n # expresado\n } else {\n # retorna algo corto\n }\n}\n\nSi el primer bloque es muy largo, para cuando lleges al else ya te habrás olvidado de la condición. Una forma de reescribir esto es usar un retorno anticipado para el caso sencillo:\n\nf &lt;- function() {\n if (!x) {\n return(algo_corto)\n }\n\n # Haz\n # algo\n # que\n # tome\n # muchas\n # líneas\n # para\n # ser\n # expresado\n}\n\nEsto tiende a hacer el código más fácil de entender, ya que no necesitas tanto contexto para interpretarlo.\n\n\n19.6.2 Escribir funciones aptas para un pipe\nSi quieres escribir funciones que sean aptas para usarlas con un pipe (%&gt;%), es importante que pienses en los valores de retorno. Conocer el tipo de objeto de tu valor de retorno significará que tu secuencia de pipes “simplemente funcionará”. Por ejemplo, en dplyr y tidyr el tipo de objeto es un data frame.\nHay dos tipos básicos de funciones aptas para pipes: transformaciones y efectos secundarios. En las transformaciones, se ingresa un objeto como primer argumento y se retorna una versión modificada del mismo. En el caso de los efectos_secundarios, el objeto ingresado no es modificado, sino que la función realiza una acción sobre el objeto (como dibujar un gráfico o guardar un archivo). Las funciones de efectos secundarios deben retornar “invisiblemente” el primer argumento, de manera que aún cuando no se impriman, puedan ser utilizados en una secuencia de pipes. Por ejemplo, esta función imprime el número de valores faltantes en un data frame:\n\nmostrar_faltantes &lt;- function(df) {\n n &lt;- sum(is.na(df))\n cat(\"Valores faltantes: \", n, \"\\n\", sep = \"\")\n\n invisible(df)\n}\n\nSi la llamamos de manera interactiva, invisible() implica que el df input no se imprime:\n\nmostrar_faltantes(mtautos)\n\nValores faltantes: 0\n\n\nPero sigue estando ahí, solamente que no se imprime por defecto:\n\nx &lt;- mostrar_faltantes(mtautos)\n\nValores faltantes: 0\n\nclass(x)\n\n[1] \"data.frame\"\n\ndim(x)\n\n[1] 32 11\n\n\nY todavía podemos usarlo en un pipe:\n\nmtautos %&gt;%\n mostrar_faltantes() %&gt;%\n mutate(millas = ifelse(millas &lt; 20, NA, millas)) %&gt;%\n mostrar_faltantes()\n\nValores faltantes: 0\nValores faltantes: 18"
  },
  {
    "objectID": "19-functions.html#entorno",
    "href": "19-functions.html#entorno",
    "title": "19  Funciones",
    "section": "19.7 Entorno",
    "text": "19.7 Entorno\nEl último componente de una función es su entorno. Esto no es algo que debas entender con profundidad cuando recién empiezas a escribir funciones. Sin embargo, es importante saber un poco acerca de los entornos, ya que son cruciales para que algunas funciones trabajen. El entorno de una función controla cómo R encuentra el valor asociado a un nombre. Por ejemplo, toma la siguiente función:\n\nf &lt;- function(x) {\n x + y\n}\n\nEn muchos lenguajes de programación, esto sería un error, porque y no está definida dentro de la función. En R, esto es un código válido ya que R usa reglas llamadas de ámbito léxico (lexical scoping) para encontrar el valor asociado a un nombre. Como y no está definida dentro de la función, R mirará dentro del entorno donde la función fue definida:\n\ny &lt;- 100\nf(10)\n\n[1] 110\n\ny &lt;- 1000\nf(10)\n\n[1] 1010\n\n\nEste comportamiento parece una receta para errores (bugs) y, de hecho, debes evitar crear deliberadamente funciones como esta. Sin embargo, en líneas generales no causa demasiados problemas (especialmente si reinicias regularmente R para hacer borrón y cuenta nueva). La ventaja de este comportamiento es que, desde el punto de vista del lenguaje, permite que R sea muy consistente. Cada nombre es buscado usando el mismo conjunto de reglas. Para f() esto incluye el comportamiento de dos cosas que podrías no esperar: { y +. Esto te permite hacer cosas enrevesadas como la siguiente:\n\n`+` &lt;- function(x, y) {\n if (runif(1) &lt; 0.1) {\n sum(x, y)\n } else {\n sum(x, y) * 1.1\n }\n}\ntable(replicate(1000, 1 + 2))\n\n\n  3 3.3 \n100 900 \n\nrm(`+`)\n\nEste es un fenómeno común en R. R pone pocos límites a tu poder. Puedes hacer muchas cosas que no podrías hacer en otro lenguaje de programación. Puedes hacer cosas que el 99% de las veces son extremadamente desaconsejables (¡como sobrescribir manualmente cómo funciona la adición!). Pero este poder y flexibilidad es lo que hace que herramientas como ggplot2 y dplyr sean posibles. Aprender cómo hacer el mejor uso de esta flexibilidad está mas allá del alcance de este libro, pero puedes leer al respecto en Advanced R."
  },
  {
    "objectID": "20-vectors.html#introducción",
    "href": "20-vectors.html#introducción",
    "title": "20  Vectores",
    "section": "20.1 Introducción",
    "text": "20.1 Introducción\nHasta ahora este libro se ha enfocado en los tibbles y los paquetes que trabajan con ellos. Pero a medida que empieces a escribir tus propias funciones y a profundizar en R, es necesario que aprendas sobre vectores, esto es, sobre los objetos que están a la base de los tibbles. Si aprendiste R de una manera más tradicional, probablemente ya te hayas familiarizado con los vectores, ya que la mayoría de los recursos sobre R parten con vectores y luego abordan los tibbles. Creemos que es mejor empezar con los tibbles porque resultan útiles de inmediato y luego explorar los componentes que están a la base. Los vectores son particularmente importantes, ya que la mayoría de las funciones que escribirás trabajan con ellos. Es posible escribir funciones que trabajen con tibbles (como ggplot2, dplyr y tidyr); sin embargo, las herramientas que necesitas para hacerlo aún son idiosincráticas y no están lo suficientemente maduras. Estamos trabajando en una mejor aproximación (https://github.com/hadley/lazyeval), pero no estará lista a tiempo para la publicación del libro. Incluso aún cuando esté completa, será necesaro que entiendas los vectores: hará que sea más fácil escribir una capa amigable con el usuario encima de ellos.\n\n20.1.1 Prerrequisitos\nEste capítulo se enfoca en las estructuras de datos de R base, por lo que no es esencial cargar ningún paquete. Sin embargo, usaremos un conjunto de funciones del paquete purrr para evitar algunas inconsistencias de R base.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "20-vectors.html#vectores-básicos",
    "href": "20-vectors.html#vectores-básicos",
    "title": "20  Vectores",
    "section": "20.2 Vectores básicos",
    "text": "20.2 Vectores básicos\nHay dos tipos de vectores:\n\nVectores atómicos, de los cuales existen seis tipos: lógico, entero, doble, caracter, complejo y sin procesar (raw). Los vectores de tipo entero y doble son conocidos de manera colectiva como vectores numéricos.\nLas listas, que a veces son denominadas como vectores recursivos debido a que pueden contener otras listas.\n\nLa diferencia principal entre vectores atómicos y listas es que los vectores atómicos son homogéneos, mientras las listas pueden ser heterogéneas. Existe otro objeto relacionado: NULL (nulo). NULL es a menudo utilizado para representar la ausencia de un vector (en oposición a NA que se utiliza para representar la ausencia de un valor en un vector). NULL se comporta típicamente como un vector de longitud 0 (cero). La figura @ref(fig:datatypes) resume las interrelaciones.\n\n\n\n\n\nLa jerarquía de los tipos de vectores en R\n\n\n\n\nCada vector tiene dos propiedades clave:\n\nSu tipo (type), que puedes determinar con typeof() (tipo de).\n\n\n typeof(letters)\n\n[1] \"character\"\n\n typeof(1:10)\n\n[1] \"integer\"\n\n\n\nSu longitud (length), que puede determinar con length().\n\n\n x &lt;- list(\"a\", \"b\", 1:10)\n length(x)\n\n[1] 3\n\n\nLos vectores pueden contener también metadata adicional arbitraria en forma de atributos. Estos atributos son usados para crear vectores aumentados, los que se basan en un comportamiento distinto. Existen tres tipos de vectores aumentados: * Los factores (factors), construidos sobre la base de vectores de enteros. * Las fechas y fechas-hora (date-times), construidas a partir de vectores numéricos. * Los dataframes y tibbles, construidos a partir de listas.\nEste capítulo te introducirá en estos importantes vectores, desde los más simples a los más complicados. Comenzarás con vectores atómicos, luego seguirás con listas y finalizarás con vectores aumentados."
  },
  {
    "objectID": "20-vectors.html#tipos-importantes-de-vectores-atómicos",
    "href": "20-vectors.html#tipos-importantes-de-vectores-atómicos",
    "title": "20  Vectores",
    "section": "20.3 Tipos importantes de vectores atómicos",
    "text": "20.3 Tipos importantes de vectores atómicos\nLos cuatro tipos más importantes de vectores atómicos son lógico, entero, doble y carácter. Los de tipo raw y complejo son raramente usados durante el análisis de datos, por lo tanto, no discutiremos sobre ellos aquí.\n\n20.3.1 Lógico\nLos vectores de tipo lógico son el tipo más sencillo de vectores atómicos, ya que solo pueden tomar tres valores posibles: FALSE, TRUE y NA. Los vectores lógicos son construidos usualmente con operadores de comparación, tal como se describe en la sección [comparaciones]. También puedes crearlos manualmente con la función c():\n\n1:10 %% 3 == 0\n\n [1] FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE\n\nc(TRUE, TRUE, FALSE, NA)\n\n[1]  TRUE  TRUE FALSE    NA\n\n\n\n\n20.3.2 Numérico\nLos vectores de tipo entero y doble se conocen de manera colectiva como vectores numéricos. En R, los números por defecto son representados como double. Para generar un entero, coloca una L después del número:\n\ntypeof(1)\n\n[1] \"double\"\n\ntypeof(1L)\n\n[1] \"integer\"\n\n1.5L\n\n[1] 1.5\n\n\nLa distinción entre enteros y dobles usualmente no resulta importante, aunque existen dos diferencias relevantes de las que debes ser consciente:\n\nLos números dobles son aproximaciones. Representan números de punto flotante que no siempre pueden ser representados de manera precisa con un cantidad fija de memoria. Esto significa que debes considerar a todos los dobles como aproximaciones. Por ejemplo, ¿cuál es el cuadrado de la raíz cuadrada de dos?\n\n::: {.cell}\nx &lt;- sqrt(2) ^ 2\nx\n::: {.cell-output .cell-output-stdout} [1] 2 :::\nx - 2\n::: {.cell-output .cell-output-stdout} [1] 4.440892e-16 ::: :::\nEste comportamiento es común cuando trabajas con números de punto flotante: la mayoría de los cálculos incluyen algunos errores de aproximación. En lugar de comparar números de punto flotante usando ==, debes usar ´dplyr::near()`, que provee tolerancia numérica.\n\nLos números enteros tienen un valor especial, NA, mientras que los dobles tienen cuatro tipos: NA, NaN, Inf y –Inf. Los tres valores especiales NaN, Inf y -Inf pueden surgir durante una división:\n\n\nc(-1, 0, 1) / 0\n\n[1] -Inf  NaN  Inf\n\n\nEvita usar == para chequear estos valores especiales. En su lugar usa la funciones de ayuda is.finite(), is.infinite(), y is.nan():\n\n\n\n\n0\nInf\nNA\nNaN\n\n\n\n\nis.finite()\nx\n\n\n\n\n\nis.infinite()\n\nx\n\n\n\n\nis.na()\n\n\nx\nx\n\n\nis.nan()\n\n\n\nx\n\n\n\n\n\n20.3.3 Caracter\nLos vectores de caracteres son los tipos de vectores atómicos más complejos, ya que cada elemento del mismo es un string (una cadena de caracteres) y un string puede contener una cantidad arbitraria de datos. Ya has aprendido un montón acerca de cómo trabajar con strings en el capítulo sobre [Cadenas de caracteres]. Pero queremos mencionar una característica importante de la implementación que subyace a los strings: R usa una reserva global de strings. Esto significa que cada string único solo es almacenado en la memoria una vez y cada uso de un string apunta a esa representación. Esto reduce la cantidad de memoria necesaria para strings duplicados. Puedes ver este comportamiento en práctica con pryr::object_size():\n\nx &lt;- \"Esta es una cadena de caracteres razonablemente larga.\"\npryr::object_size(x)\n\n168 B\n\ny &lt;- rep(x, 1000)\npryr::object_size(y)\n\n8.16 kB\n\n\ny no utiliza 1000 veces más memoria que x, ya que cada elemento de y solo apunta al mismo string. Cada uno de estos punteros utiliza 8 bytes, por lo que 1000 punteros hacia un string de 168 B es igual a 8 * 1000 + 168 = 8.16 kB.\n\n\n20.3.4 Valores faltantes\nCada tipo de vector atómico tiene su propio valor faltante (missing value):\n\nNA # lógico\n\n[1] NA\n\nNA_integer_ # entero\n\n[1] NA\n\nNA_real_ # doble o real\n\n[1] NA\n\nNA_character_ # caracter\n\n[1] NA\n\n\nNormalmente no necesitas saber sobre los diferentes tipos porque siempre puedes usar NA (del inglés Not Available, no disponible), el que se convertirá al tipo correcto usando las reglas implícitas de coerción. Sin embargo, existen algunas funciones que son estrictas acerca de sus inputs, por lo que es útil tener presente este conocimiento, así tu código puede ser lo suficientemente específico cuando lo necesites.\n\n\n20.3.5 Ejercicios\n\nDescribe la diferencia entre is.finite(x) y !is.infinite(x).\nLee el código fuente de dplyr:: near() (Pista: para ver el código fuente, escribe el nombre de la función sin ()). ¿Funcionó?\nUn vector de tipo lógico puede tomar 3 valores posibles. ¿Cuántos valores posibles puede tomar un vector de tipo entero? ¿Cuántos valores posibles puede tomar un vector de tipo doble? Usa google para investigar sobre esto.\nIdea al menos 4 funciones que te permitan convertir un vector de tipo doble a entero. ¿En qué difieren las funciones? Describe las diferencias con precisión.\n¿Qué funciones del paquete readr te permiten convertir una cadena de caracteres en un vector de tipo lógico, entero y doble?"
  },
  {
    "objectID": "20-vectors.html#usando-vectores-atómicos",
    "href": "20-vectors.html#usando-vectores-atómicos",
    "title": "20  Vectores",
    "section": "20.4 Usando vectores atómicos",
    "text": "20.4 Usando vectores atómicos\nAhora que conoces los diferentes tipos de vectores atómicos, es útil repasar algunas herramientas importantes para trabajar con ellos. Estas incluyen:\n\nCómo realizar una conversión de un determinado tipo a otro y en qué casos esto sucede automáticamente.\nCómo decidir si un objeto es de un tipo específico de vector.\nQué sucede cuando trabajas con vectores de diferentes longitudes.\nCómo nombrar los elementos de un vector\nCómo extraer los elementos de interés de un vector.\n\n\n20.4.1 Coerción\nExisten dos maneras de convertir, o coercionar, un tipo de vector a otro:\n\nLa coerción explícita ocurre cuando llamas una función como as.logical(), as.integer(), as.double(), o as.character(). Cuando te encuentres usando coerción expíicita, comprueba si es posible hacer algún tipo de arreglo antes que permita que al vector nunca se le llegue a asignar el tipo incorrecto. Por ejemplo, podrías necesitar ajustar la especificación de col_types (tipos de columna) del paquete readr cuando importas los datos.\nLa coerción implícita ocurre cuando usas un vector en un contexto específico en el que se espera que sea de cierto tipo. Por ejemplo, cuando usas un vector de tipo lógico con la función numérica summary (resumen), o cuando usas un vector de tipo doble donde se espera que sea de tipo entero. Debido a que la coerción explícita se usa raramente y es mucho más fácil de entender, nos enfocaremos acá en la coerción implícita. Ya viste el tipo más importante de coerción implícita: cuando se usa un vector de tipo lógico en un contexto numérico. En ese caso, el valor TRUE es convertido a 1 y FALSE a 0. Esto significa que la suma de un vector de tipo lógico es el número de valores verdaderos, y que la media es de un vector lógico es la proporción de valores verdaderos:\n\n\nx &lt;- sample(20, 100, replace = TRUE)\ny &lt;- x &gt; 10\nsum(y) # ¿Cuántos valores son más grandes que 10?\n\n[1] 49\n\nmean(y) # ¿Qué proporción es mayor que 10?\n\n[1] 0.49\n\n\nQuizás veas código (usualmente más antiguo) que se basa en la coerción implícita en la dirección opuesta, es decir, de un valor entero a uno lógico:\n\nif (length(x)) {\n # hacer algo\n}\n\nEn este caso, 0 es convertido a FALSE y todo lo demás es convertido a TRUE. Creemos que esto hace que tu código sea más difícil de entender, por lo que no lo recomendamos. En su lugar, utiliza explícitamente: length(x) &gt; 0.\nEs también importante entender qué ocurre cuando creas un vector que contiene múltiples tipos usando c(): los tipos más complejos siempre ganan.\n\ntypeof(c(TRUE, 1L))\n\n[1] \"integer\"\n\ntypeof(c(1L, 1.5))\n\n[1] \"double\"\n\ntypeof(c(1.5, \"a\"))\n\n[1] \"character\"\n\n\nUn vector atómico no puede contener una mezcla de diferentes tipos, ya que el tipo es una propiedad del vector completo, no de los elementos individuales. Si necesitas mezclar diferentes tipos en el mismo vector, entonces deberías utilizar una lista, sobre la que aprenderás en breve.\n\n\n20.4.2 Funciones de prueba\nAlgunas veces quieres diferentes cosas dependiendo del tipo de vector. Una opción es utilizar typeof(); otra es usar una función de prueba que devuelva TRUE o FALSE. Si bien R base provee muchas funciones como is.vector() e is.atomic(), estas a menudo devuelven resultados inesperados. En su lugar, es más seguro utilizar las funciones is_* provistas por el paquete purrr, que se resumen en la tabla de más abajo.\n\n\n\n\nlgl\nint\ndbl\nchr\nlist\n\n\n\n\nis_logical()\nx\n\n\n\n\n\n\nis_integer()\n\nx\n\n\n\n\n\nis_double()\n\n\nx\n\n\n\n\nis_numeric()\n\nx\nx\n\n\n\n\nis_character()\n\n\n\nx\n\n\n\nis_atomic()\nx\nx\nx\nx\n\n\n\nis_list()\n\n\n\n\nx\n\n\nis_vector()\nx\nx\nx\nx\nx\n\n\n\n\n\n20.4.3 Escalares y reglas de reciclado\nAsí como se coercionan implícitamente los tipos de vectores para que sean compatibles, R también implicitamente coerciona la longitud de los vectores. Esto se denomina reciclado de vectores (vector recicling), debido a que el vector de menor longitud se repite, o recicla, hasta igualar la longitud del vector más largo. Generalmente, esto es más útil cuando estás trabajando con vectores y “escalares”. Hemos puesto “escalares” entre comillas porque R en realidad no tiene escalares: en su lugar, un solo número es un vector de longitud 1. Debido a que no existen los escalares, la mayoría de las funciones pre-definidas están vectorizadas, lo que implica que operarán en un vector de números. Esa es la razón de por qué, por ejemplo, el siguiente código funciona:\n\nsample(10) + 100 # (sample = muestreo)\n\n [1] 110 101 106 109 103 108 105 104 107 102\n\nrunif(10) &gt; 0.5\n\n [1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE\n\n\nEn R, las operaciones matemáticas básicas funcionan con vectores. Esto significa que nunca necesitarás la ejecución de una interacción explícita cuando realices cálculos matemáticos sencillos. Es intuitivo lo que debería pasar si agregas dos vectores de la misma longitud, o un vector y un “escalar”. Pero ¿qué sucede si agregas dos vectores de diferentes longitudes?\n\n1:10 + 1:2\n\n [1]  2  4  4  6  6  8  8 10 10 12\n\n\nAquí, R expandirá el vector más corto a la misma longitud del vector más largo, que es lo que denominamos reciclaje. Esto se realiza de manera silenciosa, excepto cuando la longitud del vector más largo no es un múltiplo entero de la longitud del vector más corto:\n\n1:10 + 1:3\n\nWarning in 1:10 + 1:3: longer object length is not a multiple of shorter object\nlength\n\n\n [1]  2  4  6  5  7  9  8 10 12 11\n\n\nSi bien el vector reciclado puede ser usado para crear código sucinto e ingenioso, también puede ocultar problemas de manera silenciosa. Por esta razón, las funciones vectorizadas en el tidyverse mostrarán errores cuando reciclas cualquier otra cosa que no sea un escalar. Si realmente quieres reutilizar, necesitarás hacerlo de manera explícita con rep():\n\ntibble(x = 1:4, y = 1:2)\n\nError in `tibble()`:\n! Tibble columns must have compatible sizes.\n• Size 4: Existing data.\n• Size 2: Column `y`.\nℹ Only values of size one are recycled.\n\ntibble(x = 1:4, y = rep(1:2, 2))\n\n# A tibble: 4 × 2\n      x     y\n  &lt;int&gt; &lt;int&gt;\n1     1     1\n2     2     2\n3     3     1\n4     4     2\n\ntibble(x = 1:4, y = rep(1:2, each = 2))\n\n# A tibble: 4 × 2\n      x     y\n  &lt;int&gt; &lt;int&gt;\n1     1     1\n2     2     1\n3     3     2\n4     4     2\n\n\n\n\n20.4.4 Nombrar vectores\nTodos los tipos de vectores pueden ser nombrados. Puedes asignarles un nombre al momento de crearlos con c():\n\nc(x = 1, y = 2, z = 4)\n\nx y z \n1 2 4 \n\n\nO después de haberlos creado con purrr::set_names():\n\nset_names(1:3, c(\"a\", \"b\", \"c\"))\n\na b c \n1 2 3 \n\n\nLos vectores con nombres son particularmente útiles para la creación de subconjuntos, como se describe a continuación.\n\n\n20.4.5 Creación de subconjuntos (subsetting)\nHasta ahora hemos utilizado dplyr::filter() para filtrar filas en un tibble. filter() solo funciona con tibbles, por lo que necesitaremos una nueva herramienta para trabajar con vectores: [. [ es la función para crear subconjuntos (subsetting) y podemos llamarla como x[a]. Existen cuatro tipos de cosas con las que puedes un crear un subset de un vector:\n\nUn vector numérico que contenga solo enteros. Los enteros deben ser todos positivos, todos negativos, o cero.\n Crear subconjuntos con enteros positivos mantiene los elementos en aquellas posiciones:\n\n\nx &lt;- c(\"uno\", \"dos\", \"tres\", \"cuatro\", \"cinco\")\nx[c(3, 2, 5)]\n\n[1] \"tres\"  \"dos\"   \"cinco\"\n\n\n    Repitiendo una posición, puedes en realidad generar un output de mayor longitud que el input:\n    \n\nx[c(1, 1, 5, 5, 5, 2)]\n\n[1] \"uno\"   \"uno\"   \"cinco\" \"cinco\" \"cinco\" \"dos\"  \n\n\n    Los valores negativos eliminan elementos en las posiciones especificadas:\n    \n\nx[c(-1, -3, -5)]\n\n[1] \"dos\"    \"cuatro\"\n\n\n    Es un error mezclar valores positivos y negativos:\n    \n    \n\nx[c(1, -1)]\n\nError in x[c(1, -1)]: only 0's may be mixed with negative subscripts\n\n\n    El mensaje menciona crear subsets utilizando cero, lo que no retorna valores.\n    \n\nx[0]\n\ncharacter(0)\n\n\n    Esto a menudo no es útil, pero puede ser de ayuda si quieres crear estructuras de datos inusuales con las que testear tus funciones.\n    \n\nCrear subsets con un vector lógico mantiene todos los valores que correspondan al valor TRUE. Esto es usualmente útil en conjunto con las funciones de comparación.\n\n\nx &lt;- c(10, 3, NA, 5, 8, 1, NA)\n        \n# Todos los valores no faltantes de x\nx[!is.na(x)]\n\n[1] 10  3  5  8  1\n\n# Todos los valores pares (o faltantes!) de x\nx[x %% 2 == 0]\n\n[1] 10 NA  8 NA\n\n\n\nSi tienes un vector con nombre, puedes subdivirlo en un vector de tipo caracter.\n\n\nx &lt;- c(abc = 1, def = 2, xyz = 5)\nx[c(\"xyz\", \"def\")]\n\nxyz def \n  5   2 \n\n\n    Al igual que con los enteros positivos, también puedes usar un vector del tipo caracter para duplicar entradas individuales.\n\nEl tipo más sencillo de subsetting es nada, x[], lo que retorna el valor completo de x. Esto no es útil para crear subconjuntos de vectores, pero sí lo es para el caso de las matrices (y otras estructuras de alta dimensionalidad), ya que te permite seleccionar toda las filas o todas las columnas, dejando el índice en blanco. Por ejemplo, si x tiene dos dimensiones, x[1, ] selecciona la primera fila y todas las columnas y x[, -1] selecciona todas las filas y todas las columnas excepto la primera.\n\nPara aprender más acerca de las aplicaciones de la creación de subconjuntos, puedes leer el capítulo “Subsetting” de Advanced R: http://adv-r.hadley.nz/Subsetting.html#applications.\nExiste una importante variación de [ llamada [[. [[ solo extrae un único elemento y siempre descarta nombres. Es una buena idea usarla cada vez que quieras dejar en claro que estás extrayendo un único item, como en un bucle for (for loop). La diferencia entre [ y[[ es más importante para el caso de las listas, como veremos en breve.\n\n\n20.4.6 Ejercicios\n\n¿Qué es lo que mean(is.na(x)) te dice acerca del vector ‘x’? ¿Y qué es lo que te dice sum(!is.finite(x))?\nLee detenidamente la documentación de is.vector(). ¿Qué es lo que esta función realmente testea? ¿Por qué la función is.atomic() no concuerda con la definición de vectores atómicos vista anteriormente?\nCompara y contrasta setNames() con purrr::set_names().\nCrea funciones que tomen un vector como input y devuelvan:\n\nEl último valor. ¿Deberías usar [ o [[?\nLos elementos en posiciones pares.\nCada elemento excepto el último valor.\nSolo las posiciones pares (sin valores perdidos).\n\n¿Por qué x[-which(x &gt; 0)] no es lo mismo que x[x &lt;= 0]?\n¿Qué sucede cuando realizas un subset con un entero positivo que es mayor que la longitud del vector? ¿Qué sucede cuando realizas un subset con un nombre que no existe?"
  },
  {
    "objectID": "20-vectors.html#vectores-recursivos-listas",
    "href": "20-vectors.html#vectores-recursivos-listas",
    "title": "20  Vectores",
    "section": "20.5 Vectores Recursivos (listas)",
    "text": "20.5 Vectores Recursivos (listas)\nLas listas son un escalón más en complejidad respecto de los vectores atómicos, ya que pueden contener otras listas en su interior. Esto las hace adecuadas para representar estructuras jerárquicas o de tipo árbol. Puedes crear una lista con ´list()´:\n\nx &lt;- list(1, 2, 3) \nx\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] 3\n\n\nUn herramienta muy útil para trabajar con listas es str() ya que se enfoca en la estructura, no en los contenidos.\n\nstr(x)\n\nList of 3\n $ : num 1\n $ : num 2\n $ : num 3\n\nx_nombrada &lt;- list(a = 1, b = 2, c = 3)\nstr(x_nombrada)\n\nList of 3\n $ a: num 1\n $ b: num 2\n $ c: num 3\n\n\nA diferencia de los vectores atómicos, ´list()´ puede contener una mezcla de objetos:\n\ny &lt;- list(\"a\", 1L, 1.5, TRUE)\nstr(y)\n\nList of 4\n $ : chr \"a\"\n $ : int 1\n $ : num 1.5\n $ : logi TRUE\n\n\n¡Las listas incluso pueden contener otras listas!\n\nz &lt;- list(list(1, 2), list(3, 4))\nstr(z)\n\nList of 2\n $ :List of 2\n  ..$ : num 1\n  ..$ : num 2\n $ :List of 2\n  ..$ : num 3\n  ..$ : num 4\n\n\n\n20.5.1 Visualizando listas\nPara explicar funciones de manipulación de listas más complejas, es útil tener una representacion visual de las listas. Por ejemplo, considera estas tres listas:\n\nx1 &lt;- list(c(1, 2), c(3, 4))\nx2 &lt;- list(list(1, 2), list(3, 4))\nx3 &lt;- list(1, list(2, list(3)))\n\nAsí es como las representaremos visualmente:\n\n\n\n\n\nExisten tres principios en la imagen anterior:\n\nLas listas tienen esquinas redondeadas; los vectores atómicos esquinas cuadradas.\nLos elementos hijos están dibujados dentro de sus padres y tienen un fondo ligeramente más oscuro para facilitar la visualización de la jerarquía.\nNo es importante la orientación de los elementos hijos (esto es, las filas o columnas), por lo que si elegimos determinada orientación será para ahorrar espacio o para ilustrar una propiedad importante en el ejemplo.\n\n\n\n20.5.2 Subconjuntos (Subsetting)\nExisten tres maneras de extraer subconjuntos de una lista, los que ilustraremos con una lista denominada a:\n\na &lt;- list(a = 1:3, b = \"una cadena\", c = pi, d = list(-1, -5))\n\n\nEl corchete simple [ extrae una sub-lista. El resultado siempre será una lista.\n\n\nstr(a[1:2])\n\nList of 2\n $ a: int [1:3] 1 2 3\n $ b: chr \"una cadena\"\n\nstr(a[4])\n\nList of 1\n $ d:List of 2\n  ..$ : num -1\n  ..$ : num -5\n\n\n    Al igual que con los vectores, puedes extraer subconjuntos con un vector lógico, de enteros o de caracteres.\n\nEl doble corchete [[ extrae un solo componente de una lista. Elimina un nivel de la jerarquía de la lista.\n\n\nstr(a[[1]])\n\n int [1:3] 1 2 3\n\nstr(a[[4]])\n\nList of 2\n $ : num -1\n $ : num -5\n\n\n\n$ es un atajo para extraer elementos con nombre de una lista. Funciona de modo similar al doble corchete [[, excepto que no necesitas utilizar comillas.\n\n\na$a\n\n[1] 1 2 3\n\na[[\"a\"]]\n\n[1] 1 2 3\n\n\nLa diferencia entre [ y [[ es muy importante para las listas, ya que [[ se adentra en una lista mientras que [ retorna una lista nueva, más pequeña. Compara el código y el output de arriba con la representación visual de la Figura @ref(fig:lists-subsetting).\n\n\n\n\n\nSubdividir una lista, de manera visual.\n\n\n\n\n\n\n20.5.3 Listas de Condimentos\nLa diferencia entre [ y [[ es muy importante, pero es muy fácil confundirse. Para ayudarte a recordar, te mostraremos un pimentero inusual.\n\n\n\n\n\nSi este pimientero es tu lista x, entonces, x[1] es un pimientero que contiene un solo paquete de pimienta:\n\n\n\n\n\nx[2] luciría igual, pero contendría el segundo paquete. x[1:2] sería un pimentero que contiene dos paquetes de pimienta.\nx[[1]] es:\n\n\n\n\n\nSi quisieras obtener el contenido del paquete de pimienta, necesitarías utilizar x[[1]][[1]:\n\n\n\n\n\n\n\n20.5.4 Ejercicios\n1.Dibuja las siguientes listas como sets anidados:\n    1. `list(a, b, list(c, d), list(e, f))`\n    1. `list(list(list(list(list(list(a))))))`\n2.¿Qué pasaría si hicieras subsetting a un tibble como si fuera una lista? ¿Cuáles son las principales diferencias entre una lista y un tibble?"
  },
  {
    "objectID": "20-vectors.html#atributos",
    "href": "20-vectors.html#atributos",
    "title": "20  Vectores",
    "section": "20.6 Atributos",
    "text": "20.6 Atributos\nCualquier vector puede contener metadatos arbitrarios adicionales mediante sus atributos. Puedes pensar en los atributos como una lista de vectores con nombre que pueden ser adjuntadas a cualquier otro objeto. Puedes obtener y definir valores de atributos individuales con attr() o verlos todos al mismo tiempo con attributes().\n\nx &lt;- 1:10\nattr(x, \"saludo\")\n\nNULL\n\nattr(x, \"saludo\") &lt;- \"¡Hola!\"\nattr(x, \" despedida\") &lt;- \"¡Adiós!\"\nattributes(x)\n\n$saludo\n[1] \"¡Hola!\"\n\n$` despedida`\n[1] \"¡Adiós!\"\n\n\nExisten tres atributos muy importantes que son utilizados para implementar partes fundamentals de R:\n\nLos nombres son utilizados para nombrar los elementos de un vector.\nLas dimensiones (o dims, abreviado) hacen que un vector se comporte como una matriz o array.\nLa clase es utilizada para implementar el sistema orientado a objetos S3.\n\nYa revisamos los nombres más arriba y no abordaremos las dimensiones porque en este libro no utilizamos matrices. Nos queda describir el atributo clase, que controla cómo trabajan las funciones genéricas. Las funciones genéricas son clave para la programación orientada a objetos en R, ya que hacen que las funciones se comporten de manera diferente para diferentes clases de inputs. Está fuera del alcance de este libro tener una discusión más profunda sobre la programacion orientada a objetos, pero puedes leer más al respecto en el libro Advanced R: https://adv-r.hadley.nz/s3.html.\nAsí es como luce una función genérica típica:\n\nas.Date\n\nfunction (x, ...) \nUseMethod(\"as.Date\")\n&lt;bytecode: 0x55a8d3dbcdd0&gt;\n&lt;environment: namespace:base&gt;\n\n\nLa llamada a “UseMethod” significa que esta es una función genérica y que llamará a un método específico, esto es, una función basada en la clase del primer argumento. (Todos los métodos son funciones; no todas las funciones son métodos). Puedes listar todos los métodos existentes para una función genérica con methods():\n\nmethods(\"as.Date\")\n\n[1] as.Date.character*  as.Date.default*    as.Date.factor*    \n[4] as.Date.numeric*    as.Date.POSIXct*    as.Date.POSIXlt*   \n[7] as.Date.vctrs_sclr* as.Date.vctrs_vctr*\nsee '?methods' for accessing help and source code\n\n\nPor ejemplo, si x es un vector de caracteres, as.Date() llamará a as.Date.character(); si es un factor, llamará a as.Date.factor().\nPuedes ver la implementación específica de un método con: getS3method():\n\ngetS3method(\"as.Date\", \"default\")\n\nfunction (x, ...) \n{\n    if (inherits(x, \"Date\")) \n        x\n    else if (is.null(x)) \n        .Date(numeric())\n    else if (is.logical(x) && all(is.na(x))) \n        .Date(as.numeric(x))\n    else stop(gettextf(\"do not know how to convert '%s' to class %s\", \n        deparse1(substitute(x)), dQuote(\"Date\")), domain = NA)\n}\n&lt;bytecode: 0x55a8d963d118&gt;\n&lt;environment: namespace:base&gt;\n\ngetS3method(\"as.Date\", \"numeric\")\n\nfunction (x, origin, ...) \nif (missing(origin)) .Date(x) else as.Date(origin, ...) + x\n&lt;bytecode: 0x55a8d969d198&gt;\n&lt;environment: namespace:base&gt;\n\n\nLa S3 genérica más importante es print(): controla cómo el objeto es impreso cuando tipeas su nombre en la consola. Otras funciones genéricas importantes son las funciones de subconjuntos [, [[ y $."
  },
  {
    "objectID": "20-vectors.html#vectores-aumentados",
    "href": "20-vectors.html#vectores-aumentados",
    "title": "20  Vectores",
    "section": "20.7 Vectores aumentados",
    "text": "20.7 Vectores aumentados\nLos vectores atómicos y las listas son los bloques sobre los que se construyen otros tipos importantes de vectores, como factores y fechas. A estos vectores le llamamos vectores aumentados, ya que son vectores con atributos adicionales, incluyendo la clase. Debido a que los vectores aumentados tienen una clase, se comportan de manera diferente a los vectores atómicos sobre los que están construidos. En este libro, hacemos uso de cuatro importantes vectores aumentados:\n\nFactores\nFechas\nFechas-hora\nTibbles\n\nA continuación encontrarás una descripción de cada uno de ellos.\n\n20.7.1 Factores\nLos factores están diseñados para representar datos categóricos que pueden tomar un set fijo de valores posibles. Están construidos sobre la base de enteros y tienen un atributo de niveles (levels):\n\nx &lt;- factor(c(\"ab\", \"cd\", \"ab\"), levels = c(\"ab\", \"cd\", \"ef\"))\ntypeof(x)\n\n[1] \"integer\"\n\nattributes(x)\n\n$levels\n[1] \"ab\" \"cd\" \"ef\"\n\n$class\n[1] \"factor\"\n\n\n\n\n20.7.2 Fechas y fechas-hora\nLas fechas en R son vectores numéricos que representan el número de días desde el 1° de enero de 1970.\n\nx &lt;- as.Date(\"1971-01-01\")\nunclass(x)\n\n[1] 365\n\ntypeof(x)\n\n[1] \"double\"\n\nattributes(x)\n\n$class\n[1] \"Date\"\n\n\nLos vectores fecha-hora son vectores numéricos de clase POSIXct, que representan el número de segundos desde el 1° de enero de 1970. (En caso de que te lo preguntes, “POSIXct” es el acrónimo de “Portable Operating System Interface” calendar time, es decir, tiempo calendario de la interfaz portable del sistema operativo”)\n\nx &lt;- lubridate::ymd_hm(\"1970-01-01 01:00\")\nunclass(x)\n\n[1] 3600\nattr(,\"tzone\")\n[1] \"UTC\"\n\ntypeof(x)\n\n[1] \"double\"\n\nattributes(x)\n\n$class\n[1] \"POSIXct\" \"POSIXt\" \n\n$tzone\n[1] \"UTC\"\n\n\nEl atributo tzone es opcional. Controla cómo se imprime la hora, no a qué tiempo absoluto hace referencia.\n\nattr(x, \"tzone\") &lt;- \"US/Pacific\"\nx\n\n[1] \"1969-12-31 17:00:00 PST\"\n\nattr(x, \"tzone\") &lt;- \"US/Eastern\"\nx\n\n[1] \"1969-12-31 20:00:00 EST\"\n\n\nExiste otro tipo de fechas-hora llamado POSIXlt. Estos se construyen sobre la base de listas nombradas (named lists).\n\ny &lt;- as.POSIXlt(x)\ntypeof(y)\n\n[1] \"list\"\n\nattributes(y)\n\n$names\n [1] \"sec\"    \"min\"    \"hour\"   \"mday\"   \"mon\"    \"year\"   \"wday\"   \"yday\"  \n [9] \"isdst\"  \"zone\"   \"gmtoff\"\n\n$class\n[1] \"POSIXlt\" \"POSIXt\" \n\n$tzone\n[1] \"US/Eastern\" \"EST\"        \"EDT\"       \n\n$balanced\n[1] TRUE\n\n\nLos POSIXlts son pocos comunes dentro del tidyverse. Sí lo son en R base, ya que son necesarios para extraer components específicos de una fecha, como el año o el mes. Debido a que el paquete lubridate provee funciones de ayuda para efectuar dicha extracción, ya no los necesitarás. Siempre es más sencillo trabajar con POSIXct, por lo que si te encuentras con un POSIXlt, deberías convertirlo a un vector de fecha-hora con lubridate::as_date_time().\n\n\n20.7.3 Tibbles\nLos tibbles son listas aumentadas: tienen las clases “tbl_df”, “tbl” y “data.frame”, y atributos names (para columna) y row.names (para fila):\n\ntb &lt;- tibble::tibble(x = 1:5, y = 5:1)\ntypeof(tb)\n\n[1] \"list\"\n\nattributes(tb)\n\n$class\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$row.names\n[1] 1 2 3 4 5\n\n$names\n[1] \"x\" \"y\"\n\n\nLa diferencia entre un tibble y una lista, consiste en que todos los elementos de un data frame deben ser vectores de la misma longitud. Todas las funciones que utilizan tibbles imponen esta condición.\nLos data.frames tradicionales tienen una estructura muy similar a los tibbles:\n\ndf &lt;- data.frame(x = 1:5, y = 5:1)\ntypeof(df)\n\n[1] \"list\"\n\nattributes(df)\n\n$names\n[1] \"x\" \"y\"\n\n$class\n[1] \"data.frame\"\n\n$row.names\n[1] 1 2 3 4 5\n\n\nLa diferencia principal entre ambos es la clase. La clase tibble incluye “data.frame”, lo que significa que los tibbles heredan el comportamiento regular de un data frame por defecto.\n\n\n20.7.4 Ejercicios:\n\n¿Qué valor retorna hms::hms(3600)? ¿Cómo se imprime? ¿Cuál es la tipo primario sobre en el que se basa el vector aumentado? ¿Qué atributos utiliza?\nIntenta crear un tibble que tenga columnas con diferentes longitudes. ¿Qué es lo que ocurre?\nTeniendo en cuenta la definición anterior, ¿está bien tener una lista como columna en un tibble?"
  },
  {
    "objectID": "21-iteration.html#introducción",
    "href": "21-iteration.html#introducción",
    "title": "21  Iteración",
    "section": "21.1 Introducción",
    "text": "21.1 Introducción\nEn [funciones], hablamos sobre la importancia de reducir la duplicación en el código creando funciones, en lugar de copiar y pegar. Reducir la duplicación de código tiene tres beneficios principales:\n\nEs más fácil ver el objetivo de tu código; lo diferente llama más atención a la vista que aquello que permanece igual.\nEs más sencillo responder a cambios en los requerimientos. A medida que tus necesidades cambian, solo necesitarás realizar cambios en un lugar, en vez de recordar cambiar en cada lugar donde copiaste y pegaste el código.\nEs probable que tengas menos errores porque cada línea de código es utilizada en más lugares.\n\nUna herramienta para reducir la duplicación de código son las funciones, que reducen dicha duplicación al identificar patrones repetidos de código y extraerlos en piezas independientes que pueden reutilizarse y actualizarse fácilmente. Otra herramienta para reducir la duplicación es la iteración, que te ayuda cuando necesitas hacer la misma tarea con múltiples entradas: repetir la misma operación en diferentes columnas o en diferentes conjuntos de datos. En este capítulo aprenderás sobre dos paradigmas de iteración importantes: la programación imperativa y la programación funcional. Por el lado imperativo, tienes herramientas como for loops y while loops, que son un gran lugar para comenzar porque hacen que la iteración sea muy explícita, por lo que es obvio qué está pasando. Sin embargo, los bucles for son bastante detallados y requieren bastante código que se duplica para cada bucle. La programación funcional (PF) ofrece herramientas para extraer este código duplicado, por lo que cada patrón común de bucle obtiene su propia función. Una vez que domines el vocabulario de PF, podrás resolver muchos problemas comunes de iteración con menos código, mayor facilidad y menos errores.\n\n21.1.1 Prerrequisitos\nUna vez que hayas dominado los bucles for proporcionados por R base, aprenderás algunas de las potentes herramientas de programación proporcionadas por purrr, uno de los paquetes principales de tidyverse.\n\nlibrary(tidyverse)\nlibrary(datos)"
  },
  {
    "objectID": "21-iteration.html#bucles-for",
    "href": "21-iteration.html#bucles-for",
    "title": "21  Iteración",
    "section": "21.2 Bucles for",
    "text": "21.2 Bucles for\nImagina que tenemos este simple tibble:\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\nQueremos calcular la mediana de cada columna. Podrías hacerlo copiando y pegando el siguiente código:\n\nmedian(df$a)\n\n[1] -0.2319488\n\nmedian(df$b)\n\n[1] 0.3469402\n\nmedian(df$c)\n\n[1] 0.2954221\n\nmedian(df$d)\n\n[1] 0.1232375\n\n\nPero eso rompe nuestra regla de oro: nunca copiar y pegar más de dos veces. En cambio, podríamos usar un bucle for:\n\noutput &lt;- vector(\"double\", ncol(df))  # 1. output\nfor (i in seq_along(df)) {            # 2. secuencia\n  output[[i]] &lt;- median(df[[i]])      # 3. cuerpo\n}\noutput\n\n[1] -0.2319488  0.3469402  0.2954221  0.1232375\n\n\nCada bucle tiene tres componentes:\n\noutput: output &lt;- vector(\"double\", length(x)). Antes de comenzar el bucle, siempre debes asignar suficiente espacio para la salida. Esto es muy importante para la eficiencia: si aumentas el bucle for en cada iteración usando, por ejemplo, c () , el bucle for será muy lento.\nUna forma general de crear un vector vacío de longitud dada es la función vector(). Tiene dos argumentos: el tipo de vector (“logical”, “integer”, “double”, “character”, etc) y su longitud.\nLa secuencia: i in seq_along (df). Este código determina sobre qué iterar: cada ejecución del bucle for asignará a i un valor diferente de seq_along (df). Es útil pensar en i como un pronombre, como “eso”.\nEs posible que no hayas visto seq_along () con anterioridad. Es una versión segura de la más familiar 1:length(l), con una diferencia importante: si se tiene un vector de longitud cero, seq_along () hace lo correcto:\n\ny &lt;- vector(\"double\", 0)\nseq_along(y)\n\ninteger(0)\n\n1:length(y)\n\n[1] 1 0\n\n\nProbablemente no vas a crear un vector de longitud cero deliberadamente, pero es fácil crearlos accidentalmente. Si usamos 1: length (x) en lugar de seq_along (x), es posible que obtengamos un mensaje de error confuso.\nEl cuerpo: output[[i]] &lt;- median(df[[i]]). Este es el código que hace el trabajo. Se ejecuta repetidamente, con un valor diferente para i cada vez. La primera iteración ejecutará output[[1]] &lt;- median(df[[1]]), la segunda ejecutará output [[2]] &lt;- median (df [[2]]), y así sucesivamente.\n\n¡Eso es todo lo que hay para el bucle for! Ahora es un buen momento para practicar creando algunos bucles for básicos (y no tan básicos) usando los ejercicios que se encuentran a continuación. Luego avanzaremos en algunas variaciones de este bucle que te ayudarán a resolver otros problemas que surgirán en la práctica.\n\n21.2.1 Ejercicios\n\nEscribe bucles for para:\n\nCalcular la media de cada columna en datos::mtautos.\nDeterminar el tipo de cada columna en datos::vuelos.\nCalcular el número de valores únicos en cada columna de datos::flores.\nGenerar diez normales aleatorias de distribuciones con medias -10, 0, 10 y 100.\n\nPiensa en el resultado, la secuencia y el cuerpo antes de empezar a escribir el bucle.\nElimina el bucle for en cada uno de los siguientes ejemplos aprovechando alguna función existente que trabaje con vectores:\n\nout &lt;- \"\"\nfor (x in letters) {\n  out &lt;- stringr::str_c(out, x)\n}\n\nx &lt;- sample(100)\nsd &lt;- 0\nfor (i in seq_along(x)) {\n  sd &lt;- sd + (x[i] - mean(x)) ^ 2\n}\nsd &lt;- sqrt(sd / (length(x) - 1))\n\nx &lt;- runif(100)\nout &lt;- vector(\"numeric\", length(x))\nout[1] &lt;- x[1]\nfor (i in 2:length(x)) {\n  out[i] &lt;- out[i - 1] + x[i]\n}\n\nCombina tus habilidades para escribir funciones y bucles for:\n\nEscribe un bucle for que imprima (prints()) la letra de la canción de niños “Cinco ranitas verdes” (u otra).\nConvierte la canción infantil “Cinco monitos saltaban en la cama” en una función. Generalizar a cualquier cantidad de monitos en cualquier estructura para dormir.\nConvierte la canción “99 botellas de cerveza en la pared” en una función. Generalizar a cualquier cantidad, de cualquier tipo de recipiente que contenga cualquier líquido sobre cualquier superficie.\n\nEs común ver bucles for que no preasignan el output y en su lugar aumentan la longitud de un vector en cada paso:\n\noutput &lt;- vector(\"integer\", 0)\nfor (i in seq_along(x)) {\n  output &lt;- c(output, lengths(x[[i]]))\n}\noutput\n\n¿Cómo afecta esto el rendimiento? Diseña y ejecuta un experimento."
  },
  {
    "objectID": "21-iteration.html#variaciones-de-bucles-for",
    "href": "21-iteration.html#variaciones-de-bucles-for",
    "title": "21  Iteración",
    "section": "21.3 Variaciones de bucles for",
    "text": "21.3 Variaciones de bucles for\nUna vez que tienes el bucle for básico en tu haber, hay algunas variaciones que debes tener en cuenta. Estas variaciones son importantes independientemente de cómo hagas la iteración, así que no te olvides de ellas una vez que hayas dominado las técnicas de programación funcional (PF) que aprenderás en la próxima sección.\nHay cuatro variaciones del bucle for básico:\n\nModificar un objeto existente, en lugar de crear un nuevo objeto.\nIterar sobre nombres o valores, en lugar de índices.\nManejar outputs de longitud desconocida.\nManejar secuencias de longitud desconocida.\n\n\n21.3.1 Modificar un objeto existente\nAlgunas veces querrás usar un bucle for para modificar un objeto existente. Por ejemplo, recuerda el desafío que teníamos en el capítulo sobre [funciones]. Queríamos reescalar cada columna en un data frame:\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\nrescale01 &lt;- function(x) {\n  rng &lt;- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\ndf$a &lt;- rescale01(df$a)\ndf$b &lt;- rescale01(df$b)\ndf$c &lt;- rescale01(df$c)\ndf$d &lt;- rescale01(df$d)\n\nPara resolver esto con un bucle for, volvamos a pensar en los tres componentes:\n\nOutput: ya tenemos el output — ¡es lo mismo que la entrada!\nSecuencia: podemos pensar en un data frame como una lista de columnas, por lo que podemos iterar sobre cada columna con seq_along (df).\nCuerpo: aplicar rescale01 ().\n\nEsto nos da:\n\nfor (i in seq_along(df)) {\n  df[[i]] &lt;- rescale01(df[[i]])\n}\n\nPor lo general, se modificará una lista o un data frame con este tipo de bucle, así que recuerda utilizar [[ y no [. Te habrás fijado que usamos [[ en todos nuestros bucles for: creemos que es mejor usar [[ incluso para vectores atómicos porque deja en claro que queremos trabajar con un solo elemento.\n\n\n21.3.2 Patrones de bucle\nHay tres formas básicas de hacer un bucle sobre un vector. Hasta ahora hemos visto la más general: iterar sobre los índices numéricos con for (i in seq_along (xs)), y extraer el valor con x [[i]]. Hay otras dos formas:\n\nIterar sobre los elementos: for (x in xs). Esta forma es la más útil si solo te preocupas por los efectos secundarios, como graficar o grabar un archivo, porque es difícil almacenar el output de forma eficiente.\nIterar sobre los nombres: for (nm in names(xs)). Esto te entrega el nombre, que se puede usar para acceder al valor con x [[nm]]. Esto es útil si queremos utilizar el nombre en el título de un gráfico o en el nombre de un archivo. Si estás creando un output con nombre, asegúrate de nombrar el vector de resultados de esta manera:\n\nresultados &lt;- vector(\"list\", length(x))\nnames(resultados) &lt;- names(x)\n\nIterar sobre los índices numéricos es la forma más general, porque dada la posición se puede extraer tanto el nombre como el valor:\n\n\nfor (i in seq_along(x)) {\n  name &lt;- names(x)[[i]]\n  value &lt;- x[[i]]\n}\n\n\n\n21.3.3 Longitud de output desconocida\nEs posible que algunas veces no sepas el tamaño que tendrá el output. Por ejemplo, imagina que quieres simular algunos vectores aleatorios de longitudes aleatorias. Podrías tener la tentación de resolver este problema haciendo crecer el vector progresivamente:\n\nmedias &lt;- c(0, 1, 2)\n\noutput &lt;- double()\nfor (i in seq_along(medias)) {\n  n &lt;- sample(100, 1)\n  output &lt;- c(output, rnorm(n, medias[[i]]))\n}\nstr(output)\n\n num [1:56] -0.337 0.371 2.177 1.494 0.577 ...\n\n\nPero esto no es muy eficiente porque en cada iteración, R tiene que copiar todos los datos de las iteraciones anteriores. En términos técnicos, obtienes un comportamiento “cuadrático” (\\(O(n^2)\\)), lo que significa que un bucle que tiene tres veces más elementos tomaría nueve (\\(3^2\\)) veces más tiempo en ejecutarse.\nUna mejor solución es guardar los resultados en una lista y luego combinarlos en un solo vector una vez que se complete el ciclo:\n\nout &lt;- vector(\"list\", length(medias))\nfor (i in seq_along(medias)) {\n  n &lt;- sample(100, 1)\n  out[[i]] &lt;- rnorm(n, medias[[i]])\n}\nstr(out)\n\nList of 3\n $ : num [1:95] 0.245 0.485 0.111 1.236 -1.705 ...\n $ : num [1:52] 0.502 0.236 0.308 0.714 2.334 ...\n $ : num [1:21] 1.113 1.761 1.307 2.906 0.888 ...\n\nstr(unlist(out))\n\n num [1:168] 0.245 0.485 0.111 1.236 -1.705 ...\n\n\nAquí usamos unlist () (deslistar en inglés) para aplanar una lista de vectores en un solo vector. Una opción más estricta es usar purrr :: flatten_dbl () (aplanar dobles) — arrojará un error si el input no es una lista de dobles.\nEste patrón ocurre también en otros lugares:\n\nPodrías estar generando una cadena larga. En lugar de pegar (paste ()) cada iteración con la anterior, guarda el output en un vector de caracteres y luego combina ese vector en una cadena con paste(output, collapse = \"\").\nPodrías estar generando un data frame grande. En lugar de enlazar (rbind ()) secuencialmente en cada iteración, guarda el resultado en una lista y luego utiliza dplyr::bind_rows(output) para combinar el output en un solo data frame.\n\nCuidado con este patrón. Cuando lo veas, cambia a un objeto de resultado más complejo y luego combínalo en un solo paso al final.\n\n\n21.3.4 Longitud de secuencia desconocida\nA veces ni siquiera sabemos cuánto tiene que durar la secuencia de entrada. Esto es común cuando se hacen simulaciones. Por ejemplo, es posible que se quiera realizar un bucle hasta que se obtengan tres caras seguidas. No podemos hacer ese tipo de iteración con un bucle for. En su lugar, podemos utilizar un bucle while (mientras, en inglés). Un bucle while es más simple que un bucle for porque solo tiene dos componentes, una condición y un cuerpo:\n\nwhile (condición) {\n  # cuerpo\n}\n\nUn bucle while también es más general que un bucle for, porque podemos reescribir este último como un bucle while, pero no podemos reescribir todos los bucles while bucles for:\n\nfor (i in seq_along(x)) {\n  # cuerpo\n}\n\n# Equivalente a \ni &lt;- 1\nwhile (i &lt;= length(x)) {\n  # cuerpo\n  i &lt;- i + 1 \n}\n\nAsí es como podríamos usar un bucle while para encontrar cuántos intentos se necesitan para obtener tres caras seguidas:\n\nlanzamiento &lt;- function() sample(c(\"S\", \"C\"), 1)\n\nlanzamientos &lt;- 0\nncaras &lt;- 0\n\nwhile (ncaras &lt; 3) {\n  if (lanzamiento() == \"C\") {\n    ncaras &lt;- ncaras + 1\n  } else {\n    ncaras &lt;- 0\n  }\n  lanzamientos &lt;- lanzamientos + 1\n}\nlanzamientos\n\n[1] 10\n\n\nMencionamos los bucles while brevemente, porque casi nunca los usamos. Se utilizan con mayor frecuencia para hacer simulaciones, un tema que está fuera del alcance de este libro. Sin embargo, es bueno saber que existen en caso que nos encontremos con problemas en los que el número de iteraciones no se conoce de antemano.\n\n\n21.3.5 Ejercicios\n\nImagina que tienes un directorio lleno de archivos CSV que quieres importar. Tienes sus ubicaciones en un vector, files &lt;- dir(\"data/\", pattern = \"\\\\.csv$\", full.names = TRUE), y ahora quieres leer cada uno con read_csv(). Escribe un bucle for que los cargue en un solo data frame.\n¿Qué pasa si utilizamos for (nm in names(x)) y x no tiene nombres (names)? ¿Qué pasa si solo algunos elementos están nombrados? ¿Qué pasa si los nombres no son únicos?\nEscribe una función que imprima el promedio de cada columna numérica en un data frame, junto con su nombre. Por ejemplo, mostrar_promedio(flores) debe imprimir:\n\nmostrar_promedio(flores)\n#&gt; Largo.Sepalo:  5.84\n#&gt; Ancho.Sepalo:  3.06\n#&gt; Largo.Petalo:  3.76\n#&gt; Ancho.Petalo:  1.20\n\n(Desafío adicional: ¿qué función utilizamos para asegurarnos que los números queden alineados a pesar que los nombres de las variables tienen diferentes longitudes?)\n¿Qué hace este código? ¿Cómo funciona?\n\ntrans &lt;- list( \n  cilindrada = function(x) x * 0.0163871,\n  transmision = function(x) {\n    factor(x, labels = c(\"automática\", \"manual\"))\n  }\n)\nfor (var in names(trans)) {\n  mtautos[[var]] &lt;- trans[[var]](mtautos[[var]])\n}"
  },
  {
    "objectID": "21-iteration.html#bucles-for-vs.-funcionales",
    "href": "21-iteration.html#bucles-for-vs.-funcionales",
    "title": "21  Iteración",
    "section": "21.4 Bucles for vs. funcionales",
    "text": "21.4 Bucles for vs. funcionales\nLos bucles for no son tan importantes en R como en otros lenguajes porque R es un lenguaje de programación funcional. Esto significa que es posible envolver los bucles en una función y llamar a esa función en lugar de usar el bucle for directamente.\nPara ver por qué esto es importante, consideremos (nuevamente) este data frame simple:\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\nImagina que quieres calcular la media de cada columna. Podríamos hacer eso con un bucle for:\n\noutput &lt;- vector(\"double\", length(df))\nfor (i in seq_along(df)) {\n  output[[i]] &lt;- mean(df[[i]])\n}\noutput\n\n[1] -0.15029524 -0.03436033 -0.23707002  0.30481451\n\n\nComo te das cuenta que vas querer calcular los promedios de cada columna con bastante frecuencia, extraer el bucle en una función:\n\ncol_media &lt;- function(df) {\n  output &lt;- vector(\"double\", length(df))\n  for (i in seq_along(df)) {\n    output[i] &lt;- mean(df[[i]])\n  }\n  output\n}\n\nPero entonces pensamos que también sería útil poder calcular la mediana y la desviación estándar, así que copiamos y pegamos la función col_media () y reemplazamos mean () con median () y sd ():\n\ncol_mediana &lt;- function(df) {\n  output &lt;- vector(\"double\", length(df))\n  for (i in seq_along(df)) {\n    output[i] &lt;- median(df[[i]])\n  }\n  output\n}\ncol_desvest &lt;- function(df) {\n  output &lt;- vector(\"double\", length(df))\n  for (i in seq_along(df)) {\n    output[i] &lt;- sd(df[[i]])\n  }\n  output\n}\n\n¡Oh oh! Copiaste y pegaste este código dos veces, por lo que es hora de pensar cómo generalizarlo. Ten en cuenta que la mayoría de este código corresponde al texto trillado del bucle for, lo que hace difícil ver la única cosa que es diferente entre las funciones (mean (), median (), sd ()).\n¿Qué podŕias hacer si ves un conjunto de funciones como esta?:\n\nf1 &lt;- function(x) abs(x - mean(x)) ^ 1\nf2 &lt;- function(x) abs(x - mean(x)) ^ 2\nf3 &lt;- function(x) abs(x - mean(x)) ^ 3\n\nPor suerte, habrás notado que hay mucha duplicación que puedes extraer con un argumento adicional:\n\nf &lt;- function(x, i) abs(x - mean(x)) ^ i\n\nRedujiste la posibilidad de errores (porque ahora tienes 1/3 menos de código) y hiciste más fácil generalizar para situaciones nuevas.\nPodemos hacer exactamente lo mismo con col_media (), col_mediana () y col_desvest () agregando un argumento que proporciona la función a aplicar en cada columna:\n\ncol_resumen &lt;- function(df, fun) {\n  out &lt;- vector(\"double\", length(df))\n  for (i in seq_along(df)) {\n    out[i] &lt;- fun(df[[i]])\n  }\n  out\n}\ncol_resumen(df, median)\n\n[1] -0.3385113 -0.2526771 -0.4861184  0.5946341\n\ncol_resumen(df, mean)\n\n[1] -0.15029524 -0.03436033 -0.23707002  0.30481451\n\n\nLa idea de pasar una función a otra es extremadamente poderosa y es uno de los comportamientos que hacen de R un lenguaje de programación funcional. Puede que te tome un tiempo comprender la idea, pero vale la pena el esfuerzo. En el resto del capítulo aprenderás y usarás el paquete purrr, que proporciona funciones que eliminan la necesidad de muchos de los bucles comunes. La familia de funciones de R base apply (aplicar: apply (), lapply (), tapply (), etc.) resuelve un problema similar; sin embargo, purrr es más consistente y, por lo tanto, es más fácil de aprender.\nEl objetivo de usar las funciones de purrr en lugar de los bucles es que te permite dividir los desafíos comunes de manipulación de listas en partes independientes:\n\n¿Cómo puedes resolver el problema para un solo elemento de la lista? Una vez que encuentres la solución, purrr se encargará de generalizarla a cada elemento de la lista.\nSi estás resolviendo un problema complejo, ¿cómo puedes dividirlo en pequeñas etapas que te permitan avanzar paso a paso hacia la solución? Con purrr obtienes muchas piezas pequeñas que puedes ensamblar utilizando el pipe (%&gt;%).\n\nEsta estructura facilita la resolución de nuevos problemas. También hace que sea más fácil entender las soluciones a problemas antiguos cuando relees código que escribiste en el pasado.\n\n21.4.1 Ejercicios\n\nLee la documentación para apply (). En el caso 2d, ¿qué dos bucles for generaliza?\nAdapta col_resumen() para que solo se aplique a las columnas numéricas. Podrías querer comenzar con la función is_numeric () que devuelve un vector lógico que tenga un TRUE por cada columna numérica."
  },
  {
    "objectID": "21-iteration.html#las-funciones-map",
    "href": "21-iteration.html#las-funciones-map",
    "title": "21  Iteración",
    "section": "21.5 Las funciones map",
    "text": "21.5 Las funciones map\nEl patrón de iterar sobre un vector, hacer algo con cada elemento y guardar los resultados es tan común que el paquete purrr proporciona una familia de funciones que lo hacen por ti. Hay una función para cada tipo de output:\n\nmap () crea una lista.\nmap_lgl () crea un vector lógico.\nmap_int () crea un vector de enteros.\nmap_dbl () crea un vector de dobles.\nmap_chr () crea un vector de caracteres.\n\nCada función map (mapa, en español) toma un vector como input, aplica una función a cada elemento y luego devuelve un nuevo vector que tiene la misma longitud (y los mismos nombres) que el input. El tipo de vector está determinado por el sufijo de la función map.\nUna vez que domines estas funciones, descubrirás que lleva mucho menos tiempo resolver los problemas de iteración. Sin embargo, nunca debes sentirse mal por usar un bucle for en lugar de una función map. Las funciones map son un nivel superior de abstracción y puede llevar mucho tiempo entender cómo funcionan. Lo importante es que resuelvas el problema en el que estás trabajando, no que escribas el código más conciso y elegante (¡aunque eso es definitivamente algo a lo que aspirar!).\nAlgunas personas te dirán que evites los bucles for porque son lentos. ¡Están equivocados! (Bueno, al menos están bastante desactualizados, ya que los bucles for han dejado de ser lentos desde hace muchos años). Los principales beneficios de usar funciones como map () no es la velocidad, sino la claridad: hacen que tu código sea más fácil de escribir y leer.\nPodemos usar estas funciones para realizar los mismos cálculos que el último bucle for. Esas funciones de resumen devolvían valores decimales, por lo que necesitamos usar map_dbl ():\n\nmap_dbl(df, mean)\n\n          a           b           c           d \n-0.15029524 -0.03436033 -0.23707002  0.30481451 \n\nmap_dbl(df, median)\n\n         a          b          c          d \n-0.3385113 -0.2526771 -0.4861184  0.5946341 \n\nmap_dbl(df, sd)\n\n        a         b         c         d \n1.1538431 0.9010436 0.8499622 1.2905837 \n\n\nComparado con el uso de un bucle for, el foco está en la operación que se está realizando (es decir, mean (), median (), sd ()), y no en llevar la cuenta de las acciones requeridas para recorrer cada elemento y almacenar el output. Esto es aún más evidente si usamos el pipe:\n\ndf %&gt;% map_dbl(mean)\n\n          a           b           c           d \n-0.15029524 -0.03436033 -0.23707002  0.30481451 \n\ndf %&gt;% map_dbl(median)\n\n         a          b          c          d \n-0.3385113 -0.2526771 -0.4861184  0.5946341 \n\ndf %&gt;% map_dbl(sd)\n\n        a         b         c         d \n1.1538431 0.9010436 0.8499622 1.2905837 \n\n\nExisten algunas diferencias entre map _ * () y col_resumen():\n\nTodas las funciones de purrr están implementadas en C. Esto las hace más rápidas a expensas de la legibilidad.\nEl segundo argumento, .f, la función a aplicar, puede ser una fórmula, un vector de caracteres o un vector de enteros. Aprenderás acerca de estos atajos útiles en la siguiente sección.\nmap_*() usa … ([dot dot dot] - punto punto punto) para pasar los argumentos adicionales a .f cada vez que se llama:\n::: {.cell}\nmap_dbl(df, mean, trim = 0.5)\n::: {.cell-output .cell-output-stdout} a          b          c          d    -0.3385113 -0.2526771 -0.4861184  0.5946341 ::: :::\nLas funciones map también preservan los nombres:\n::: {.cell}\nz &lt;- list(x = 1:3, y = 4:5)\nmap_int(z, length)\n::: {.cell-output .cell-output-stdout} x y    3 2 ::: :::\n\n\n21.5.1 Atajos\nExisten algunos atajos que puedes usar con .f para ahorrar algo de tipeo Imagina que quieres ajustar un modelo lineal a cada grupo en un conjunto de datos. El siguiente ejemplo de juguete divide el dataset mtautos en tres partes (una para cada valor de cilindro) y ajusta el mismo modelo lineal a cada parte:\n\nmodelos &lt;- mtautos %&gt;% \n  split(.$cilindros) %&gt;% \n  map(function(df) lm(millas ~ peso, data = df))\n\nLa sintaxis para crear una función anónima en R es bastante verbosa, por lo que purrr provee un atajo conveniente: una fórmula unilateral.\n\nmodelos &lt;- mtautos %&gt;% \n  split(.$cilindros) %&gt;% \n  map(~lm(millas ~ peso, data = .x))\n\nHemos usado . como pronombre: se refiere al elemento actual de la lista (del mismo modo que i se refiere al índice actual en el loop for). .x corresponde al argumento de una función anónima.\nCuando examinas múltiples modelos, puedes querer extraer un estadístico resumen como lo es \\(R^2\\). Para hacer eso primero necesitas correr summary() y luego extraer la componente r.squared (R-cuadrado). Podríamos hacerlo usando un atajo para las funciones anónimas:\n\nmodelos %&gt;% \n  map(summary) %&gt;% \n  map_dbl(~.x$r.squared)\n\n        4         6         8 \n0.5086326 0.4645102 0.4229655 \n\n\nSin embargo, extraer componentes con nombres es una operación común, por lo que purrr provee un atajo aún más corto: puedes usar una cadena de caracteres (o string).\n\nmodelos %&gt;% \n  map(summary) %&gt;% \n  map_dbl(\"r.squared\")\n\n        4         6         8 \n0.5086326 0.4645102 0.4229655 \n\n\nTambién puedes usar un entero para seleccionar elementos de acuerdo a su posición:\n\nx &lt;- list(list(1, 2, 3), list(4, 5, 6), list(7, 8, 9))\nx %&gt;% map_dbl(2)\n\n[1] 2 5 8\n\n\n\n\n21.5.2 R Base\nSi la familia de funciones apply en R base te son familiares, podrás haber notado algunas similitudes con las funciones de purrr:\n\nlapply() es básicamente idéntica a map(), excepto que map() es consistente con todas las otras funciones de purrr y puedes usar atajos para .f.\nsapply() es un envoltorio (wrapper) de lapply() que automáticamente simplifica el output. Esto es úti lpara el trabajo interactivo pero es problemático en una función, ya que nunca sabrás qué tipo de output vas a obtener:\n::: {.cell}\nx1 &lt;- list(\n  c(0.27, 0.37, 0.57, 0.91, 0.20),\n  c(0.90, 0.94, 0.66, 0.63, 0.06), \n  c(0.21, 0.18, 0.69, 0.38, 0.77)\n)\nx2 &lt;- list(\n  c(0.50, 0.72, 0.99, 0.38, 0.78), \n  c(0.93, 0.21, 0.65, 0.13, 0.27), \n  c(0.39, 0.01, 0.38, 0.87, 0.34)\n)\n\numbral &lt;- function(x, cutoff = 0.8) x[x &gt; cutoff]\nx1 %&gt;% sapply(umbral) %&gt;% str()\n::: {.cell-output .cell-output-stdout} List of 3    $ : num 0.91    $ : num [1:2] 0.9 0.94    $ : num(0) :::\nx2 %&gt;% sapply(umbral) %&gt;% str()\n::: {.cell-output .cell-output-stdout} num [1:3] 0.99 0.93 0.87 ::: :::\nvapply() es una alternativa más segura a sapply() porque debes ingresar un argumento adicional que define el tipo de output. El único problema con vapply() es es que requiere mucha escritura: vapply(df, is.numeric, logical(1)) es equivalente a map_lgl(df, is.numeric). Una ventaja de vapply() sobre las funciones map de purrr es que también puede generar matrices — las funciones map solo generan vectores.\n\nAquí nos enfocamos en las funciones de purrr, ya que proveen nombres y argumentos consistentes, atajos útiles y en el futuro proveerán paralelización simple y barras de progreso.\n\n\n21.5.3 Ejercicios\n\nEscribe un código que use una de las funciones de map para:\n\nCalcular la media de cada columna en datos::mautos.\nObtener de qué tipo es cada columna en datos::vuelos.\nCalcular la cantidad de valores únicos en cada columna de datos::flores.\nGenerar diez normales aleatorias de distribuciones con medias -10, 0, 10 y 100.\n\n¿Cómo puedes crear un vector tal que para cada columna en un data frame indique si corresponde o no a un factor?\n¿Qué ocurre si usas las funciones map en vectores que no son listas? ¿Qué hace map(1:5, runif)? ¿Por qué?\n¿Qué hace map(-2:2, rnorm, n = 5)? ¿Por qué? ¿Qué hace map_dbl(-2:2, rnorm, n = 5)? ¿Por qué?\nReescribe map(x, function(df) lm(mpg ~ wt, data = df)) para eliminar todas las funciones anónimas."
  },
  {
    "objectID": "21-iteration.html#manejando-los-errores",
    "href": "21-iteration.html#manejando-los-errores",
    "title": "21  Iteración",
    "section": "21.6 Manejando los errores",
    "text": "21.6 Manejando los errores\nCuando usas las funciones map para repetir muchas operaciones, la probabilidad de que una de estas falle es mucho más alta. Cuando esto ocurre, obtendrás un mensaje de error y no una salida. Esto es molesto: ¿por qué un error evita que accedas a todo lo que sí funcionó? ¿Cómo puedes asegurarte de que una manzana podrida no arruine todo el barril?\nEn esta sección aprenderás a manejar estas situaciones con una nueva función: safely() (de forma segura, en inglés). safely() es un adverbio: toma una función (un verbo) y entrega una versión modificada. En este caso, la función modificada nunca lanzará un error. En cambio, siempre devolverá una lista de dos elementos:\n\nresult es el resultado original. Si hubo un error, aparecerá como NULL,\nerror es un objeto de error. Si la operación fue exitosa, será NULL.\n\n(Puede que estés familiarizado con la función try() (intentar) de R base. Es similar, pero dado que a veces entrega el resultado original y a veces un objeto de error, es más díficil para trabajar.)\nVeamos esto con un ejemplo simple: log():\n\nlog_seguro &lt;- safely(log)\nstr(log_seguro(10))\n\nList of 2\n $ result: num 2.3\n $ error : NULL\n\nstr(log_seguro(\"a\"))\n\nList of 2\n $ result: NULL\n $ error :List of 2\n  ..$ message: chr \"non-numeric argument to mathematical function\"\n  ..$ call   : language .Primitive(\"log\")(x, base)\n  ..- attr(*, \"class\")= chr [1:3] \"simpleError\" \"error\" \"condition\"\n\n\nCuando la función es exitosa, el elemento result contiene el resultado y el elemento error es NULL. Cuando la función falla, el elemento result es NULL y el elemento error contiene un objeto de error.\nsafely() está diseñada para funcionar con map:\n\nx &lt;- list(1, 10, \"a\")\ny &lt;- x %&gt;% map(safely(log))\nstr(y)\n\nList of 3\n $ :List of 2\n  ..$ result: num 0\n  ..$ error : NULL\n $ :List of 2\n  ..$ result: num 2.3\n  ..$ error : NULL\n $ :List of 2\n  ..$ result: NULL\n  ..$ error :List of 2\n  .. ..$ message: chr \"non-numeric argument to mathematical function\"\n  .. ..$ call   : language .Primitive(\"log\")(x, base)\n  .. ..- attr(*, \"class\")= chr [1:3] \"simpleError\" \"error\" \"condition\"\n\n\nEsto sería más fácil de trabajar si tuvieramos dos listas: una con todos los errores y otra con todas las salidas, Esto es fácil de obtener con purrr::transpose() (transponer):\n\ny &lt;- y %&gt;% transpose()\nstr(y)\n\nList of 2\n $ result:List of 3\n  ..$ : num 0\n  ..$ : num 2.3\n  ..$ : NULL\n $ error :List of 3\n  ..$ : NULL\n  ..$ : NULL\n  ..$ :List of 2\n  .. ..$ message: chr \"non-numeric argument to mathematical function\"\n  .. ..$ call   : language .Primitive(\"log\")(x, base)\n  .. ..- attr(*, \"class\")= chr [1:3] \"simpleError\" \"error\" \"condition\"\n\n\nQueda a tu criterio cómo manejar los errores, pero típicamente puedes mirar los valores de x donde y es un error, o trabajar con los valores que y que están ok:\n\nestan_ok &lt;- y$error %&gt;% map_lgl(is_null)\nx[!estan_ok]\n\n[[1]]\n[1] \"a\"\n\ny$result[estan_ok] %&gt;% flatten_dbl()\n\n[1] 0.000000 2.302585\n\n\nPurrr provee otros dos adverbios útiles:\n\nAl igual que safely(), possibly() (posiblemente) siempre tendrá éxito. Es más simple que safely(), ya que le das un valor por defecto para devolver cuando haya un error.\n\nx &lt;- list(1, 10, \"a\")\nx %&gt;% map_dbl(possibly(log, NA_real_))\n\n[1] 0.000000 2.302585       NA\n\n\nquietly() (silenciosamente) tiene un rol similar a safely(), pero en lugar de capturar los errores, captura el output impreso, los mensajes y las advertencias:\n\nx &lt;- list(1, -1)\nx %&gt;% map(quietly(log)) %&gt;% str()\n\nList of 2\n $ :List of 4\n  ..$ result  : num 0\n  ..$ output  : chr \"\"\n  ..$ warnings: chr(0) \n  ..$ messages: chr(0) \n $ :List of 4\n  ..$ result  : num NaN\n  ..$ output  : chr \"\"\n  ..$ warnings: chr \"NaNs produced\"\n  ..$ messages: chr(0)"
  },
  {
    "objectID": "21-iteration.html#usar-map-sobre-múltiples-argumentos",
    "href": "21-iteration.html#usar-map-sobre-múltiples-argumentos",
    "title": "21  Iteración",
    "section": "21.7 Usar map sobre múltiples argumentos",
    "text": "21.7 Usar map sobre múltiples argumentos\nHasta ahora hemos “mapeado” sobre un único input. Pero a menudo tienes multiples inputs relacionados y necesitas iterar sobre ellos en paralelo. Ese es el trabajo de las funciones map2() y pmap(). Por ejemplo, imagina que quieres simular normales aleatorias con distintas medias. Ya sabes hacerlo con map():\n\nmu &lt;- list(5, 10, -3)\nmu %&gt;% \n  map(rnorm, n = 5) %&gt;% \n  str()\n\nList of 3\n $ : num [1:5] 4.59 5.11 6.61 6.3 5.47\n $ : num [1:5] 8.47 9.73 9.68 8.98 8.66\n $ : num [1:5] -3.8 -2.6 -1.97 -1.78 -2.14\n\n\n¿Qué ocurre si también necesitas cambiar la desviación estándar? Una forma de hacerlo sería iterar sobre los índices e indexar en vectores de medias y desviaciones estándar:\n\nsigma &lt;- list(1, 5, 10)\nseq_along(mu) %&gt;% \n  map(~rnorm(5, mu[[.x]], sigma[[.x]])) %&gt;% \n  str()\n\nList of 3\n $ : num [1:5] 4.08 5.63 3.95 4.43 4.68\n $ : num [1:5] 9.73 6.53 4.89 6.37 8.97\n $ : num [1:5] 17.85 -22.45 -2.56 -4.66 -10.25\n\n\nPero esto oscurece la intención del código. En su lugar podríamos usar map2(), que itera sobre dos vectores en paralelo:\n\nmap2(mu, sigma, rnorm, n = 5) %&gt;% str()\n\nList of 3\n $ : num [1:5] 5.28 4.96 5.33 4.24 3.69\n $ : num [1:5] 6.88 4.97 11.14 2.95 14.3\n $ : num [1:5] -12.96 4.77 -10.06 8.62 10.4\n\n\nmap2() genera esta serie de llamadas a funciones:\n\n\n\n\n\nObserva que los argumentos que varían para cada llamada van antes de la función; argumentos que son los mismos para cada llamada van después.\nAl igual que map(), map2() es un envoltorio en torno a un bucle for:\n\nmap2 &lt;- function(x, y, f, ...) {\n  out &lt;- vector(\"list\", length(x))\n  for (i in seq_along(x)) {\n    out[[i]] &lt;- f(x[[i]], y[[i]], ...)\n  }\n  out\n}\n\nTambién te podrás imaginar map3(), map4(), map5(), map6(), etc., pero eso se volvería tedioso rápidamente. En cambio, purrr provee pmap(), que toma una lista de argumentos. Puedes usar eso si quieres cambiar la media, desviación estándar y el número de muestras:\n\nn &lt;- list(1, 3, 5)\nargs1 &lt;- list(n, mu, sigma)\nargs1 %&gt;%\n  pmap(rnorm) %&gt;% \n  str()\n\nList of 3\n $ : num 4.42\n $ : num [1:3] 14.7 11.5 17.7\n $ : num [1:5] -1.442 0.423 0.76 -7.021 -1.146\n\n\nEsto se ve así:\n\n\n\n\n\nSi no nombras todos los elementos de la lista, pmap() usará una coincidencia posicional al llamar la función. Esto es un poco frágil y hace el código más difícil de leer, por lo que es mejor nombrar los argumentos:\n\nargs2 &lt;- list(mean = mu, sd = sigma, n = n)\nargs2 %&gt;% \n  pmap(rnorm) %&gt;% \n  str()\n\nEsto genera llamadas más largas, pero más seguras:\n\n\n\n\n\nDado que los argumentos son todos del mismo largo, tiene sentido almacenarlos en un data frame:\n\nparams &lt;- tribble(\n  ~mean, ~sd, ~n,\n    5,     1,  1,\n   10,     5,  3,\n   -3,    10,  5\n)\nparams %&gt;% \n  pmap(rnorm)\n\n[[1]]\n[1] 6.342575\n\n[[2]]\n[1] 10.434890  2.379655  4.596387\n\n[[3]]\n[1]  3.627761  6.278116 -6.746823 -5.376471  1.894456\n\n\nUtilizar un data frame cuando tu código se vuelve complicado nos parece una buena aproximación, ya que asegura que cada columna tenga nombre y el mismo largo que las demás columnas.\n\n21.7.1 Invocando distintas funciones\nExiste un paso adicional en términos de complejidad. Así como cambias los argumentos de la función también puedes cambiar la función misma:\n\nf &lt;- c(\"runif\", \"rnorm\", \"rpois\")\nparam &lt;- list(\n  list(min = -1, max = 1), \n  list(sd = 5), \n  list(lambda = 10)\n)\n\nPara manejar este caso, puedes usar invoke_map():\n\ninvoke_map(f, param, n = 5) %&gt;% str()\n\nWarning: `invoke_map()` was deprecated in purrr 1.0.0.\nℹ Please use map() + exec() instead.\n\n\nList of 3\n $ : num [1:5] 0.102 -0.591 -0.715 -0.935 0.376\n $ : num [1:5] 1.11 3.66 -2.06 2.66 8.9\n $ : int [1:5] 14 10 12 10 6\n\n\n\n\n\n\n\nEl primer argumento es una lista de funciones o un vector de caracteres con nombres de funciones. El segundo argumento es una lista de listas que indica los argumentos que cambian en cada función. Los argumentos subsecuentes pasan a cada función.\nNuevamente, puedes usar tribble() para hacer la creación de tuplas coincidentes un poco más fácil:\n\nsim &lt;- tribble(\n  ~f,      ~params,\n  \"runif\", list(min = -1, max = 1),\n  \"rnorm\", list(sd = 5),\n  \"rpois\", list(lambda = 10)\n)\nsim %&gt;% \n  mutate(sim = invoke_map(f, params, n = 10))"
  },
  {
    "objectID": "21-iteration.html#walk",
    "href": "21-iteration.html#walk",
    "title": "21  Iteración",
    "section": "21.8 Walk",
    "text": "21.8 Walk\nWalk es una alternativa a map que puedes usar cuando quieras llamar a una función por sus efectos colaterales, más que por sobre el valor que devuelve. Típicamente hacemos esto cuando queremos mostrar la salida en pantalla o guardar archivos en el disco. Lo importante es la acción, no el valor resultante. Aquí hay un ejemplo simple:\n\nx &lt;- list(1, \"a\", 3)\n\nx %&gt;% \n  walk(print)\n\n[1] 1\n[1] \"a\"\n[1] 3\n\n\nGeneralmente walk() no es tan útil si se compara con walk2() o pwalk(). Por ejemplo, si tienes una lista de gráficos y un vector con nombres de archivos, puedes usar pwalk() para guardar cada archivo en su ubicación correspondiente en el disco:\n\nlibrary(ggplot2)\nplots &lt;- mtcars %&gt;% \n  split(.$cyl) %&gt;% \n  map(~ggplot(.x, aes(mpg, wt)) + geom_point())\npaths &lt;- stringr::str_c(names(plots), \".pdf\")\n\npwalk(list(paths, plots), ggsave, path = tempdir())\n\nwalk(), walk2() y pwalk() devuelven de forma invisible ., el primer argumento. Esto las hace adecuadas para usar dentro de cadenas de pipes."
  },
  {
    "objectID": "21-iteration.html#otros-patrones-para-los-bucles-for",
    "href": "21-iteration.html#otros-patrones-para-los-bucles-for",
    "title": "21  Iteración",
    "section": "21.9 Otros patrones para los bucles for",
    "text": "21.9 Otros patrones para los bucles for\nPurr entrega algunas funciones que resumen otros tipos de bucles for. Si bien los usarás de manera menos frecuente que las funciones map, es útil conocerlas. El objetivo aquí es ilustrar brevemente cada una, con la esperanza de que vengan a tu mente en el futuro cuando veas un problema similar. Luego puedes consultar la documentación para más detalles.\n\n21.9.1 Funciones predicativas\nAlgunas funciones trabajan con funciones predicativas que entregan un único valor TRUE o FALSE.\nkeep() y discard() mantienen los elementos de la entrada donde el predicado es TRUE o FALSE, respectivamente:\n\nflores %&gt;% \n  keep(is.factor) %&gt;% \n  str()\n\n'data.frame':   150 obs. of  1 variable:\n $ Especie: Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nflores %&gt;% \n  discard(is.factor) %&gt;% \n  str()\n\n'data.frame':   150 obs. of  4 variables:\n $ Largo.Sepalo: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Ancho.Sepalo: num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Largo.Petalo: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Ancho.Petalo: num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n\n\nsome() y every() determinan si el predicado es verdadero para todos o para algunos de los elementos.\n\nx &lt;- list(1:5, letters, list(10))\n\nx %&gt;% \n  some(is_character)\n\n[1] TRUE\n\nx %&gt;% \n  every(is_vector)\n\n[1] TRUE\n\n\ndetect() encuentra el primer elemento donde el predicado es verdadero; detect_index() entrega su posición.\n\nx &lt;- sample(10)\nx\n\n [1]  7  5  1  9  8 10  2  4  6  3\n\nx %&gt;% \n  detect(~ . &gt; 5)\n\n[1] 7\n\nx %&gt;% \n  detect_index(~ . &gt; 5)\n\n[1] 1\n\n\nhead_while() y tail_while() toman elementos al inicio y final de un vector cuando el predicado es verdadero:\n\nx %&gt;% \n  head_while(~ .x &gt; 5)\n\n[1] 7\n\nx %&gt;% \n  tail_while(~ .x &gt; 5)\n\ninteger(0)\n\n\n\n\n21.9.2 Reducir y acumular\nA veces tendrás una lista compleja que quieres reducir a una lista simple aplicando repetidamente una función que reduce un par a un elemento único. Esto es útil si quieres aplicar un verbo de dos tablas de dplyr a múltiples tablas. Por ejemplo, si tienes una lista de data frames, y quieres reducirla a un unico data frame uniendo los elementos:\n\ndfs &lt;- list(\n  age = tibble(name = \"John\", age = 30),\n  sex = tibble(name = c(\"John\", \"Mary\"), sex = c(\"M\", \"F\")),\n  trt = tibble(name = \"Mary\", treatment = \"A\")\n)\n\ndfs %&gt;% reduce(full_join)\n\nJoining with `by = join_by(name)`\nJoining with `by = join_by(name)`\n\n\n# A tibble: 2 × 4\n  name    age sex   treatment\n  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    \n1 John     30 M     &lt;NA&gt;     \n2 Mary     NA F     A        \n\n\nO puedes tener una lista de vectores y quieres encontrar la intersección:\n\nvs &lt;- list(\n  c(1, 3, 5, 6, 10),\n  c(1, 2, 3, 7, 8, 10),\n  c(1, 2, 3, 4, 8, 9, 10)\n)\n\nvs %&gt;% reduce(intersect)\n\n[1]  1  3 10\n\n\nLa función reduce() (reducir) toma una función “binaria” (e.g. una función con dos inputs primarios) y la aplica repetidamente a una lista hasta que quede un solo elemento.\naccumulate() (acumular) es similar, pero mantiene todos los resultados intermedios. Podría usarse para implementar una suma acumulativa:\n\nx &lt;- sample(10)\nx\n\n [1]  1  9  5 10  4  7  8  3  2  6\n\nx %&gt;% accumulate(`+`)\n\n [1]  1 10 15 25 29 36 44 47 49 55\n\n\n\n\n21.9.3 Ejercicios\n\nImplementa tu propia versión de every() usando un bucle for. Compárala con purrr::every(). ¿Qué hace la versión de purrr que la tuya no?\nCrea una mejora de col_resumen() que aplique una función de resumen a cada columna numérica en un data frame.\nUn posible equivalente de col_resumen() es:\n\ncol_resumen3 &lt;- function(df, f) {\n  is_num &lt;- sapply(df, is.numeric)\n  df_num &lt;- df[, is_num]\n\n  sapply(df_num, f)\n}\n\nPero tiene una cantidad de bugs que queda ilustrada con las siguientes entradas:\n\ndf &lt;- tibble(\n  x = 1:3, \n  y = 3:1,\n  z = c(\"a\", \"b\", \"c\")\n)\n# OK\ncol_resumen3(df, mean)\n# Tiene problemas: no siempre devuelve un vector numérico\ncol_resumen3(df[1:2], mean)\ncol_resumen3(df[1], mean)\ncol_resumen3(df[0], mean)\n\n¿Qué causa los bugs?"
  },
  {
    "objectID": "22-model.html#generación-de-hipótesis-vs.-confirmación-de-hipótesis",
    "href": "22-model.html#generación-de-hipótesis-vs.-confirmación-de-hipótesis",
    "title": "22  Introducción",
    "section": "22.1 Generación de hipótesis vs. confirmación de hipótesis",
    "text": "22.1 Generación de hipótesis vs. confirmación de hipótesis\nEn este libro vamos a usar los modelos como una herramienta para la exploración, completando la tríada de las herramientas para EDA que se introdujeron en la Parte 1. Los modelos no se suelen enseñar de esta manera, pero como verás, son herramientas importantes para la exploración. Tradicionalmente, el enfoque del modelado está en la inferencia, es decir, para confirmar que una hipótesis es verdadera; hacerlo correctamente no es complicado, pero si difícil. Hay un par de ideas que debes comprender para poder hacer la inferencia correctamente:\n\nCada observación puede ser utilizada para exploración o para confirmación, pero no para ambas.\nPuedes usar una observación tantas veces como quieras para la exploración, pero solo una vez para confirmación. En el instante que usaste una observación dos veces, pasaste de confirmar a explorar.\n\nEsto es necesario porque, para confirmar una hipótesis, debes usar datos independientes de los datos utilizados para generarla. De lo contrario, serás demasiado optimista. No hay absolutamente nada de malo en la exploración, pero nunca debes vender un análisis exploratorio como análisis confirmatorio porque es fundamentalmente erróneo.\nSi realmente quieres realizar un análisis confirmatorio, un enfoque es dividir los datos en tres partes antes de comenzar el análisis:\n\nEl 60% de los datos van a un conjunto de entrenamiento (del inglés, training) o exploración. Puedes hacer lo que quieras con estos datos, desde visualizarlo a ajustar toneladas de modelos.\n20% va a un conjunto de consulta (del inglés, query). Se puede usar esta información para comparar modelos o hacer visualizaciones a mano, pero no está permitido usarlo como parte de un proceso automatizado.\nEl otro 20% se reserva para un conjunto de validación (del inglés, test). Sólo se pueden usar estos datos UNA VEZ, para probar tu modelo final.\n\nEsta partición de los datos, te permite explorar con los datos de entrenamiento, generando ocasionalmente hipótesis candidatas que se verifican con el conjunto de consultas. Cuando estés seguro de tener el modelo correcto, se verifica una vez con los datos del conjunto de validación.\n(Se debe tener en cuenta que, incluso cuando realice modelado confirmatorio, se necesita hacer EDA. Si no se realiza ninguna EDA, los problemas de calidad que tengan los datos quedarán ocultos)."
  },
  {
    "objectID": "23-model-basics.html#introducción",
    "href": "23-model-basics.html#introducción",
    "title": "23  Modelos: conceptos básicos",
    "section": "23.1 Introducción",
    "text": "23.1 Introducción\nEl objetivo de un modelo es proveer un resumen de baja dimensión de un conjunto de datos (o dataset, en inglés). En el contexto de este libro vamos a usar modelos para particionar los datos en patrones y residuos. Patrones fuertes esconderán tendencias sutiles, por lo que usaremos modelos para remover capas de estructuras mientras exploramos el conjunto de datos.\nSin embargo, antes de que podamos comenzar a usar modelos en conjuntos de datos interesantes y reales, necesitarás los conceptos básicos de cómo funcionan los modelos. Por dicha razón, este capítulo es único porque usa solamente datos simulados. Estos conjunto de datos son muy simples y no muy interesantes, pero nos ayudarán a entender la esencia del modelado antes de que apliques las mismas técnicas con datos reales en el próximo capítulo.\nHay dos partes en un modelo:\n\nPrimero, defines una familia de modelos que expresa un patrón que quieras capturar. El patrón debe ser preciso, pero también genérico. Por ejemplo, el patrón podría ser una línea recta, o una curva cuadrática. Expresarás la familia de modelos con una ecuación como y = a_1 * x + a_2 o y = a_1 * x ^ a_2. Aquí, x e y son variables conocidas de tus datos, y a_1 y a_2 son parámetros que pueden variar al capturar diferentes patrones.\nLuego, generas un modelo ajustado al encontrar un modelo de la familia que sea lo más cercano a tus datos. Esto toma la familia de modelos genérica y la vuelve específica, como y = 3 * x + 7 o y = 9 * x ^ 2.\n\nEs importante enteder que el modelo ajustado es solamente el modelo más cercano a la familia de modelos. Esto implica que tu tienes el “mejor” modelo (de acuerdo a cierto criterio); no implica que tu tienes un buen modelo y ciertamente no implica que ese modelo es “verdadero”. George Box lo explica muy bien en su famoso aforismo:\n\nTodos los modelos están mal, algunos son útiles.\n\nVale la pena leer el contexto más completo de la cita:\n\nAhora sería muy notable si cualquier sistema existente en el mundo real pudiera ser representado exactamente por algún modelo simple. Sin embargo, modelos simples astutamente escogidos a menudo proporcionan aproximaciones notablemente útiles.\nPor ejemplo, la ley PV = RT que relaciona la presión P, el volumen V y la temperatura T de un gas “ideal” a través de una constante R no es exactamente verdadera para cualquier gas real, pero frecuentmente provee una aproximación útil y, además, su estructura es informativa ya que proviene de un punto de vista físico del comportamiento de las moléculas de un gas.\nPara tal modelo, no hay necesidad de preguntarse “¿Es el modelo verdadero?”. Si la “verdad” debe ser la “verdad completa”, la respuesta debe ser “No”. La única pregunta de interés es “¿Es el modelo esclarecedor y útil?”.\n\nEl objetivo de un modelo no es descubrir la verdad, sino descubrir una aproximación simple que sea útil.\n\n23.1.1 Prerrequisitos\nEn este capítulo usaremos el paquete modelr que encapsula (del inglés wrapper) las funciones de modelado de R base para que funcionen naturalmente en un pipe.\n\nlibrary(tidyverse)\n\nlibrary(modelr)\noptions(na.action = na.warn)"
  },
  {
    "objectID": "23-model-basics.html#un-modelo-simple",
    "href": "23-model-basics.html#un-modelo-simple",
    "title": "23  Modelos: conceptos básicos",
    "section": "23.2 Un modelo simple",
    "text": "23.2 Un modelo simple\nMiremos el conjunto de datos simulado sim1, incluído dentro del paquete modelr. Este contiene dos variables continuas, x e y. Grafiquémoslas para ver como están relacionadas:\n\nggplot(sim1, aes(x, y)) +\n  geom_point()\n\n\n\n\nPuedes ver un fuerte patrón en los datos. Usemos un modelo para capturar dicho patrón y hacerlo explícito. Es nuestro trabajo proporcionar la forma básica del modelo. En este caso, la relación parece ser lineal, es decir: y = a_0 + a_1 * x. Comencemos por tener una idea de cómo son los modelos de esa familia generando aleatoriamente unos pocos y superponiéndolos sobre los datos. Para este caso simple, podemos usar geom_abline() que toma una pendiente e intercepto (u ordenada al origen) como parámetros. Más adelante, aprenderemos técnicas más generales que funcionan con cualquier modelo.\n\nmodelos &lt;- tibble(\n  a1 = runif(250, -20, 40),\n  a2 = runif(250, -5, 5)\n)\n\nggplot(sim1, aes(x, y)) +\n  geom_abline(aes(intercept = a1, slope = a2), data = modelos, alpha = 1 / 4) +\n  geom_point()\n\n\n\n\nHay 250 modelos en el gráfico, ¡pero muchos son realmente malos! Necesitamos encontrar los modelos buenos especificando nuestra intuición de que un buen modelo está “cerca” de los datos. Necesitamos una manera de cuantificar la distancia entre los datos y un modelo. Entonces podemos ajustar el modelo encontrando el valor de a_0 ya_1 que genera el modelo con la menor distancia a estos datos.\nUn lugar fácil para comenzar es encontrar la distancia vertical entre cada punto y el modelo, como lo muestra el siguiente diagrama. (Nota que he cambiado ligeramente los valores x para que puedas ver las distancias individuales.)\n\n\n\n\n\nLa distancia es solo la diferencia entre el valor dado por el modelo (la predicción), y el valor real y en los datos (la respuesta).\nPara calcular esta distancia, primero transformamos nuestra familia de modelos en una función de R. Esta función toma los parámetros del modelo y los datos como inputs, y retorna el valor predicho por el modelo como output:\n\nmodel1 &lt;- function(a, data) {\n  a[1] + data$x * a[2]\n}\nmodel1(c(7, 1.5), sim1)\n\n [1]  8.5  8.5  8.5 10.0 10.0 10.0 11.5 11.5 11.5 13.0 13.0 13.0 14.5 14.5 14.5\n[16] 16.0 16.0 16.0 17.5 17.5 17.5 19.0 19.0 19.0 20.5 20.5 20.5 22.0 22.0 22.0\n\n\nLuego, necesitaremos calcular la distancia entre lo predicho y los valores reales. En otras palabras, el siguiente gráfico muestra 30 distancias: ¿Cómo las colapsamos en un único número?\nUna forma habitual de hacer esto en estadística es usar la “raíz del error cuadrático medio” (del inglés root-mean-squared deviation). Calculamos la diferencia entre los valores reales y los predichos, los elevamos al cuadrado, luego se promedian y tomamos la raíz cuadrada. Esta distancia cuenta con propiedades matemáticas interesantes, pero no nos referiremos a ellas en este capítulo. ¡Tendrás que creer en mi palabra!\n\nmeasure_distance &lt;- function(mod, data) {\n  diff &lt;- data$y - model1(mod, data)\n  sqrt(mean(diff^2))\n}\nmeasure_distance(c(7, 1.5), sim1)\n\n[1] 2.665212\n\n\nAhora podemos usar purrr para calcular la distancia de todos los modelos definidos anteriormente. Necesitamos una función auxiliar debido a que nuestra función de distancia espera que el modelo sea un vector numérico de longitud 2.\n\nsim1_dist &lt;- function(a1, a2) {\n  measure_distance(c(a1, a2), sim1)\n}\n\nmodelos &lt;- modelos %&gt;%\n  mutate(dist = purrr::map2_dbl(a1, a2, sim1_dist))\nmodelos\n\n# A tibble: 250 × 3\n      a1     a2  dist\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 18.3   2.77  18.3 \n 2 -1.78  1.49   9.50\n 3  3.23  4.30  13.2 \n 4 27.9   2.43  25.9 \n 5  7.77  0.863  5.02\n 6  3.45  2.24   2.21\n 7 33.1  -0.357 17.2 \n 8 -6.04  0.795 17.7 \n 9 37.1   4.54  47.2 \n10 35.8   3.36  38.9 \n# ℹ 240 more rows\n\n\nA continuación, vamos a superponer los mejores 10 modelos en los datos. He coloreado los modelos usando -dist: esto es una forma fácil de asegurarse de que los mejores modelos (es decir, aquellos con la menor distancia) tengan los colores más brillantes.\n\nggplot(sim1, aes(x, y)) +\n  geom_point(size = 2, colour = \"grey30\") +\n  geom_abline(\n    aes(intercept = a1, slope = a2, colour = -dist),\n    data = filter(modelos, rank(dist) &lt;= 10)\n  )\n\n\n\n\nTambién podemos pensar estos modelos como observaciones y visualizar un diagrama de dispersión (o scatterplot, en inglés) de a1 versus a2, nuevamente coloreado usando -dist. No podremos ver directamente cómo el modelo contrasta con los datos, pero podemos ver muchos modelos a la vez. Nuevamente, he destacado los mejores 10 modelos, esta vez dibujando círculos rojos bajo ellos.\n\nggplot(modelos, aes(a1, a2)) +\n  geom_point(data = filter(modelos, rank(dist) &lt;= 10), size = 4, colour = \"red\") +\n  geom_point(aes(colour = -dist))\n\n\n\n\nEn lugar de probar con múltples modelos aleatorios, se puede sistematizar y generar una cuadrícula de puntos igualmente espaciados (esto se llama búsqueda en cuadrícula). He seleccionado los parámetros de la cuadrícula por aproximación, mirando donde se ubican los mejores modelos en el gráfico anterior.\n\ngrid &lt;- expand.grid(\n  a1 = seq(-5, 20, length = 25),\n  a2 = seq(1, 3, length = 25)\n) %&gt;%\n  mutate(dist = purrr::map2_dbl(a1, a2, sim1_dist))\n\ngrid %&gt;%\n  ggplot(aes(a1, a2)) +\n  geom_point(data = filter(grid, rank(dist) &lt;= 10), size = 4, colour = \"red\") +\n  geom_point(aes(colour = -dist))\n\n\n\n\nCuando superpones los mejores 10 modelos en los datos originales, se ven bastante bien:\n\nggplot(sim1, aes(x, y)) +\n  geom_point(size = 2, colour = \"grey30\") +\n  geom_abline(\n    aes(intercept = a1, slope = a2, colour = -dist),\n    data = filter(grid, rank(dist) &lt;= 10)\n  )\n\n\n\n\nPodrás imaginarte que de forma iterativa puedo hacer la cuadrícula más y más fina hasta reducir los resultados al mejor modelo. Existe una forma mejor de resolver el problema: una herramienta de minimización llamada búsqueda de Newton-Raphson. La intuición detrás de Newton-Raphson es bastante simple: tomas un punto de partida y buscas la pendiente más fuerte en torno a ese punto. Puedes bajar por esa pendiente un poco, para luego repetir el proceso varias veces, hasta que no se puede descender más. En R, esto se puede hacer con la función optim():\n\nbest &lt;- optim(c(0, 0), measure_distance, data = sim1)\nbest$par\n\n[1] 4.222248 2.051204\n\nggplot(sim1, aes(x, y)) +\n  geom_point(size = 2, colour = \"grey30\") +\n  geom_abline(intercept = best$par[1], slope = best$par[2])\n\n\n\n\nNo te preocupes demasiado acerca de los detalles de cómo funciona optim(). La intuición es lo importante en esta parte. Si tienes una función que define la mínima distancia entre un modelo y un conjunto de datos, un algoritmo que pueda minimizar la distancia modificando los parámetros del modelo te permitirá encontrar el mejor modelo. Lo interesante de este enfoque es que funciona con cualquier familia de modelos respecto de la cual se pueda escribir una ecuación que los describa.\nExiste otro enfoque que podemos usar para este modelo, debido a que es un caso especial de una familia más amplia: los modelos lineales. Un modelo lineal es de la forma y = a_1 + a_2 * x_1 + a_3 * x_2 + ... + a_n * x_(n+1). Este modelo simple es equivalente a un modelo lineal generalizado en el que n tiene valor 2 y x_1 es x. R cuenta con una herramienta diseñada especialmente para ajustar modelos lineales llamada lm(). lm() tiene un modo especial de especificar la familia del modelo: las fórmulas. Las fórmulas son similares a y ~ x, que lm() traducirá a una función de la forma y = a_1 + a_2 * x. Podemos ajustar el modelo y mirar la salida:\n\nsim1_mod &lt;- lm(y ~ x, data = sim1)\ncoef(sim1_mod)\n\n(Intercept)           x \n   4.220822    2.051533 \n\n\n¡Estos son exactamente los mismos valores obtenidos con optim()! Detrás del escenario lm() no usa optim(), sin embargo saca ventaja de la estructura matemática de los modelos lineales. Usando algunas conexiones entre geometría, cálculo y álgebra lineal, lm() encuentra directamente el mejor modelo en un paso, usando un algoritmo sofisticado. Este enfoque es a la vez raṕido y garantiza que existe un mínimo global.\n\n23.2.1 Ejercicios\n\nUna desventaja del modelo lineal es ser sensible a valores inusuales debido a que la distancia incorpora un término al cuadrado. Ajusta un modelo a los datos simulados que se presentan a continuación y visualiza los resultados. Corre el modelo varias veces para generar diferentes conjuntos de datos simulados. ¿Qué puedes observar respecto del modelo?\n\n::: {.cell}\nsim1a &lt;- tibble(\n x = rep(1:10, each = 3),\n y = x * 1.5 + 6 + rt(length(x), df = 2)\n)\n:::\n\nUna forma de obtener un modelo lineal más robusto es usar una métrica distinta para la distancia. Por ejemplo, en lugar de la raíz de la distancia media cuadrática (del inglés root-mean-squared distance) se podría usar la media de la distancia absoluta:\n\n::: {.cell}\nmeasure_distance &lt;- function(mod, data) {\n diff &lt;- data$y - model1(mod, data)\n mean(abs(diff))\n}\n:::\nUsa optim() para ajustar este modelo a los datos simulados anteriormente y compara el resultado con el modelo lineal.\n\nUn desafío al realizar optimización numérica es que únicamente garantiza encontrar un óptimo local. ¿Qué problema se presenta al optimizar un modelo de tres parámetros como el que se presenta a continuación?\n\n::: {.cell}\nmodel1 &lt;- function(a, data) {\n a[1] + data$x * a[2] + a[3]\n}\n:::"
  },
  {
    "objectID": "23-model-basics.html#visualizando-modelos",
    "href": "23-model-basics.html#visualizando-modelos",
    "title": "23  Modelos: conceptos básicos",
    "section": "23.3 Visualizando modelos",
    "text": "23.3 Visualizando modelos\nPara modelos simples, como el presentado anteriormente, puedes descubrir el patrón que captura el modelo si inspeccionas cuidadosamente la familia del modelo y los coeficientes ajustados. Si alguna vez tomaste un curso de modelado estadístico, te será habitual gastar mucho tiempo en esa tarea. Aquí, sin embargo, tomaremos otro camino. Vamos a enfocarnos en entender un modelo mirando las predicciones que genera. Esto tiene una gran ventaja: cada tipo de modelo predictivo realiza predicciones (¿qué otra podría realizar?) de modo que podemos usar el mismo conjunto de técnicas para entender cualquier tipo de modelo predictivo.\nTambién es útil observar lo que el modelo no captura, los llamados residuos que se obtienen restando las predicciones a los datos. Los residuos son poderosos porque nos permiten usar modelos para quitar patrones fuertes y así observar tendencias sutiles que se mantengan luego de quitar los patrones más evidentes.\n\n23.3.1 Predicciones\nPara visualizar las predicciones de un modelo, podemos partir por generar una grilla de valores equidistantes que cubra la región donde se encuentran los datos. La forma más fácil de hacerlo es usando modelr::data_grid(). El primer argumento es un data frame y, por cada argumento adicional, encuentra las variables únicas y luego genera todas las combinaciones:\n\ngrid &lt;- sim1 %&gt;%\n  data_grid(x)\ngrid\n\n# A tibble: 10 × 1\n       x\n   &lt;int&gt;\n 1     1\n 2     2\n 3     3\n 4     4\n 5     5\n 6     6\n 7     7\n 8     8\n 9     9\n10    10\n\n\n(Esto será más interesante cuando se agreguen más variables al modelo.)\nLuego agregamos las predicciones. Usaremos modelr::add_predictions() que toma un data frame y un modelo. Esto agrega las predicciones del modelo en una nueva columna en el data frame:\n\ngrid &lt;- grid %&gt;%\n  add_predictions(sim1_mod)\ngrid\n\n# A tibble: 10 × 2\n       x  pred\n   &lt;int&gt; &lt;dbl&gt;\n 1     1  6.27\n 2     2  8.32\n 3     3 10.4 \n 4     4 12.4 \n 5     5 14.5 \n 6     6 16.5 \n 7     7 18.6 \n 8     8 20.6 \n 9     9 22.7 \n10    10 24.7 \n\n\n(También puedes usar esta función para agregar prediccionees al conjunto de datos original.)\nA continuación, graficamos las predicciones. Te preguntarás acerca de todo este trabajo adicional en comparación a usar geom_abline(). Pero la ventaja de este enfoque es que funciona con cualquier modelo en R, desde los más simples a los más complejos. La única limitante son tus habilidades de visualización. Para más ideas respecto de como visualizar modelos complejos, puedes consultar http://vita.had.co.nz/papers/model-vis.html.\n\nggplot(sim1, aes(x)) +\n  geom_point(aes(y = y)) +\n  geom_line(aes(y = pred), data = grid, colour = \"red\", size = 1)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n23.3.2 Residuos\nLa otra cara de las predicciones son los residuos. Las predicciones te informan de los patrones que el modelo captura y los residuos te dicen lo que el modelo ignora. Los residuos son las distancias entre lo observado y los valores predichos que calculamos anteriormente.\nAgregamos los residuos a los datos con add_residuals(), que funciona de manera similar a add_predictions(). Nota, sin embargo, que usamos el data frame original y no no una grilla manufacturada. Esto es porque para calcular los residuos se necesitan los valores de “y”.\n\nsim1 &lt;- sim1 %&gt;%\n  add_residuals(sim1_mod)\nsim1\n\n# A tibble: 30 × 3\n       x     y    resid\n   &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1     1  4.20 -2.07   \n 2     1  7.51  1.24   \n 3     1  2.13 -4.15   \n 4     2  8.99  0.665  \n 5     2 10.2   1.92   \n 6     2 11.3   2.97   \n 7     3  7.36 -3.02   \n 8     3 10.5   0.130  \n 9     3 10.5   0.136  \n10     4 12.4   0.00763\n# ℹ 20 more rows\n\n\nExisten diferentes formas de entender qué nos dicen los residuos respecto del modelo. Una forma es dibujar un polígono de frecuencia que nos ayude a entender cómo se propagan los residuos:\n\nggplot(sim1, aes(resid)) +\n  geom_freqpoly(binwidth = 0.5)\n\n\n\n\nEsto ayuda a calibrar la calidad del modelo: ¿qué tan lejos se encuentran las predicciones de los valores observados? Nota que el promedio del residuo es siempre cero.\nA menudo vas a querer crear gráficos usando los residuos en lugar del predictor original. Verás mucho de eso en el capítulo siguiente:\n\nggplot(sim1, aes(x, resid)) +\n  geom_ref_line(h = 0) +\n  geom_point()\n\n\n\n\nEsto parece ser ruido aleatorio, lo que sugiere que el modelo ha hecho un buen trabajo capturando los patrones del conjunto de datos.\n\n\n23.3.3 Ejercicios\n\nEn lugar de usar lm() para ajustar una línea recta, puedes usar loess() para ajustar una curva suave. Repite el proceso de ajustar el modelo, generar la cuadrícula, predicciones y visualización con sim1 usando loess() en vez de lm(). ¿Cómo se compara el resultado a geom_smooth().\nadd_predictions() está pareada con gather_predictions() y spread_predictions(). ¿Cómo difieren estas tres funciones?\n¿Qué hace geom_ref_line()? ¿De qué paquete proviene? ¿Por qué es útil e importante incluir una línea de referencia en los gráficos que muestran residuos?\n¿Por qué quisieras mirar un polígono de frecuencias con los residuos absolutos? ¿Cuáles son las ventajas y desventajas de los residuos crudos?"
  },
  {
    "objectID": "23-model-basics.html#fórmulas-y-familias-de-modelos",
    "href": "23-model-basics.html#fórmulas-y-familias-de-modelos",
    "title": "23  Modelos: conceptos básicos",
    "section": "23.4 Fórmulas y familias de modelos",
    "text": "23.4 Fórmulas y familias de modelos\nYa habrás visto fórmulas anteriormente cuando usamos facet_wrap() y facet_grid(). En R, las fórmulas proveen un modo general de obtener “comportamientos especiales”. En lugar de evaluar los valores de las variables directamente, se capturan los valores para que sean interpretados por una función.\nLa mayoría de los las funciones de modelado en R usan una conversión estándar para las fórmulas y las funciones. Ya habrás visto una conversión simple y ~ x que se convierte en y = a_1 + a_2 * x. Si quieres ver lo que hace R, puedes usar la función model_matrix(). Esta toma un data frame y una fórmula para entregar un tibble que define la ecuación del modelo: cada columna en la salida está asociada con un coeficiente del modelo, la función es siempre y = a_1 * salida_1 + a_2 * salida_2. Para el caso simple y ~ x1 esto nos muestra algo interesante:\n\ndf &lt;- tribble(\n  ~y, ~x1, ~x2,\n  4, 2, 5,\n  5, 1, 6\n)\nmodel_matrix(df, y ~ x1)\n\n# A tibble: 2 × 2\n  `(Intercept)`    x1\n          &lt;dbl&gt; &lt;dbl&gt;\n1             1     2\n2             1     1\n\n\nLa forma en que R agrega el intercepto (u ordenada al origen) al modelo es mediante una columna de unos. Por defecto, R siempre agregará esta columna. Si no quieres esto, necesitas excluirla explícitamente usando -1:\n\nmodel_matrix(df, y ~ x1 - 1)\n\n# A tibble: 2 × 1\n     x1\n  &lt;dbl&gt;\n1     2\n2     1\n\n\nLa matriz del modelo crece de manera nada sorprendente si incluyes más variables al modelo:\n\nmodel_matrix(df, y ~ x1 + x2)\n\n# A tibble: 2 × 3\n  `(Intercept)`    x1    x2\n          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1             1     2     5\n2             1     1     6\n\n\nEsta notación para las fórmulas a veces se le llama “notación de Wilkinson-Rogers”, la cual fue descrita inicialmente en Symbolic Description of Factorial Models for Analysis of Variance, escrito por G. N. Wilkinson y C. E. Rogers https://www.jstor.org/stable/2346786. Es conveniente excavar un poco y leer el artículo original si quieres entender los detalles del álgebra de modelado.\nLas siguientes secciones detallan cómo esta notación de fórmulas funciona con variables categóricas, interacciones y transformaciones.\n\n23.4.1 Variables categóricas\nGenerar una función a partir de una fórmula es directo cuando el predictor es una variable continua, pero las cosas son más complicadas cuando el predictor es una variable categórica. Imagina que tienes una fórmula como y ~ sexo, donde el sexo puede ser hombre o mujer. No tiene sentido convertir a una fórmula del tipo y = a_0 + a_1 * sexo debido a que sexo no es un número - ¡no se puede multiplicar! En su lugar, lo que R hace es convertir a y = a_0 + a_1 * sexo_hombre donde sexo_hombre tiene valor 1 si sexo corresponde a hombre y cero a mujer:\n\ndf &lt;- tribble(\n  ~genero, ~respuesta,\n  \"masculino\", 1,\n  \"femenino\", 2,\n  \"masculino\", 1\n)\nmodel_matrix(df, respuesta ~ genero)\n\n# A tibble: 3 × 2\n  `(Intercept)` generomasculino\n          &lt;dbl&gt;           &lt;dbl&gt;\n1             1               1\n2             1               0\n3             1               1\n\n\nQuizá te preguntes por qué R no crea la columna generofemenino. El problema es que eso crearía una columna perfectamente predecible a partir de las otras columnas (es decir, generofemenino = 1 - generomasculino). Desafortunadamete los detalles exactos de por qué esto es un problema van más allá del alcance del libro, pero básicamente crea una familia de modelos que es muy flexible y genera infinitos modelos igualmente cercanos a los datos.\nAfortunadamente, sin embargo, si te enfocas en visualizar las predicciones no necesitas preocuparte de la parametrización exacta. Veamos algunos datos y modelos para hacer algo concreto. Aquí está el dataset sim2 de modelr:\n\nggplot(sim2) +\n  geom_point(aes(x, y))\n\n\n\n\nPodemos ajustar un modelo a esto y generar predicciones:\n\nmod2 &lt;- lm(y ~ x, data = sim2)\n\ngrid &lt;- sim2 %&gt;%\n  data_grid(x) %&gt;%\n  add_predictions(mod2)\ngrid\n\n# A tibble: 4 × 2\n  x      pred\n  &lt;chr&gt; &lt;dbl&gt;\n1 a      1.15\n2 b      8.12\n3 c      6.13\n4 d      1.91\n\n\nEfectivamente, un modelo con una variable x categórica va a predecir el valor medio para cada categoría. (¿Por qué? porque la media minimiza la raíz de la distancia media cuadrática.) Es fácil de ver si superponemos la predicción sobre los datos originales:\n\nggplot(sim2, aes(x)) +\n  geom_point(aes(y = y)) +\n  geom_point(data = grid, aes(y = pred), colour = \"red\", size = 4)\n\n\n\n\nNo es posible hacer predicciones sobre niveles no observados. A veces harás esto por accidente, por lo que es bueno reconocer el siguiente mensaje de error:\n\ntibble(x = \"e\") %&gt;%\n  add_predictions(mod2)\n\nError in model.frame.default(Terms, newdata, na.action = na.action, xlev = object$xlevels): factor x has new level e\n\n\n\n\n23.4.2 Interacciones (continuas y categóricas)\n¿Qué ocurre si combinas una variable continua y una categórica? sim3 contiene un predictor categórico y otro predictor continuo. Podemos visualizarlos con un gráfico simple:\n\nggplot(sim3, aes(x1, y)) +\n  geom_point(aes(colour = x2))\n\n\n\n\nExisten dos posibles modelos que se pueden ajustar a estos datos:\n\nmod1 &lt;- lm(y ~ x1 + x2, data = sim3)\nmod2 &lt;- lm(y ~ x1 * x2, data = sim3)\n\nCuando agregas variables con + el modelo va a estimar cada efecto independientemente de los demás. Es posible agregar al ajuste lo que se conoce como interacción usando *. Por ejemplo, y ~ x1 * x2 se traduce en y = a_0 + a_1 * x_1 + a_2 * x_2 + a_12 * x_1 * x_2. Observa que si usas *, tanto el efecto interacción como los efectos individuales se incluyen en el modelo.\nPara visualizar estos modelos necesitamos dos nuevos trucos:\n\nTenemos dos predictores, por lo que necesitamos pasar ambas variables a data_grid(). Esto encontrará todos los valores únicos de x1 y x2 y luego generará todas las combinaciones,\nPara generar predicciones de ambos modelos simultáneamente, podemos usar gather_predictions() que incorpora cada predicción como una fila. El complemento de gather_predictions() es spread_predictions() que incluye cada predicción en una nueva columna.\n\nEsto combinado nos da:\n\ngrid &lt;- sim3 %&gt;%\n  data_grid(x1, x2) %&gt;%\n  gather_predictions(mod1, mod2)\ngrid\n\n# A tibble: 80 × 4\n   model    x1 x2     pred\n   &lt;chr&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt;\n 1 mod1      1 a      1.67\n 2 mod1      1 b      4.56\n 3 mod1      1 c      6.48\n 4 mod1      1 d      4.03\n 5 mod1      2 a      1.48\n 6 mod1      2 b      4.37\n 7 mod1      2 c      6.28\n 8 mod1      2 d      3.84\n 9 mod1      3 a      1.28\n10 mod1      3 b      4.17\n# ℹ 70 more rows\n\n\nPodemos visualizar los resultados de ambos modelos en un gráfico usando separando en facetas:\n\nggplot(sim3, aes(x1, y, colour = x2)) +\n  geom_point() +\n  geom_line(data = grid, aes(y = pred)) +\n  facet_wrap(~model)\n\n\n\n\nObserva que el modelo que usa + tiene la misma pendiente para cada recta, pero distintos interceptos (u ordenadas al origen). El modelo que usa * tiene distinta pendiente e intercepto.\n¿Qué modelo es el más adecuado para los datos? Podemos mirar los residuos. Aquí hemos separado facetas por modelo y por x2ya que facilita ver el patrón dentro de cada grupo.\n\nsim3 &lt;- sim3 %&gt;%\n  gather_residuals(mod1, mod2)\n\nggplot(sim3, aes(x1, resid, colour = x2)) +\n  geom_point() +\n  facet_grid(model ~ x2)\n\n\n\n\nExiste un patrón poco obvio en los residuos de mod2. Los residuos de mod1 muestran que el modelo tiene algunos patrones ignorados en b, y un poco menos ignorados en c y d. Quizá te preguntas si existe una forma precisa de determinar si acaso mod1 o mod2 es mejor. Existe, pero requiere un respaldo matemático fuerte y no nos preocuparemos de eso. Lo que aquí interesa es evaluar cualitativamente si el modelo ha capturado los patrones que nos interesan.\n\n\n23.4.3 Interacciones (dos variables continuas)\nDemos un vistazo al modelo equivalente para dos variables continuas. Para comenzar, se procede de igual modo que el ejemplo anterior:\n\nmod1 &lt;- lm(y ~ x1 + x2, data = sim4)\nmod2 &lt;- lm(y ~ x1 * x2, data = sim4)\n\ngrid &lt;- sim4 %&gt;%\n  data_grid(\n    x1 = seq_range(x1, 5),\n    x2 = seq_range(x2, 5)\n  ) %&gt;%\n  gather_predictions(mod1, mod2)\ngrid\n\n# A tibble: 50 × 4\n   model    x1    x2   pred\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 mod1   -1    -1    0.996\n 2 mod1   -1    -0.5 -0.395\n 3 mod1   -1     0   -1.79 \n 4 mod1   -1     0.5 -3.18 \n 5 mod1   -1     1   -4.57 \n 6 mod1   -0.5  -1    1.91 \n 7 mod1   -0.5  -0.5  0.516\n 8 mod1   -0.5   0   -0.875\n 9 mod1   -0.5   0.5 -2.27 \n10 mod1   -0.5   1   -3.66 \n# ℹ 40 more rows\n\n\nObserva el uso de seq_range() dentro de data_grid(). En lugar de usar cada valor único de x, usamos una cuadrícula uniformemente espaciada de cinco valores entre los números mínimo y máximo. Quizá no es lo más importante aquí, pero es una técnica útil en general. Existen otros dos argumentos en seq_range():\n\npretty = TRUE generará una secuencia “bonita”, por ejemplo algo agradable al ojo humano. Esto es útil si quieres generar tablas a partir del output:\n\n::: {.cell}\nseq_range(c(0.0123, 0.923423), n = 5)\n::: {.cell-output .cell-output-stdout} [1] 0.0123000 0.2400808 0.4678615 0.6956423 0.9234230 :::\nseq_range(c(0.0123, 0.923423), n = 5, pretty = TRUE)\n::: {.cell-output .cell-output-stdout} [1] 0.0 0.2 0.4 0.6 0.8 1.0 ::: :::\n\ntrim = 0.1 eliminará el 10% de los valores en el extremo de la cola. Esto es útil si las variables tienen una distribución con una cola larga y te quieres enfocar en generar valores cerca del centro:\n\n::: {.cell}\nx1 &lt;- rcauchy(100)\nseq_range(x1, n = 5)\n::: {.cell-output .cell-output-stdout} [1] -139.61834 -100.29139  -60.96445  -21.63751   17.68944 :::\nseq_range(x1, n = 5, trim = 0.10)\n::: {.cell-output .cell-output-stdout} [1] -10.539816  -6.283969  -2.028122   2.227725   6.483572 :::\nseq_range(x1, n = 5, trim = 0.25)\n::: {.cell-output .cell-output-stdout} [1] -3.7377131 -2.0251329 -0.3125527  1.4000275  3.1126077 :::\nseq_range(x1, n = 5, trim = 0.50)\n::: {.cell-output .cell-output-stdout} [1] -0.8061662 -0.2916046  0.2229570  0.7375186  1.2520802 ::: :::\n\nexpand = 0.1 es en cierta medida el opuesto de trim() ya que expande el rango en un 10%.\n\n::: {.cell}\nx2 &lt;- c(0, 1)\nseq_range(x2, n = 5)\n::: {.cell-output .cell-output-stdout} [1] 0.00 0.25 0.50 0.75 1.00 :::\nseq_range(x2, n = 5, expand = 0.10)\n::: {.cell-output .cell-output-stdout} [1] -0.050  0.225  0.500  0.775  1.050 :::\nseq_range(x2, n = 5, expand = 0.25)\n::: {.cell-output .cell-output-stdout} [1] -0.1250  0.1875  0.5000  0.8125  1.1250 :::\nseq_range(x2, n = 5, expand = 0.50)\n::: {.cell-output .cell-output-stdout} [1] -0.250  0.125  0.500  0.875  1.250 ::: :::\nA continuación intentemos visualizar el modelo. Tenemos dos predictores continuos, por lo que te imaginarás el modelo como una superficie 3d. Podemos mostrar esto usando geom_tile():\n\nggplot(grid, aes(x1, x2)) +\n  geom_tile(aes(fill = pred)) +\n  facet_wrap(~model)\n\n\n\n\n¡Esto no sugiere que los modelos sean muy distintos! Pero eso es en parte una ilusión: nuestros ojos y cerebros no son muy buenos en comparar sombras de color de forma adecuada. En lugar de mirar la superficie desde arriba, podríamos mirarla desde los costados, mostrando múltiples cortes:\n\nggplot(grid, aes(x1, pred, colour = x2, group = x2)) +\n  geom_line() +\n  facet_wrap(~model)\n\n\n\nggplot(grid, aes(x2, pred, colour = x1, group = x1)) +\n  geom_line() +\n  facet_wrap(~model)\n\n\n\n\nEsto muestra la interacción entre dos variables continuas que básicamente opera del mismo modo que una variable continua y una categórica. Una interacción dice que no existe un resultado fijo: necesitas considerar los valores de x1 y x2 simultáneamente para predecir y.\nPodrás ver que con apenas dos variables continuas, obtener un buen resultado de visualización es difícil. Pero esto es razonable: ¡no deberías esperar que con tres o más variables sea más fácil entender la interacción! Nuevamente, estamos parcialmente a salvo porque estamos usando modelos para la exploración y crearás tus propios modelos en el tiempo. El modelo no debe ser perfecto, tiene que ayudar a revelar información acerca de los datos.\nPasé un tiempo mirando los residuos para ver si acaso mod2 es mejor que mod1. Creo que lo es, pero es algo sutil. Tendrás la oportunidad de explorar esto en los ejercicios.\n\n\n23.4.4 Transformaciones\nPuedes hacer transformaciones dentro de la fórmula del modelo. Por ejemplo log(y) ~ sqrt(x1) + x2 se transforma en log(y) = a_1 + a_2 * sqrt(x1) + a_3 * x2. Si la transformación involucra +, *, ^ o -, necesitas dejar eso dentro de I() para que R no lo tome como parte de la especificación del modelo. Por ejemplo, y ~ x + I(x ^ 2) se traduce en y = a_1 + a_2 * x + a_3 * x^2. Si olvidas incluir I() y especificas y ~ x ^ 2 + x, R va a calcular y ~ x * x + x. x * x lo que resulta en la interacción de x consigo misma, lo que se reduce a x. R automáticamente elimina las variables redundantes, por lo que x + x se convierte en x, lo que significa que y ~ x ^ 2 + x especifica la función y = a_1 + a_2 * x. ¡Eso probablemente no es lo que querías!\nNuevamente, si te confunde lo que el modelo hace, puedes usar model_matrix() para ver exactamente lo que la ecuación lm() está ajustando:\n\ndf &lt;- tribble(\n  ~y, ~x,\n  1, 1,\n  2, 2,\n  3, 3\n)\nmodel_matrix(df, y ~ x^2 + x)\n\n# A tibble: 3 × 2\n  `(Intercept)`     x\n          &lt;dbl&gt; &lt;dbl&gt;\n1             1     1\n2             1     2\n3             1     3\n\nmodel_matrix(df, y ~ I(x^2) + x)\n\n# A tibble: 3 × 3\n  `(Intercept)` `I(x^2)`     x\n          &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1             1        1     1\n2             1        4     2\n3             1        9     3\n\n\nLas transformaciones son útiles porque puedes aproximar funciones no lineales. Si tuviste clases de cálculo, habrás escuchado acerca del teorema de Taylor que dice que puedes aproximar una función suave como la suma de infinitos polinomios. Esto significa que puedes usar una función polinomial para acercarte a una distancia arbitrariamente pequeña de una función suave ajustando una ecuación como y = a_1 + a_2 * x + a_3 * x^2 + a_4 * x^3. Escribir esta secuencia a mano es tedioso, pero R provee la función auxiliar poly():\n\nmodel_matrix(df, y ~ poly(x, 2))\n\n# A tibble: 3 × 3\n  `(Intercept)` `poly(x, 2)1` `poly(x, 2)2`\n          &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1             1     -7.07e- 1         0.408\n2             1     -7.85e-17        -0.816\n3             1      7.07e- 1         0.408\n\n\nSin embargo, existe un problema mayor al usar poly(): fuera del rango de los datos, los polinomios rápidamente se disparan a infinito positivo o negativo. Una alternativa más segura es usar spline natural, splines::ns().\n\nlibrary(splines)\nmodel_matrix(df, y ~ ns(x, 2))\n\n# A tibble: 3 × 3\n  `(Intercept)` `ns(x, 2)1` `ns(x, 2)2`\n          &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1             1       0           0    \n2             1       0.566      -0.211\n3             1       0.344       0.771\n\n\nVeamos esto cuando intentamos aproximar una función no lineal:\n\nsim5 &lt;- tibble(\n  x = seq(0, 3.5 * pi, length = 50),\n  y = 4 * sin(x) + rnorm(length(x))\n)\n\nggplot(sim5, aes(x, y)) +\n  geom_point()\n\n\n\n\nVoy a ajustar cinco modelos a los datos.\n\nmod1 &lt;- lm(y ~ splines::ns(x, 1), data = sim5)\nmod2 &lt;- lm(y ~ splines::ns(x, 2), data = sim5)\nmod3 &lt;- lm(y ~ splines::ns(x, 3), data = sim5)\nmod4 &lt;- lm(y ~ splines::ns(x, 4), data = sim5)\nmod5 &lt;- lm(y ~ splines::ns(x, 5), data = sim5)\n\ngrid &lt;- sim5 %&gt;%\n  data_grid(x = seq_range(x, n = 50, expand = 0.1)) %&gt;%\n  gather_predictions(mod1, mod2, mod3, mod4, mod5, .pred = \"y\")\n\nggplot(sim5, aes(x, y)) +\n  geom_point() +\n  geom_line(data = grid, colour = \"red\") +\n  facet_wrap(~model)\n\n\n\n\nObserva que la extrapolación fuera del rango de los datos es claramente mala. Esta es la desventaja de aproximar una función mediante un polinomio. Pero este es un problema real con cualquier modelo: el modelo nunca te dirá si el comportamiento es verdadero cuando extrapolas fuera del rango de los datos que has observado. Deberás apoyarte en la teoría y la ciencia.\n\n\n23.4.5 Ejercicios\n\n¿Qué pasa si repites el análisis de sim2 usando un modelo sin intercepto? ¿Qué ocurre con la ecuación del modelo? ¿Qué ocurre con las predicciones?\nUsa model_matrix() para explorar las ecuaciones generadas por los modelos ajustados a sim3 y sim4. ¿Por qué * es un atajo para la interacción?\nUsando los principios básicos, convierte las fórmulas de los siguientes modelos en funciones. (Sugerencia: comienza por convertir las variables categóricas en ceros y unos.)\n\n::: {.cell}\nmod1 &lt;- lm(y ~ x1 + x2, data = sim3)\nmod2 &lt;- lm(y ~ x1 * x2, data = sim3)\n:::\n\nPara sim4, ¿Es mejor mod1 o mod2? Yo creo que mod2 es ligeramente mejor removiendo las tendencias, pero es bastante sutil. ¿Puedes generar un gráfico que de sustento a esta hipótesis?"
  },
  {
    "objectID": "23-model-basics.html#valores-faltantes",
    "href": "23-model-basics.html#valores-faltantes",
    "title": "23  Modelos: conceptos básicos",
    "section": "23.5 Valores faltantes",
    "text": "23.5 Valores faltantes\nLos valores faltantes obviamente no proporcionan información respecto de la relación entre las variables, por lo que modelar funciones va a eliminar todas las filas con valores faltantes. R por defecto lo hace de forma silenciosa, pero options(na.action = na.warn) (ejecutado en los prerrequisitos) asegura que la salida incluya una advertencia.\n\ndf &lt;- tribble(\n  ~x, ~y,\n  1, 2.2,\n  2, NA,\n  3, 3.5,\n  4, 8.3,\n  NA, 10\n)\n\nmod &lt;- lm(y ~ x, data = df)\n\nWarning: Dropping 2 rows with missing values\n\n\nPara suprimir los mensajes de advertencia, incluye na.action = na.exclude:\n\nmod &lt;- lm(y ~ x, data = df, na.action = na.exclude)\n\nSiempre puedes consultar cuántas observaciones se usaron con nobs():\n\nnobs(mod)\n\n[1] 3"
  },
  {
    "objectID": "23-model-basics.html#otras-familias-de-modelos",
    "href": "23-model-basics.html#otras-familias-de-modelos",
    "title": "23  Modelos: conceptos básicos",
    "section": "23.6 Otras familias de modelos",
    "text": "23.6 Otras familias de modelos\nEste capítulo se centró de forma exclusiva en la familia de modelos lineales, la cual asume una relación de la forma y = a_1 * x1 + a_2 * x2 + ... + a_n * xn. Además, los modelos lineales asumen que los residuos siguen una distribución normal, algo de lo que no hemos hablado. Existe un amplio conjunto de familias de modelos que extienden la familia de modelos lineales de varias formas interesantes. Algunos son:\n\nModelos lineales generalizados, es decir, stats::glm(). Los modelos lineales asumen que la respuesta es una variable continua y que el error sigue una distribución normal. Los modelos lineales generalizados extienden los modelos lineales para incluir respuestas no continuas (es decir, datos binarios o conteos). Definen una distancia métrica basada en la idea estadística de verosimilitud.\nModelos generalizados aditivos, es decir, mgcv::gam(), extienden los modelos lineales generalizados para incorporar funciones suaves arbitrarias. Esto significa que puedes escribir una fórmula del tipo y ~ s(x) que se transforma en una ecuación de la forma y = f(x) y dejar que gam() estime la función (sujeto a algunas restricciones de suavidad para que el problema sea manejable).\nModelos lineales penalizados, es decir, glmnet::glmnet(), incorporan un término de penalización a la distancia y así penalizan modelos complejos (definidos por la distancia entre el vector de parámetros y el origen). Esto tiende a entregar modelos que generalizan mejor respecto de nuevos conjuntos de datos para la misma población.\nModelos lineales robustos, es decir, MASS:rlm(), modifican la distancia para restar importancia a los puntos que quedan muy alejados. Esto resulta en modelos menos sensibles a valores extremos, con el inconveniente de que no son muy buenos cuando no hay valores extremos.\nÁrboles, es decir, rpart::rpart(), atacan un problema de un modo totalmente distinto a los modelos lineales. Ajustan un modelo constante por partes, dividiendo los datos en partes progresivamente más y más pequeñas. Los árboles no son tremendamente efectivos por sí solos, pero son muy poderosos cuando se usan en modelos agregados como bosques aleatorios, del inglés random forests), (es decir, randomForest::randomForest()) o máquinas aceleradoras de gradiente, del inglés gradient boosting machines (es decir, xgboost::xgboost.).\n\nEstos modelos son todos similares desde una perspectiva de programación. Una vez que hayas manejado los modelos lineales, te resultará sencillo entender la mecánica de otras clases de modelos. Ser un modelador hábil consiste en tener buenos principios generales y una gran caja de herramientas técnicas. Ahora que has aprendido algunas herramientas y algunas clases de modelos, puedes continuar aprendiendo sobre otras clases en otras fuentes."
  },
  {
    "objectID": "24-model-building.html#introducción",
    "href": "24-model-building.html#introducción",
    "title": "24  Construcción de modelos",
    "section": "24.1 Introducción",
    "text": "24.1 Introducción\nEn el capítulo previo aprendimos cómo funcionan los modelos lineales, y aprendimos algunas herramientas básicas para entender lo que un modelo está mostrando con sus datos. El capítulo previo se enfocó en simular conjunto de datos. Este capítulo se centrará en datos reales, mostrando como puedes progresivamente construir un modelo que te ayude a entender los datos.\nTomaremos ventaja del hecho que se puede pensar que un modelo particiona tus datos en patrones y residuos. Encontraremos patrones con visualizaciones, luego los haremos concretos y precisos con un modelo. Repetiremos luego el proceso, pero reemplazaremos la variable antigua con los residuos del modelo. El objetivo es pasar de un conocimiento implícito en la data a un conocimiento explícito en un modelo cuantitativo. Esto hace que sea más fácil aplicar nuevos dominios, y más fácil de usar para otros.\nPara un conjunto de datos muy grande y complejo esto será mucho trabajo. Sin duda hay enfoques alternativos - un enfoque de aprendizaje automático es simplemente enfocarse en la capacidad predictiva del modelo. Ese enfoque tiende a producir cajas negras: el modelo hace muy bien su trabajo generando predicciones, pero no sabes por qué. Esto es un enfoque totalmente razonable, pero es difícil de aplicar el conocimiento del mundo real al modelo. Eso, a su vez, hace difícil evaluar si el modelo continuará o no funcionando a largo plazo, ya que los fundamentos cambian. Para la mayoría de los modelos, esperaría que usaras alguna combinación de este enfoque y un enfoque clásico automatizado.\nEs un desafio saber cuando detenerse. Necesitas darte cuenta cuando tu modelo es lo suficientemente bueno, y cuando no es conveniente invertir mas tiempo en él. Me gusta especialmente esta cita del usuario de reddit Broseidon241:\n\nHace mucho tiempo en clase de arte, mi profesor me dijo “Un artista necesita saber cuándo una pieza está terminada. No puedes retocar algo a la perfección - termínalo. Si no te gusta, hazlo otra vez. O sino empieza algo nuevo”. En años posteriores, yo escuché “Una pobre costurera comete muchos errores. Una buena costurera trabaja duro para corregir esos errores. Una grandiosa costurera no tiene miedo de tirar la prenda y empezar nuevamente”.\n\n– Broseidon241, https://www.reddit.com/r/datascience/comments/4irajq\n\n24.1.1 Prerrequisitos\nUsaremos las mismas herramientas que en el capítulo anterior, pero agregaremos algunos conjuntos de datos reales: diamantes y vuelos del paquete datos También necesitaremos lubridate para trabajar con fechas/horas en vuelos.\n\nlibrary(tidyverse)\nlibrary(modelr)\nlibrary(lubridate)\nlibrary(datos)\noptions(na.action = na.warn)"
  },
  {
    "objectID": "24-model-building.html#diamond-prices",
    "href": "24-model-building.html#diamond-prices",
    "title": "24  Construcción de modelos",
    "section": "24.2 ¿Por qué los diamantes de baja calidad son más caros?",
    "text": "24.2 ¿Por qué los diamantes de baja calidad son más caros?\nEn el capítulo anterior vimos una sorprendente relación entre la calidad de los diamantes y su precio: diamantes de baja calidad (cortes pobres, colores malos, y claridad inferior) tienen más altos precios.\n\nggplot(diamantes, aes(corte, precio)) + geom_boxplot()\nggplot(diamantes, aes(color, precio)) + geom_boxplot()\nggplot(diamantes, aes(claridad, precio)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTen en cuenta que el peor diamante es J (amarillo claro), y la peor claridad es I1 (inclusiones visibles a simple vista).\n\n24.2.1 Precio y quilates\nPareciera que los diamantes de menor calidad tiene precios más altos porque hay una importante variable de confusión: el peso (carat) del diamante. El peso del diamante es el factor individual más importante para determinar el precio del diamante, y los diamantes de menor calidad tienden a ser más grandes.\n\nggplot(diamantes, aes(quilate, precio)) + \n  geom_hex(bins = 50)\n\n\n\n\n\n\n\n\nPodemos hacer que sea más fácil ver cómo los otros atributos de un diamante afectan su precio relativo al ajustar un modelo para separar el efecto de quilates. Pero primero, hagamos algunos ajustes al conjunto de datos de diamantes para que sea más fácil trabajar con ellos:\n\nFoco en los diamantes más pequeños que 2.5 quilates (99.7% de los datos).\nHaz una transformación logarítmica de las variables quilates y precio\n\n\ndiamantes2 &lt;- diamantes %&gt;%\n  filter(quilate &lt;= 2.5) %&gt;% \n  mutate(log_precio = log2(precio), log_quilates = log2(quilate))\n\nJuntos, esos cambios hacen más fácil ver la relación entre quilates y precio:\n\nggplot(diamantes2, aes(log_quilates, log_precio)) + \n  geom_hex(bins = 50)\n\n\n\n\n\n\n\n\nLa transformación logarítmica es particularmente util aquí porque hace que el patrón sea lineal, y patrones lineales son más fáciles de usar. Tomemos el próximo paso y eliminemos ese patron lineal fuerte. Primero hacemos explícito el patrón ajustando el modelo:\n\nmod_diamantes &lt;- lm(log_precio ~ log_quilates, data = diamantes2)\n\nLuego observamos lo que el modelo nos dice. Ten en cuenta que vuelvo atrás la transformación de la predicción, deshaciendo la transformación logarítmica, para poder superponer las predicciones sobre los datos originales:\n\ncuadricula &lt;- diamantes2 %&gt;% \n  data_grid(quilate = seq_range(quilate, 20)) %&gt;% \n  mutate(log_quilates = log2(quilate)) %&gt;% \n  add_predictions(mod_diamantes, \"log_precio\") %&gt;% \n  mutate(precio = 2 ^ log_precio)\n\nggplot(diamantes2, aes(quilate, precio)) + \n  geom_hex(bins = 50) + \n  geom_line(data = cuadricula, colour = \"red\", size = 1)\n#&gt; Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#&gt; ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nEso nos dice algo interesante acerca de nuestros datos. Si creemos en nuestro modelo, los diamantes grandes son mucho más baratos que lo esperado. Esto es posiblemente porque ninguno de los diamantes de estos datos cuesta más de US$19,000.\nAhora podemos ver los residuos, lo cual comprueba que hemos eliminado el patrón lineal fuerte:\n\ndiamantes2 &lt;- diamantes2 %&gt;% \n  add_residuals(mod_diamantes, \"lresid\")\n\nggplot(diamantes2, aes(log_quilates, lresid)) + \n  geom_hex(bins = 50)\n\n\n\n\n\n\n\n\nEs importante destacar que ahora podemos volver a hacer nuestros gráficos motivadores utilizando esos residuos en lugar de precio.\n\nggplot(diamantes2, aes(corte, lresid)) + geom_boxplot()\nggplot(diamantes2, aes(color, lresid)) + geom_boxplot()\nggplot(diamantes2, aes(claridad, lresid)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAhora vemos la relación que esperábamos: a medida que aumenta la calidad del diamante, también lo hace su precio relativo. Para interpretar el eje y, necesitamos pensar que nos dicen los residuos, y en que escala están. Un residuo de -1 indica que log_precio era 1 unidad más baja que la predicción basada únicamente en su peso. \\(2^{-1}\\) es 1/2, los puntos con un valor de -1 son la mitad del precio esperado, y los residuos con el valor 1 son el doble del precio predicho.\n\n\n24.2.2 Un modelo más complicado\nSi quisiéramos, podríamos continuar construyendo nuestro modelo, traspasando los resultados que hemos observado en el modelo para hacerlos explícitos. Por ejemplo, podríamos incluir color, corte, y claridad en el modelo para que también hagamos explícito el efecto de esas tres variables categóricas:\n\nmod_diamantes2 &lt;- lm(log_precio ~ log_quilates + color + corte + claridad, data = diamantes2)\n\nEste modelo ahora incluye cuatro predictores, por lo que es más difícil de visualizar. Afortunadamente, todos ellos son actualmente independientes lo que significa que podemos graficarlos individualmente en cuatro gráficos. Para hacer el proceso más fácil, vamos a usar el argumento .model en data_grid:\n\ncuadricula &lt;- diamantes2 %&gt;% \n  data_grid(corte, .model = mod_diamantes2) %&gt;% \n  add_predictions(mod_diamantes2)\ncuadricula\n#&gt; # A tibble: 5 × 5\n#&gt;   corte     log_quilates color claridad  pred\n#&gt;   &lt;ord&gt;            &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;\n#&gt; 1 Regular         -0.515 G     VS2       11.2\n#&gt; 2 Bueno           -0.515 G     VS2       11.3\n#&gt; 3 Muy bueno       -0.515 G     VS2       11.4\n#&gt; 4 Premium         -0.515 G     VS2       11.4\n#&gt; 5 Ideal           -0.515 G     VS2       11.4\n\nggplot(cuadricula, aes(corte, pred)) + \n  geom_point()\n\n\n\n\n\n\n\n\nSi el modelo necesita variables que no has suministrado, data_grid() automáticamente los rellenará con el valor “typical”. Para variables continuas, se usa la mediana, y para variables categóricas se usa el valor más frecuente (o valores, si hay un empate).\n\ndiamantes2 &lt;- diamantes2 %&gt;% \n  add_residuals(mod_diamantes2, \"lresid2\")\n\nggplot(diamantes2, aes(log_quilates, lresid2)) + \n  geom_hex(bins = 50)\n\n\n\n\n\n\n\n\nEste gráfico indica que hay algunos diamantes con residuos bastante grandes - recuerda que un residuo de 2 indica que el diamante es 4x el precio que esperábamos. A menudo es útil mirar los valores inusuales individualmente:\n\ndiamantes2 %&gt;% \n  filter(abs(lresid2) &gt; 1) %&gt;% \n  add_predictions(mod_diamantes2) %&gt;% \n  mutate(pred = round(2 ^ pred)) %&gt;% \n  select(precio, pred, quilate:tabla, x:z) %&gt;% \n  arrange(precio)\n#&gt; # A tibble: 16 × 11\n#&gt;   precio  pred quilate corte  color claridad profundidad tabla     x     y     z\n#&gt;    &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;ord&gt;  &lt;ord&gt; &lt;ord&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1   1013   264    0.25 Regul… F     SI2             54.4    64  4.3   4.23  2.32\n#&gt; 2   1186   284    0.25 Premi… G     SI2             59      60  5.33  5.28  3.12\n#&gt; 3   1186   284    0.25 Premi… G     SI2             58.8    60  5.33  5.28  3.12\n#&gt; 4   1262  2644    1.03 Regul… E     I1              78.2    54  5.72  5.59  4.42\n#&gt; 5   1415   639    0.35 Regul… G     VS2             65.9    54  5.57  5.53  3.66\n#&gt; 6   1415   639    0.35 Regul… G     VS2             65.9    54  5.57  5.53  3.66\n#&gt; # ℹ 10 more rows\n\nHasta aquí nada realmente interesante, pero probablemente valga la pena pasar tiempo considerando si esto significa un problema con nuestro modelo, o si hay errores en los datos. Si hay errores en los datos, esta podría ser una oportunidad para comprar diamantes que fueron incorrectamente tasados con valor bajo.\n\n\n24.2.3 Ejercicios\n\nEn el gráfico de log_quilates vs. log_precio, hay unas tiras verticales brillantes. ¿Qué representan?\nSi log(precio) = a_0 + a_1 * log(quilates), ¿Qué dice eso acerca\nla relación entre precio y quilates?\nExtrae los diamantes que tienen residuos muy altos y muy bajos. ¿Hay algo inusual en estos diamantes? ¿Son particularmente malos o buenos?, o ¿Crees que estos son errores de precio?\n¿El modelo final, mod_diamantes2, hace un buen trabajo al predecir el precios de los diamantes? ¿Confiarías en lo que te indique gastar si fueras a comprar un diamante?"
  },
  {
    "objectID": "24-model-building.html#qué-afecta-el-número-de-vuelos-diarios",
    "href": "24-model-building.html#qué-afecta-el-número-de-vuelos-diarios",
    "title": "24  Construcción de modelos",
    "section": "24.3 ¿Qué afecta el número de vuelos diarios?",
    "text": "24.3 ¿Qué afecta el número de vuelos diarios?\nTrabajaremos a través de un proceso similar para un conjunto de datos que parece aún más simple a primera vista: el número de vuelos que salen de NYC por día. Este es un conjunto realmente pequeño de datos — solo 365 filas y 2 columnas — y no vamos a terminar con un modelo completamente realizado, pero como veras, los pasos en el camino nos ayudarán a entender mejor los datos. Comenzaremos contando el número de vuelos por día y visualizándolos con ggplot2.\n\nvuelos_por_dia &lt;- vuelos %&gt;% \n  mutate(fecha = make_date(anio, mes, dia)) %&gt;% \n  group_by(fecha) %&gt;% \n  summarise(n = n())\nvuelos_por_dia\n#&gt; # A tibble: 365 × 2\n#&gt;   fecha          n\n#&gt;   &lt;date&gt;     &lt;int&gt;\n#&gt; 1 2013-01-01   842\n#&gt; 2 2013-01-02   943\n#&gt; 3 2013-01-03   914\n#&gt; 4 2013-01-04   915\n#&gt; 5 2013-01-05   720\n#&gt; 6 2013-01-06   832\n#&gt; # ℹ 359 more rows\n\nggplot(vuelos_por_dia, aes(fecha, n)) + \n  geom_line()\n\n\n\n\n\n\n\n\n\n24.3.1 Día de la semana\nComprender la tendencia a largo plazo es un desafío porque hay un fuerte efecto de día de la semana que domina a los patrones más sutiles. Comenzaremos mirando la distribución de número de vuelos por día de la semana:\n\nvuelos_por_dia &lt;- vuelos_por_dia %&gt;% \n  mutate(dia_semana = wday(fecha, label = TRUE))\nggplot(vuelos_por_dia, aes(dia_semana, n)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\nHay pocos vuelos los fines de semana porque la mayoría de los viajes son por negocios. El efecto es particularmente pronunciado el sábado: alguna vez podrías salir un domingo para ir a una reunión un lunes por la mañana, pero es menos común que salgas un sábado ya que preferirías estar en casa con tu familia.\nUna forma de eliminar este fuerte patrón es usar un modelo. Primero, ajustamos el modelo, y mostraremos sus predicciones superpuestas sobre los datos originales:\n\nmod &lt;- lm(n ~ dia_semana, data = vuelos_por_dia)\n\ncuadricula &lt;- vuelos_por_dia %&gt;% \n  data_grid(dia_semana) %&gt;% \n  add_predictions(mod, \"n\")\n\nggplot(vuelos_por_dia, aes(dia_semana, n)) + \n  geom_boxplot() +\n  geom_point(data = cuadricula, colour = \"red\", size = 4)\n\n\n\n\n\n\n\n\nA continuación calculamos y visualizamos los residuos:\n\nvuelos_por_dia &lt;- vuelos_por_dia %&gt;% \n  add_residuals(mod)\nvuelos_por_dia %&gt;% \n  ggplot(aes(fecha, resid)) + \n  geom_ref_line(h = 0) + \n  geom_line()\n\n\n\n\n\n\n\n\nNotar el cambio en el eje Y: ahora estamos viendo el desvío desde el número de vuelos esperados, dado el día de la semana. Este gráfico es útil porque ahora que removimos la mayor parte del efecto día de la semana, podemos ver algo de los patrones más sutiles que quedan:\n\nNuestro modelo parece fallar a partir de junio: todavía se puede ver un patrón regular fuerte que nuestro modelo no ha capturado. Dibujando un diagrama con una línea para cada día de la semana se hace más facil de ver la causa:\n\nggplot(vuelos_por_dia, aes(fecha, resid, colour = dia_semana)) + \n  geom_ref_line(h = 0) + \n  geom_line()\n\n\n\n\n\n\n\n\nNuestro modelo falla en predecir con precisión el número de vuelos los sábados: durante el verano hay más vuelos de los que esperamos, y durante el otoño hay menos. Veremos como podemos capturar mejor este patrón en la siguiente sección.\nHay algunos días con mucho menos vuelos que los esperados:\n\nvuelos_por_dia %&gt;% \n  filter(resid &lt; -100)\n#&gt; # A tibble: 11 × 4\n#&gt;   fecha          n dia_semana resid\n#&gt;   &lt;date&gt;     &lt;int&gt; &lt;ord&gt;      &lt;dbl&gt;\n#&gt; 1 2013-01-01   842 Tue        -109.\n#&gt; 2 2013-01-20   786 Sun        -105.\n#&gt; 3 2013-05-26   729 Sun        -162.\n#&gt; 4 2013-07-04   737 Thu        -229.\n#&gt; 5 2013-07-05   822 Fri        -145.\n#&gt; 6 2013-09-01   718 Sun        -173.\n#&gt; # ℹ 5 more rows\n\nSi estás familiarizado con los feriados públicos de Estados Unidos, podrías reconocer los días de Año Nuevo, el 4 de julio, el día de Acción de Gracias y Navidad. Hay algunos otros que parecen no corresponder a feriados públicos. Trabajarás sobre esos días en uno de los ejercicios.\nParece que hay una tendencia más suave a largo plazo en el transcurso del año. Podemos destacar esa tendencia con geom_smooth():\n\nvuelos_por_dia %&gt;% \n  ggplot(aes(fecha, resid)) + \n  geom_ref_line(h = 0) + \n  geom_line(colour = \"grey50\") + \n  geom_smooth(se = FALSE, span = 0.20)\n#&gt; `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\nHay menos vuelos en enero (y diciembre), y más en verano (May-Sep). No podemos hacer mucho cuantitativamente con este patrón, porque\nsólo tenemos un año de datos. Pero podemos usar nuestro conocimiento para pensar en posibles explicaciones.\n\n\n\n24.3.2 Efecto estacional del sábado\nPrimero abordaremos nuestra falla para predecir con exactitud el número de vuelos el sábado. Un buen lugar para empezar es volver a los números originales, enfocándonos en el sábado:\n\nvuelos_por_dia %&gt;% \n  filter(dia_semana == \"Sat\") %&gt;% \n  ggplot(aes(fecha, n)) + \n    geom_point() + \n    geom_line() +\n    scale_x_date(NULL, date_breaks = \"1 month\", date_labels = \"%b\")\n\n\n\n\n\n\n\n\n(He usado tanto puntos como líneas para dejar más claro que son los datos y qué es la interpolación).\nSospecho que este patrón es causado por las vacaciones de invierno: mucha gente va de vacaciones en verano, y a las personas no les importa viajar un sábado en sus vacaciones. Al mirar este gráfico, podemos suponer que las vacaciones de verano son de principio de junio a finales de agosto. Parece que se alinea bastante bien con el calendario escolar del estado de NY: las vacaciones de verano en 2013 fueron del 26 de junio hasta el 9 de septiembre.\n¿Por qué hay más vuelos los sábados en primavera que en otoño? Le pregunté a algunos amigos estadounidenses y ellos me dijeron que es menos común planificar vacaciones familiares durante el otoño porque debido a los grandes feriados de Acción de Gracias y Navidad. No tenemos los datos para estar seguros, pero parecería una hipótesis de trabajo razonable.\nVamos a crear la variable “trimestre” que capture aproximadamente los tres períodos escolares, y verificamos nuestro trabajo con un gráfico:\n\ntrimestre &lt;- function(fecha) {\n  cut(fecha, \n    breaks = ymd(20130101, 20130605, 20130825, 20140101),\n    labels = c(\"primavera\", \"verano\", \"otoño\")\n  )\n}\n\nvuelos_por_dia &lt;- vuelos_por_dia %&gt;% \n  mutate(trimestre = trimestre(fecha)) \n\nvuelos_por_dia %&gt;% \n  filter(dia_semana == \"Sat\") %&gt;% \n  ggplot(aes(fecha, n, colour = trimestre)) +\n  geom_point(alpha = 1/3) + \n  geom_line() +\n  scale_x_date(NULL, date_breaks = \"1 month\", date_labels = \"%b\")\n\n\n\n\n\n\n\n\n(Modifiqué manualmente las fechas para obtener mejores cortes en el gráfico. Una técnica general y realmente poderosa es usar una visualización para ayudarte a entender lo que tu función está haciendo).\nEs útil ver como esta nueva variable afecta los otros días de la semana:\n\nvuelos_por_dia %&gt;% \n  ggplot(aes(dia_semana, n, colour = trimestre)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\nParece que hay una variación significativa entre los periodos, por lo que es razonable ajustar el efecto de los días de la semana por separado para cada período. Esto mejora nuestro modelo, pero no tanto como podríamos esperar:\n\nmod1 &lt;- lm(n ~ dia_semana, data = vuelos_por_dia)\nmod2 &lt;- lm(n ~ dia_semana * trimestre, data = vuelos_por_dia)\n\nvuelos_por_dia %&gt;% \n  gather_residuals(sin_trimestre = mod1, con_trimestre = mod2) %&gt;% \n  ggplot(aes(fecha, resid, colour = model)) +\n    geom_line(alpha = 0.75)\n\n\n\n\n\n\n\n\nPodemos ver el problema al superponer las predicciones del modelo a los datos crudos:\n\ncuadricula &lt;- vuelos_por_dia %&gt;% \n  data_grid(dia_semana, trimestre) %&gt;% \n  add_predictions(mod2, \"n\")\n\nggplot(vuelos_por_dia, aes(dia_semana, n)) +\n  geom_boxplot() + \n  geom_point(data = cuadricula, colour = \"red\") + \n  facet_wrap(~ trimestre)\n\n\n\n\n\n\n\n\nNuestro modelo esta encontrando el efecto mean , pero tenemos muchos valores atípicos grandes, por lo tanto la media tiende a estar lejos de los valores atípicos. Podemos aliviar este problema usando un modelo que es más robusto a los efectos de los valores atípicos: MASS::rlm(). Esto reduce en gran medida el impacto de los valores atípicos en nuestras estimaciones, y proporciona un modelo que hace un buen trabajo eliminando el patrón del día de la semana:\n\nmod3 &lt;- MASS::rlm(n ~ dia_semana * trimestre, data = vuelos_por_dia)\n\nvuelos_por_dia %&gt;% \n  add_residuals(mod3, \"resid\") %&gt;% \n  ggplot(aes(fecha, resid)) + \n  geom_hline(yintercept = 0, size = 2, colour = \"white\") + \n  geom_line()\n\n\n\n\n\n\n\n\nAhora es mucho más fácil ver la tendencia a largo plazo, los positivos y negativos valores atípicos.\n\n\n24.3.3 Variables calculadas\nSi estas experimentando con muchos modelos y muchas visualizaciones, es una buena idea agrupar la creación de variables en una función para que no haya posibilidad de aplicar accidentalmente transformaciones a diferentes lugares. Por ejemplo, podríamos escribir:\n\ncompute_vars &lt;- function(data) {\n  data %&gt;% \n    mutate(\n      trimestre = trimestre(date), \n      dia_semana = wday(date, label = TRUE)\n    )\n}\n\nOtra opción es colocar las transformaciones directamente en la fórmula del modelo:\n\ndia_semana2 &lt;- function(x) wday(x, label = TRUE)\nmod3 &lt;- lm(n ~ dia_semana2(fecha) * trimestre(fecha), data = vuelos_por_dia)\n\nCualquiera de los enfoques es razonable. Hacer que una variable transformada sea explicita es útil si quieres verificar tu trabajo, o usarlas en una visualización. Pero no puedes usar fácilmente transformaciones (como splines) que devuelven múltiples columnas. Incluir las transformaciones en el modelo hace la vida más fácil cuando se trabaja con diferentes conjuntos de datos porque el modelo es autónomo.\n\n\n24.3.4 Época del año: un enfoque alternativo\nEn la sección anterior usamos nuestro conocimiento (como el calendario escolar de Estados Unidos afecta el viaje) para mejorar el modelo. Una alternativa es utilizar nuestro conocimiento explícito en el modelo para darle a los datos más espacio para hablar. Podríamos utilizar un modelo más flexible y permitir que capture el patrón que nos interesa. Una tendencia lineal simple no es adecuada, por lo que podríamos intentar usar una spline natural para ajustarnos a una curva suave durante el año:\n\nlibrary(splines)\nmod &lt;- MASS::rlm(n ~ dia_semana * ns(fecha, 5), data = vuelos_por_dia)\n\nvuelos_por_dia %&gt;% \n  data_grid(dia_semana, fecha = seq_range(fecha, n = 13)) %&gt;% \n  add_predictions(mod) %&gt;% \n  ggplot(aes(fecha, pred, colour = dia_semana)) + \n    geom_line() +\n    geom_point()\n\n\n\n\n\n\n\n\nVemos un patrón fuerte en el número de vuelos de los sábados. Esto es tranquilizador, porque también vimos ese patrón en los datos sin transformar. Es una buena señal cuando obtienes la misma señal desde diferentes enfoques.\n\n\n24.3.5 Ejercicios\n\nUsa tus habilidades detestivescas con los buscadores para intercambiar ideas sobre por qué hubo menos vuelos esperados el 20 de enero, 26 de mayo y 1 de septiembre. (Pista: todos tienen la misma explicación.) ¿Cómo generalizarías esos días a otros años?\n¿Qué representan esos tres días con altos residuos positivos? ¿Cómo se generalizarían esos días a otros años?\n\nvuelos_por_dia %&gt;% \n  slice_max(n = 3, resid)\n#&gt; # A tibble: 3 × 5\n#&gt;   fecha          n dia_semana resid trimestre\n#&gt;   &lt;date&gt;     &lt;int&gt; &lt;ord&gt;      &lt;dbl&gt; &lt;fct&gt;    \n#&gt; 1 2013-11-30   857 Sat        112.  otoño    \n#&gt; 2 2013-12-01   987 Sun         95.5 otoño    \n#&gt; 3 2013-12-28   814 Sat         69.4 otoño\n\nCrea una nueva variable que divida la variable dia_semana en periodos, pero sólo para sábados, es decir, debería tener Thu, Fri, y Sat-verano, Sat-primavera, Sat-otonio. ¿Cómo este modelo se compara con el modelo que tiene la combinación de dia_semana y trimestre?\nCrea una nueva variable dia_semana que combina el día de la semana, periodos (para sábados), y feriados públicos. ¿Cómo se ven los residuos de este modelo?\n¿Qué sucede si ajustas un efecto de día de la semana que varía según el mes o varía mes a mes (es decir, n ~ dia_semana * month)? ¿Por qué esto no es muy útil?\n¿Que esperarías del modelo n ~ dia_semana + ns(fecha, 5)? Sabiendo lo que sabes sobre los datos, ¿porqué esperarias que no sea particularmente efectivo?\nPresumimos que las personas que salen los domingos son probablemente viajeros de negocios quienes necesitan estar en algun lugar el lunes. Explora esa hipótesis al ver cómo se descompone en función de la distancia y tiempo: si es verdad, esperarías ver más vuelos en la tarde del domingo a lugares que estan muy lejos.\nEs un poco frustante que el domingo y sábado esté en los extremos opuestos del gráfico. Escribe una pequeña función para establecer los niveles del factor para que la semana comience el lunes."
  },
  {
    "objectID": "24-model-building.html#aprende-más-sobre-los-modelos",
    "href": "24-model-building.html#aprende-más-sobre-los-modelos",
    "title": "24  Construcción de modelos",
    "section": "24.4 Aprende más sobre los modelos",
    "text": "24.4 Aprende más sobre los modelos\nSolo hemos dado una pincelada sobre el tema de modelos, pero es de esperar que hayas adquirido algunas herramientas simples, pero de uso general que puedes usar para mejorar tus propios análisis. ¡Está bien empezar de manera simple! Como has visto, incluso modelos muy simples pueden significar una gran diferencia en tu habilidad para desentrañar las interacciones o pueden generar un incremento dramático en tu habilidad para desentrañar las interacciones.\nEstos capítulos de modelos son aún más dogmáticos que el resto del libro. Yo enfoco el modelamiento desde una perspectiva diferente a la mayoría, y hay relativamente poco espacio dedicado a ello. El modelamiento realmente requiere un libro completo, así que recomiendo que leas alguno de estos 3 libros:\n\nStatistical Modeling: A Fresh Approach by Danny Kaplan, http://project-mosaic-books.com/?page_id=13. Este libro provee una introducción suave al modelado, donde desarrollas tu intuición, herramientas matemáticas, y habilidades de R en paralelo. El libro reemplaza al curso tradicional de “Introducción a la Estadística”, proporcionando un plan de estudios actualizado y relevante para ciencia de datos.\nAn Introduction to Statistical Learning by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani, http://www-bcf.usc.edu/~gareth/ISL/ (Disponible en línea gratis). Este libro presenta una moderna familia de técnicas de modelamiento colectivamente conocidas como aprendizaje estadístico. Para una más profunda comprensión de la matemática detrás de los modelos, lee el clásico Elements of Statistical Learning por Trevor Hastie, Robert Tibshirani, y Jerome Friedman, http://statweb.stanford.edu/~tibs/ElemStatLearn/ (También disponible en línea gratis).\nApplied Predictive Modeling por Max Kuhn and Kjell Johnson, http://appliedpredictivemodeling.com. Este libro es un compañero del paquete caret y provee herramientas prácticas para lidiar con desafíos de modelado predictivo."
  },
  {
    "objectID": "25-model-many.html#introducción",
    "href": "25-model-many.html#introducción",
    "title": "25  Muchos modelos",
    "section": "25.1 Introducción",
    "text": "25.1 Introducción\nEn este capítulo vas a aprender tres ideas poderosas que te van a ayudar a trabajar fácilmente con un gran número de modelos:\n\nUsar muchos modelos simples para entender mejor conjuntos de datos complejos.\nUsar columnas-lista (list-columns) para almacenar estructuras de datos arbitrarias en un data frame. Esto, por ejemplo, te permitirá tener una columna que contenga modelos lineales.\nUsar el paquete broom, de David Robinson, para transformar modelos en datos ordenados. Esta es una técnica poderosa para trabajar con un gran número de modelos porque una vez que tienes datos ordenados, puedes aplicar todas las técnicas que has aprendido anteriormente en el libro.\n\nEmpezaremos entrando de lleno en un ejemplo motivador usando datos sobre la esperanza de vida alrededor del mundo. Es un conjunto de datos pequeño pero que ilustra cuán importante puede ser modelar para mejorar tus visualizaciones. Utilizaremos un número grande de modelos simples para separar algunas de las señales más fuertes y así poder ver las señales sutiles que permanecen. También veremos cómo las medidas de resumen de los modelos nos pueden ayudar a encontrar datos atípicos y tendencias inusuales.\nLas siguientes secciones ahondarán en más detalles acerca de cada una de estas técnicas:\n\nEn columnas-lista aprenderás más acerca de la estructura de datos columna-lista y por qué es válido poner listas en data frames.\nEn creando columnas-lista aprenderás las tres maneras principales en las que crearás columnas-lista.\nEn simplificando columnas-lista aprenderás cómo convertir columnas-lista de vuelta a vectores atómicos regulares (o conjuntos de vectores atómicos) para que puedas trabajar con ellos más fácilmente.\nEn haciendo datos ordenados con broom aprenderás sobre el conjunto de herramientas completo provisto por broom (escoba, en inglés) y verás cómo puede ser aplicado a otros tipos de estructuras de datos.\n\nEste capítulo es en cierta medida aspiracional: si este libro es tu primera introducción a R, este capítulo probablemente será un desafío. Requiere que tengas profundamente internalizadas ideas acerca de modelado, estructuras de datos e iteración. Así que no te preocupes si no lo entiendes — solo aparta este capítulo por un par de meses, y vuelve cuando quieras ejercitar tu cerebro.\n\n25.1.1 Prerrequisitos\nTrabajar con muchos modelos requiere muchos de los paquetes del tidyverse (para exploración de datos, manejo y programación) y modelr para facilitar el modelado.\n\nlibrary(modelr)\nlibrary(tidyverse)"
  },
  {
    "objectID": "25-model-many.html#gapminder",
    "href": "25-model-many.html#gapminder",
    "title": "25  Muchos modelos",
    "section": "25.2 gapminder",
    "text": "25.2 gapminder\nComo motivación para entender el poder de muchos modelos simples, vamos a mirar los datos de “gapminder”. Estos datos fueron popularizados por Hans Rosling, un doctor y estadístico sueco. Si nunca has escuchado de él, para de leer este capítulo ahora mismo y revisa algunos de sus videos! Es un fantástico presentador de datos e ilustra cómo puedes usar datos para presentar una historia convincente. Un buen lugar para empezar es este video corto filmado en conjunto con la BBC: https://www.youtube.com/watch?v=jbkSRLYSojo.\nLos datos de gapminder resumen la progresión de países a través del tiempo, mirando estadísticos como esperanza de vida y PIB. Los datos son de fácil acceso en R gracias a Jenny Bryan, quien creó el paquete gapminder. Utilizaremos la versión en español contenida en el paquete datos, que incorpora este dataset en el objeto paises.\n\nlibrary(datos)\npaises\n\n# A tibble: 1,704 × 6\n   pais       continente  anio esperanza_de_vida poblacion pib_per_capita\n   &lt;fct&gt;      &lt;fct&gt;      &lt;int&gt;             &lt;dbl&gt;     &lt;int&gt;          &lt;dbl&gt;\n 1 Afganistán Asia        1952              28.8   8425333           779.\n 2 Afganistán Asia        1957              30.3   9240934           821.\n 3 Afganistán Asia        1962              32.0  10267083           853.\n 4 Afganistán Asia        1967              34.0  11537966           836.\n 5 Afganistán Asia        1972              36.1  13079460           740.\n 6 Afganistán Asia        1977              38.4  14880372           786.\n 7 Afganistán Asia        1982              39.9  12881816           978.\n 8 Afganistán Asia        1987              40.8  13867957           852.\n 9 Afganistán Asia        1992              41.7  16317921           649.\n10 Afganistán Asia        1997              41.8  22227415           635.\n# ℹ 1,694 more rows\n\n\nEn este caso de estudio, nos enfocaremos solo en tres variables para responder la pregunta “¿Cómo la esperanza de vida (esperanza_de_vida) cambia a través del tiempo (anio) para cada país (pais)?”. Un buen lugar para empezar es con un gráfico:\n\npaises %&gt;%\n  ggplot(aes(anio, esperanza_de_vida, group = pais)) +\n  geom_line(alpha = 1 / 3)\n\n\n\n\nEs un conjunto de datos pequeño: solo tiene ~1,700 observaciones y 3 variables. ¡Pero aun así es difícil ver qué está pasando! En general, pareciera que la esperanza de vida ha estado mejorando en forma constante. Sin embargo, si miras de cerca, puedes notar que algunos países no siguen este patrón. ¿Cómo podemos hacer que esos países se vean más fácilmente?\nUna forma es usar el mismo enfoque que en el último capítulo: hay una señal fuerte (un crecimiento lineal general) que hace difícil ver tendencias más sutiles. Separaremos estos factores estimando un modelo con una tendencia lineal. El modelo captura el crecimiento estable en el tiempo y los residuos mostrarán lo que queda fuera.\nYa sabes cómo hacer eso si tenemos un solo país:\n\nnz &lt;- filter(paises, pais == \"Nueva Zelanda\")\nnz %&gt;%\n  ggplot(aes(anio, esperanza_de_vida)) +\n  geom_line() +\n  ggtitle(\"Datos completos = \")\n\n\n\nnz_mod &lt;- lm(esperanza_de_vida ~ anio, data = nz)\nnz %&gt;%\n  add_predictions(nz_mod) %&gt;%\n  ggplot(aes(anio, pred)) +\n  geom_line() +\n  ggtitle(\"Tendencia lineal + \")\n\n\n\nnz %&gt;%\n  add_residuals(nz_mod) %&gt;%\n  ggplot(aes(anio, resid)) +\n  geom_hline(yintercept = 0, colour = \"white\", size = 3) +\n  geom_line() +\n  ggtitle(\"Patrón restante\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n¿Cómo podemos ajustar fácilmente ese modelo para cada país?\n\n25.2.1 Datos anidados\nTe puedes imaginar copiando y pegando ese código múltiples veces; sin embargo, ¡ya has aprendido una mejor forma! Extrae el código en común con una función y repítelo usando una función map del paquete purrr. Este problema se estructura un poco diferente respecto a lo que has visto antes. En lugar de repetir una acción por cada variable, bnhgqueremos repetirla para cada país, es decir, un subconjunto de filas. Para hacer esto, necesitamos una nueva estructura de datos: el data frame anidado (nested data frame). Para crear un data frame anidado empezamos con un data frame agrupado, y lo “anidamos”:\n\npor_pais &lt;- paises %&gt;%\n  group_by(pais, continente) %&gt;%\n  nest()\n\npor_pais\n\n# A tibble: 142 × 3\n# Groups:   pais, continente [142]\n   pais       continente data             \n   &lt;fct&gt;      &lt;fct&gt;      &lt;list&gt;           \n 1 Afganistán Asia       &lt;tibble [12 × 4]&gt;\n 2 Albania    Europa     &lt;tibble [12 × 4]&gt;\n 3 Argelia    África     &lt;tibble [12 × 4]&gt;\n 4 Angola     África     &lt;tibble [12 × 4]&gt;\n 5 Argentina  Américas   &lt;tibble [12 × 4]&gt;\n 6 Australia  Oceanía    &lt;tibble [12 × 4]&gt;\n 7 Austria    Europa     &lt;tibble [12 × 4]&gt;\n 8 Baréin     Asia       &lt;tibble [12 × 4]&gt;\n 9 Bangladesh Asia       &lt;tibble [12 × 4]&gt;\n10 Bélgica    Europa     &lt;tibble [12 × 4]&gt;\n# ℹ 132 more rows\n\n\n(Estamos haciendo un poco de trampa agrupando por continente y pais al mismo tiempo. Dado el pais, continente es fijo, así que no agrega ningún grupo más, pero es una forma fácil de llevarnos una variable adicional para el camino.)\nEsto crea un data frame que tiene una fila por grupo (por país), y una columna bastante inusual: data. data es una lista de data frames (o tibbles, para ser precisos). Esto parece una idea un poco loca: ¡tenemos un data frame con una columna que es una lista de otros data frames! Explicaré brevemente por qué pienso que es una buena idea.\nLa columna data es un poco difícil de examinar porque es una lista moderadamente complicada y todavía estamos trabajando para tener buenas herramientas para explorar estos objetos. Desafortunadamente, usar str() no es recomendable porque usualmente producirá un output (salida de código) muy extenso. Pero si extraes un solo elemento de la columna data verás que contiene todos los datos para ese país (en este caso, Afganistán).\n\npor_pais$data[[1]]\n\n# A tibble: 12 × 4\n    anio esperanza_de_vida poblacion pib_per_capita\n   &lt;int&gt;             &lt;dbl&gt;     &lt;int&gt;          &lt;dbl&gt;\n 1  1952              28.8   8425333           779.\n 2  1957              30.3   9240934           821.\n 3  1962              32.0  10267083           853.\n 4  1967              34.0  11537966           836.\n 5  1972              36.1  13079460           740.\n 6  1977              38.4  14880372           786.\n 7  1982              39.9  12881816           978.\n 8  1987              40.8  13867957           852.\n 9  1992              41.7  16317921           649.\n10  1997              41.8  22227415           635.\n11  2002              42.1  25268405           727.\n12  2007              43.8  31889923           975.\n\n\nNota la diferencia entre un data frame agrupado estándar y un data frame anidado: en un data frame agrupado cada fila es una observación; en un data frame anidado, cada fila es un grupo. Otra forma de pensar en un conjunto de datos anidado es que ahora tenemos una meta-observación: una fila que representa todo el transcurso de tiempo para un país, en lugar de solo un punto en el tiempo.\n\n\n25.2.2 Columnas-lista\nAhora que tenemos nuestro data frame anidado, estamos en una buena posición para ajustar algunos modelos. Tenemos una función para ajustar modelos:\n\nmodelo_pais &lt;- function(df) {\n  lm(esperanza_de_vida ~ anio, data = df)\n}\n\nY queremos aplicarlo a cada data frame. Los data frames están en una lista, así que podemos usar purrr::map() para aplicar modelo_pais a cada elemento:\n\nmodelos &lt;- map(por_pais$data, modelo_pais)\n\nSin embargo, en lugar de dejar la lista de modelos como un objeto suelto, lo mejor sería almacenarlo como una columna en el data frame por_pais. Almacenar objetos relacionados en columnas es una parte clave del valor de los data frames, y por eso creemos que las columnas-lista son tan buena idea. En el transcurso de nuestro trabajo con estos países vamos a tener muchas listas en las que tenemos un elemento por país. ¿Por qué no almacenarlos todos juntos en un data frame?\nEn otras palabras, en lugar de crear un nuevo objeto en el entorno global, vamos a crear una nueva variable en el data frame por_pais. Ese es un trabajo para dplyr::mutate():\n\npor_pais &lt;- por_pais %&gt;%\n  mutate(modelo = map(data, modelo_pais))\npor_pais\n\n# A tibble: 142 × 4\n# Groups:   pais, continente [142]\n   pais       continente data              modelo\n   &lt;fct&gt;      &lt;fct&gt;      &lt;list&gt;            &lt;list&gt;\n 1 Afganistán Asia       &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 2 Albania    Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 3 Argelia    África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 4 Angola     África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 5 Argentina  Américas   &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 6 Australia  Oceanía    &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 7 Austria    Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 8 Baréin     Asia       &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 9 Bangladesh Asia       &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n10 Bélgica    Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n# ℹ 132 more rows\n\n\nEsto tiene una gran ventaja: como todos los objetos relacionados están almacenados juntos, no necesitas manualmente mantenerlos sincronizados cuando filtras o reordenas. La semántica del data frame se ocupa de esto por ti:\n\npor_pais %&gt;%\n  filter(continente == \"Europa\")\n\n# A tibble: 30 × 4\n# Groups:   pais, continente [30]\n   pais                 continente data              modelo\n   &lt;fct&gt;                &lt;fct&gt;      &lt;list&gt;            &lt;list&gt;\n 1 Albania              Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 2 Austria              Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 3 Bélgica              Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 4 Bosnia y Herzegovina Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 5 Bulgaria             Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 6 Croacia              Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 7 República Checa      Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 8 Dinamarca            Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 9 Finlandia            Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n10 Francia              Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n# ℹ 20 more rows\n\npor_pais %&gt;%\n  arrange(continente, pais)\n\n# A tibble: 142 × 4\n# Groups:   pais, continente [142]\n   pais                     continente data              modelo\n   &lt;fct&gt;                    &lt;fct&gt;      &lt;list&gt;            &lt;list&gt;\n 1 Argelia                  África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 2 Angola                   África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 3 Benin                    África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 4 Botswana                 África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 5 Burkina Faso             África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 6 Burundi                  África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 7 Camerún                  África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 8 República Centroafricana África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n 9 Chad                     África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n10 Comoras                  África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;  \n# ℹ 132 more rows\n\n\nSi tu lista de data frames y lista de modelos fueran objetos separados, tendrías que acordarte de que cuando reordenas o seleccionas un subconjunto de un vector, necesitas reordenar o seleccionar el subconjunto de todos los demás para mantenerlos sincronizados. Si te olvidas, tu código va a seguir funcionando, ¡pero va a devolver la respuesta equivocada!\n\n\n25.2.3 Desanidando\nPreviamente calculamos los residuos de un único modelo con un conjunto de datos también único. Ahora tenemos 142 data frames y 142 modelos. Para calcular los residuos, necesitamos llamar a la función add_residuals() (adicionar residuos, en inglés) con cada par modelo-datos:\n\npor_pais &lt;- por_pais %&gt;%\n  mutate(\n    residuos = map2(data, modelo, add_residuals)\n  )\npor_pais\n\n# A tibble: 142 × 5\n# Groups:   pais, continente [142]\n   pais       continente data              modelo residuos         \n   &lt;fct&gt;      &lt;fct&gt;      &lt;list&gt;            &lt;list&gt; &lt;list&gt;           \n 1 Afganistán Asia       &lt;tibble [12 × 4]&gt; &lt;lm&gt;   &lt;tibble [12 × 5]&gt;\n 2 Albania    Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;   &lt;tibble [12 × 5]&gt;\n 3 Argelia    África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;   &lt;tibble [12 × 5]&gt;\n 4 Angola     África     &lt;tibble [12 × 4]&gt; &lt;lm&gt;   &lt;tibble [12 × 5]&gt;\n 5 Argentina  Américas   &lt;tibble [12 × 4]&gt; &lt;lm&gt;   &lt;tibble [12 × 5]&gt;\n 6 Australia  Oceanía    &lt;tibble [12 × 4]&gt; &lt;lm&gt;   &lt;tibble [12 × 5]&gt;\n 7 Austria    Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;   &lt;tibble [12 × 5]&gt;\n 8 Baréin     Asia       &lt;tibble [12 × 4]&gt; &lt;lm&gt;   &lt;tibble [12 × 5]&gt;\n 9 Bangladesh Asia       &lt;tibble [12 × 4]&gt; &lt;lm&gt;   &lt;tibble [12 × 5]&gt;\n10 Bélgica    Europa     &lt;tibble [12 × 4]&gt; &lt;lm&gt;   &lt;tibble [12 × 5]&gt;\n# ℹ 132 more rows\n\n\n¿Pero cómo puedes graficar una lista de data frames? En lugar de luchar para contestar esa pregunta, transformemos la lista de data frames de vuelta en un data frame regular. Previamente usamos nest() (anidar) para transformar un data frame regular en uno anidado; ahora desanidaremos con unnest():\n\nresiduos &lt;- unnest(por_pais, residuos)\nresiduos\n\n# A tibble: 1,704 × 9\n# Groups:   pais, continente [142]\n   pais       continente data     modelo  anio esperanza_de_vida poblacion\n   &lt;fct&gt;      &lt;fct&gt;      &lt;list&gt;   &lt;list&gt; &lt;int&gt;             &lt;dbl&gt;     &lt;int&gt;\n 1 Afganistán Asia       &lt;tibble&gt; &lt;lm&gt;    1952              28.8   8425333\n 2 Afganistán Asia       &lt;tibble&gt; &lt;lm&gt;    1957              30.3   9240934\n 3 Afganistán Asia       &lt;tibble&gt; &lt;lm&gt;    1962              32.0  10267083\n 4 Afganistán Asia       &lt;tibble&gt; &lt;lm&gt;    1967              34.0  11537966\n 5 Afganistán Asia       &lt;tibble&gt; &lt;lm&gt;    1972              36.1  13079460\n 6 Afganistán Asia       &lt;tibble&gt; &lt;lm&gt;    1977              38.4  14880372\n 7 Afganistán Asia       &lt;tibble&gt; &lt;lm&gt;    1982              39.9  12881816\n 8 Afganistán Asia       &lt;tibble&gt; &lt;lm&gt;    1987              40.8  13867957\n 9 Afganistán Asia       &lt;tibble&gt; &lt;lm&gt;    1992              41.7  16317921\n10 Afganistán Asia       &lt;tibble&gt; &lt;lm&gt;    1997              41.8  22227415\n# ℹ 1,694 more rows\n# ℹ 2 more variables: pib_per_capita &lt;dbl&gt;, resid &lt;dbl&gt;\n\n\nNota que cada columna regular está repetida una vez por cada fila en la columna anidada.\nAhora que tenemos un data frame regular, podemos graficar los residuos:\n\nresiduos %&gt;%\n  ggplot(aes(anio, resid)) +\n  geom_line(aes(group = pais), alpha = 1 / 3) +\n  geom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nSeparar facetas por continente es particularmente revelador:\n\nresiduos %&gt;%\n  ggplot(aes(anio, resid, group = pais)) +\n  geom_line(alpha = 1 / 3) +\n  facet_wrap(~continente)\n\n\n\n\nParece que hemos perdido algunos patrones suaves. También hay algo interesante pasando en África: vemos algunos residuos muy grandes, lo que sugiere que nuestro modelo no está ajustando muy bien. Exploraremos más eso en la próxima sección, atacando el problema desde un ángulo un poco diferente.\n\n\n25.2.4 Calidad del modelo\nEn lugar de examinar los residuos del modelo, podríamos examinar algunas medidas generales de la calidad del modelo. Aprendiste cómo calcular algunas medidas específicas en el capítulo anterior. Aquí mostraremos un enfoque diferente usando el paquete broom. El paquete broom provee un conjunto de funciones generales para transformar modelos en datos ordenados. Aquí utilizaremos broom::glance() (vistazo, en inglés) para extraer algunas métricas de la calidad del modelo. Si lo aplicamos a un modelo, obtenemos un data frame con una única fila:\n\nbroom::glance(nz_mod)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic      p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.954         0.949 0.804      205. 0.0000000541     1  -13.3  32.6  34.1\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nPodemos usar mutate() y unnest() para crear un data frame con una fila por cada país:\n\nglance &lt;- por_pais %&gt;%\n  mutate(glance = map(modelo, broom::glance)) %&gt;%\n  select(-data, -modelo, -residuos) %&gt;% # remover las listas-columnas innecesarias\n  unnest(glance)\n\nglance\n\n# A tibble: 142 × 14\n# Groups:   pais, continente [142]\n   pais       continente r.squared adj.r.squared sigma statistic  p.value    df\n   &lt;fct&gt;      &lt;fct&gt;          &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1 Afganistán Asia           0.948         0.942 1.22      181.  9.84e- 8     1\n 2 Albania    Europa         0.911         0.902 1.98      102.  1.46e- 6     1\n 3 Argelia    África         0.985         0.984 1.32      662.  1.81e-10     1\n 4 Angola     África         0.888         0.877 1.41       79.1 4.59e- 6     1\n 5 Argentina  Américas       0.996         0.995 0.292    2246.  4.22e-13     1\n 6 Australia  Oceanía        0.980         0.978 0.621     481.  8.67e-10     1\n 7 Austria    Europa         0.992         0.991 0.407    1261.  7.44e-12     1\n 8 Baréin     Asia           0.967         0.963 1.64      291.  1.02e- 8     1\n 9 Bangladesh Asia           0.989         0.988 0.977     930.  3.37e-11     1\n10 Bélgica    Europa         0.995         0.994 0.293    1822.  1.20e-12     1\n# ℹ 132 more rows\n# ℹ 6 more variables: logLik &lt;dbl&gt;, AIC &lt;dbl&gt;, BIC &lt;dbl&gt;, deviance &lt;dbl&gt;,\n#   df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n(Presta atención a las variables que no se imprimieron: hay mucha información útil allí).\nCon este data frame podemos empezar a buscar modelos que no se ajustan bien:\n\nglance %&gt;%\n  arrange(r.squared)\n\n# A tibble: 142 × 14\n# Groups:   pais, continente [142]\n   pais  continente r.squared adj.r.squared sigma statistic p.value    df logLik\n   &lt;fct&gt; &lt;fct&gt;          &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Ruan… África        0.0172      -0.0811   6.56     0.175  0.685      1  -38.5\n 2 Bots… África        0.0340      -0.0626   6.11     0.352  0.566      1  -37.7\n 3 Zimb… África        0.0562      -0.0381   7.21     0.596  0.458      1  -39.6\n 4 Zamb… África        0.0598      -0.0342   4.53     0.636  0.444      1  -34.1\n 5 Swaz… África        0.0682      -0.0250   6.64     0.732  0.412      1  -38.7\n 6 Leso… África        0.0849      -0.00666  5.93     0.927  0.358      1  -37.3\n 7 Cost… África        0.283        0.212    3.93     3.95   0.0748     1  -32.3\n 8 Sudá… África        0.312        0.244    4.74     4.54   0.0588     1  -34.6\n 9 Ugan… África        0.342        0.276    3.19     5.20   0.0457     1  -29.8\n10 Repú… África        0.348        0.283    2.43     5.34   0.0434     1  -26.6\n# ℹ 132 more rows\n# ℹ 5 more variables: AIC &lt;dbl&gt;, BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, df.residual &lt;int&gt;,\n#   nobs &lt;int&gt;\n\n\nLos peores modelos parecieran estar todos en África. Vamos a chequear esto con un gráfico. Tenemos un número relativamente chico de observaciones y una variable discreta, así que usar geom_jitter() es efectivo:\n\nglance %&gt;%\n  ggplot(aes(continente, r.squared)) +\n  geom_jitter(width = 0.5)\n\n\n\n\nPodríamos quitar los países con un \\(R^2\\) particularmente malo y graficar los datos:\n\nmal_ajuste &lt;- filter(glance, r.squared &lt; 0.25)\n\npaises %&gt;%\n  semi_join(mal_ajuste, by = \"pais\") %&gt;%\n  ggplot(aes(anio, esperanza_de_vida, colour = pais)) +\n  geom_line()\n\n\n\n\nVemos dos efectos principales aquí: las tragedias de la epidemia de VIH/SIDA y el genocidio de Ruanda.\n\n\n25.2.5 Ejercicios\n\nUna tendencia lineal parece ser demasiado simple para la tendencia general. ¿Puedes hacerlo mejor con un polinomio cuadrático? ¿Cómo puedes interpretar el coeficiente del término cuadrático? (Pista: puedes querer transformar year para que tenga media cero.)\nExplora otros métodos para visualizar la distribución del \\(R^2\\) por continente. Puedes querer probar el paquete ggbeeswarm, que provee métodos similares para evitar superposiciones como jitter, pero usa métodos determinísticos.\nPara crear el último gráfico (mostrando los datos para los países con los peores ajustes del modelo), precisamos dos pasos: creamos un data frame con una fila por país y después hicimos un semi-join al conjunto de datos original. Es posible evitar este join si usamos unnest() en lugar de unnest(.drop = TRUE). ¿Cómo?"
  },
  {
    "objectID": "25-model-many.html#columnas-lista-1",
    "href": "25-model-many.html#columnas-lista-1",
    "title": "25  Muchos modelos",
    "section": "25.3 Columnas-lista",
    "text": "25.3 Columnas-lista\nAhora que has visto un flujo de trabajo básico para manejar muchos modelos, vamos a sumergirnos en algunos detalles. En esta sección, exploraremos en más detalle la estructura de datos columna-lista. Solo recientemente hemos comenzado a apreciar realmente la idea de la columna-lista. Esta estructura está implícita en la definición de data frame: un data frame es una lista nombrada de vectores de igual largo. Una lista es un vector, así que siempre ha sido legítimo usar una lista como una columna de un data frame. Sin embargo, R base no hace las cosas fáciles para crear columnas-lista, y data.frame() trata a la lista como una lista de columnas:\n\ndata.frame(x = list(1:3, 3:5))\n\n  x.1.3 x.3.5\n1     1     3\n2     2     4\n3     3     5\n\n\nPuedes prevenir que data.frame() haga esto con I(), pero el resultado no se imprime particularmente bien:\n\ndata.frame(\n  x = I(list(1:3, 3:5)),\n  y = c(\"1, 2\", \"3, 4, 5\")\n)\n\n        x       y\n1 1, 2, 3    1, 2\n2 3, 4, 5 3, 4, 5\n\n\nTibble mitiga este problema siendo más perezoso (tibble() no modifica sus inputs) y proporcionando un mejor método de impresión:\n\ntibble(\n  x = list(1:3, 3:5),\n  y = c(\"1, 2\", \"3, 4, 5\")\n)\n\n# A tibble: 2 × 2\n  x         y      \n  &lt;list&gt;    &lt;chr&gt;  \n1 &lt;int [3]&gt; 1, 2   \n2 &lt;int [3]&gt; 3, 4, 5\n\n\nEs incluso más fácil con tribble(), ya que automáticamente puede interpretar que necesitas una lista:\n\ntribble(\n  ~x, ~y,\n  1:3, \"1, 2\",\n  3:5, \"3, 4, 5\"\n)\n\n# A tibble: 2 × 2\n  x         y      \n  &lt;list&gt;    &lt;chr&gt;  \n1 &lt;int [3]&gt; 1, 2   \n2 &lt;int [3]&gt; 3, 4, 5\n\n\nLas columnas-lista son usualmente más útiles como estructuras de datos intermedias. Es difícil trabajar con ellas directamente, porque la mayoría de las funciones de R trabaja con vectores atómicos o data frames, pero la ventaja de mantener ítems relacionados juntos en un data frame hace que valga la pena un poco de molestia.\nGeneralmente hay tres partes en un pipeline efectivo de columnas-lista:\n\nCreas la columna-lista usando alguna de estas opciones: nest() o summarise() + list() o mutate() + una función map, como se describe en Creando columnas-lista.\nCreas otra columna-lista intermedia transformando columnas lista existentes con map(), map2() o pmap(). Por ejemplo, en el caso de estudio de arriba, creamos una columna-lista de modelos transformando una columna-lista de data frames.\nSimplificas la columna-lista de vuelta en un data frame o vector atómico, como se describe en Simplificando columnas-lista."
  },
  {
    "objectID": "25-model-many.html#creando-columnas-lista",
    "href": "25-model-many.html#creando-columnas-lista",
    "title": "25  Muchos modelos",
    "section": "25.4 Creando columnas-lista",
    "text": "25.4 Creando columnas-lista\nTípicamente, no tendrás que crear columnas-lista con tibble(), sino a partir de columnas regulares usando uno de estos tres métodos:\n\nCon tidyr::nest() para convertir un data frame agrupado en uno anidado en el que tengas columnas-lista de data frames.\nCon mutate() y funciones vectorizadas que retornan una lista.\nCon summarise() y funciones de resumen que retornan múltiples resultados.\n\nAlternativamente, podrías crearlas a partir de una lista nombrada, usando tibble::enframe().\nGeneralmente, cuando creas columnas-lista, debes asegurarte de que sean homogéneas: cada elemento debe contener el mismo tipo de cosa. No hay chequeos para asegurarte de que sea así, pero si usas purrr y recuerdas lo que aprendiste sobre funciones de tipo estable (type-stable functions), encontrarás que eso pasa naturalmente.\n\n25.4.1 Con anidación\nnest() crea un data frame anidado, que es un data frame con una columna-lista de data frames. En un data frame anidado cada fila es una meta-observación: las otras columnas son variables que definen la observación (como país y continente arriba), y la columna-lista de data frames tiene las observaciones individuales que construyen la meta-observación.\nHay dos formas de usar nest(). Hasta ahora has visto cómo usarlo con un data frame agrupado. Cuando se aplica a un data frame agrupado, nest() mantiene las columnas que agrupan tal cual, y envuelve todo lo demás en la columna-lista:\n\npaises %&gt;%\n  group_by(pais, continente) %&gt;%\n  nest()\n\n# A tibble: 142 × 3\n# Groups:   pais, continente [142]\n   pais       continente data             \n   &lt;fct&gt;      &lt;fct&gt;      &lt;list&gt;           \n 1 Afganistán Asia       &lt;tibble [12 × 4]&gt;\n 2 Albania    Europa     &lt;tibble [12 × 4]&gt;\n 3 Argelia    África     &lt;tibble [12 × 4]&gt;\n 4 Angola     África     &lt;tibble [12 × 4]&gt;\n 5 Argentina  Américas   &lt;tibble [12 × 4]&gt;\n 6 Australia  Oceanía    &lt;tibble [12 × 4]&gt;\n 7 Austria    Europa     &lt;tibble [12 × 4]&gt;\n 8 Baréin     Asia       &lt;tibble [12 × 4]&gt;\n 9 Bangladesh Asia       &lt;tibble [12 × 4]&gt;\n10 Bélgica    Europa     &lt;tibble [12 × 4]&gt;\n# ℹ 132 more rows\n\n\nTambién lo puedes usar en un data frame no agrupado, especificando cuáles columnas quieres anidar:\n\npaises %&gt;%\n  nest(data = anio:pib_per_capita)\n\n# A tibble: 142 × 3\n   pais       continente data             \n   &lt;fct&gt;      &lt;fct&gt;      &lt;list&gt;           \n 1 Afganistán Asia       &lt;tibble [12 × 4]&gt;\n 2 Albania    Europa     &lt;tibble [12 × 4]&gt;\n 3 Argelia    África     &lt;tibble [12 × 4]&gt;\n 4 Angola     África     &lt;tibble [12 × 4]&gt;\n 5 Argentina  Américas   &lt;tibble [12 × 4]&gt;\n 6 Australia  Oceanía    &lt;tibble [12 × 4]&gt;\n 7 Austria    Europa     &lt;tibble [12 × 4]&gt;\n 8 Baréin     Asia       &lt;tibble [12 × 4]&gt;\n 9 Bangladesh Asia       &lt;tibble [12 × 4]&gt;\n10 Bélgica    Europa     &lt;tibble [12 × 4]&gt;\n# ℹ 132 more rows\n\n\n\n\n25.4.2 A partir de funciones vectorizadas\nAlgunas funciones útiles toman un vector atómico y retornan una lista. Por ejemplo, en [cadenas de caracteres] aprendiste sobre stringr::str_split(), que toma un vector de caracteres y retorna una lista de vectores de caracteres. Si lo usas dentro de mutate, obtendrás una columna-lista:\n\ndf &lt;- tribble(\n  ~x1,\n  \"a,b,c\",\n  \"d,e,f,g\"\n)\n\ndf %&gt;%\n  mutate(x2 = stringr::str_split(x1, \",\"))\n\n# A tibble: 2 × 2\n  x1      x2       \n  &lt;chr&gt;   &lt;list&gt;   \n1 a,b,c   &lt;chr [3]&gt;\n2 d,e,f,g &lt;chr [4]&gt;\n\n\nunnest() sabe cómo manejar estas listas de vectores:\n\ndf %&gt;%\n  mutate(x2 = stringr::str_split(x1, \",\")) %&gt;%\n  unnest(x2)\n\n# A tibble: 7 × 2\n  x1      x2   \n  &lt;chr&gt;   &lt;chr&gt;\n1 a,b,c   a    \n2 a,b,c   b    \n3 a,b,c   c    \n4 d,e,f,g d    \n5 d,e,f,g e    \n6 d,e,f,g f    \n7 d,e,f,g g    \n\n\n(Si usas mucho este patrón, asegúrate de chequear tidyr::separate_rows(), que es un wrapper alrededor de este patrón común).\nOtro ejemplo de este patrón es usar map(), map2(), pmap() de purrr. Por ejemplo, podríamos tomar el ejemplo final de [Invocando distintas functions] y reescribirlo usando mutate():\n\nsim &lt;- tribble(\n  ~f, ~params,\n  \"runif\", list(min = -1, max = 1),\n  \"rnorm\", list(sd = 5),\n  \"rpois\", list(lambda = 10)\n)\n\nsim %&gt;%\n  mutate(sims = invoke_map(f, params, n = 10))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `sims = invoke_map(f, params, n = 10)`.\nCaused by warning:\n! `invoke_map()` was deprecated in purrr 1.0.0.\nℹ Please use map() + exec() instead.\n\n\n# A tibble: 3 × 3\n  f     params           sims      \n  &lt;chr&gt; &lt;list&gt;           &lt;list&gt;    \n1 runif &lt;named list [2]&gt; &lt;dbl [10]&gt;\n2 rnorm &lt;named list [1]&gt; &lt;dbl [10]&gt;\n3 rpois &lt;named list [1]&gt; &lt;int [10]&gt;\n\n\nNota que técnicamente sim no es homogéneo porque contiene tanto vectores de dobles como vectores de enteros. Sin embargo, es probable que esto no cause muchos problemas porque ambos vectores son numéricos.\n\n\n25.4.3 A partir de medidas de resumen con más de un valor\nUna restricción de summarise() es que solo funciona con funciones de resumen que retornan un único valor. Eso significa que no puedes usarlo con funciones como quantile(), que retorna un vector de largo arbitrario:\n\nmtautos %&gt;%\n  group_by(cilindros) %&gt;%\n  summarise(q = quantile(millas))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'cilindros'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 15 × 2\n# Groups:   cilindros [3]\n   cilindros     q\n       &lt;dbl&gt; &lt;dbl&gt;\n 1         4  21.4\n 2         4  22.8\n 3         4  26  \n 4         4  30.4\n 5         4  33.9\n 6         6  17.8\n 7         6  18.6\n 8         6  19.7\n 9         6  21  \n10         6  21.4\n11         8  10.4\n12         8  14.4\n13         8  15.2\n14         8  16.2\n15         8  19.2\n\n\nSin embargo, ¡puedes envolver el resultado en una lista! Esto obedece el contrato de summarise(), porque cada resumen ahora es una lista (un vector) de largo 1.\n\nmtautos %&gt;%\n  group_by(cilindros) %&gt;%\n  summarise(q = list(quantile(millas)))\n\n# A tibble: 3 × 2\n  cilindros q        \n      &lt;dbl&gt; &lt;list&gt;   \n1         4 &lt;dbl [5]&gt;\n2         6 &lt;dbl [5]&gt;\n3         8 &lt;dbl [5]&gt;\n\n\nPara producir resultados útiles con unnest, también necesitarás capturar las probabilidades:\n\nprobs &lt;- c(0.01, 0.25, 0.5, 0.75, 0.99)\nmtautos %&gt;%\n  group_by(cilindros) %&gt;%\n  summarise(p = list(probs), q = list(quantile(millas, probs))) %&gt;%\n  unnest(c(p, q))\n\n# A tibble: 15 × 3\n   cilindros     p     q\n       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1         4  0.01  21.4\n 2         4  0.25  22.8\n 3         4  0.5   26  \n 4         4  0.75  30.4\n 5         4  0.99  33.8\n 6         6  0.01  17.8\n 7         6  0.25  18.6\n 8         6  0.5   19.7\n 9         6  0.75  21  \n10         6  0.99  21.4\n11         8  0.01  10.4\n12         8  0.25  14.4\n13         8  0.5   15.2\n14         8  0.75  16.2\n15         8  0.99  19.1\n\n\n\n\n25.4.4 A partir de una lista nombrada\nLos data frames con columnas-lista proveen una solución a un problema común: ¿qué haces si quieres iterar sobre el contenido de una lista y también sobre sus elementos? En lugar de tratar de juntar todo en un único objeto, usualmente es más fácil hacer un data frame: una columna puede contener los elementos y otra columna la lista. Una forma fácil de crear un data frame como este desde una lista es tibble::enframe().\n\nx &lt;- list(\n  a = 1:5,\n  b = 3:4,\n  c = 5:6\n)\n\ndf &lt;- enframe(x)\ndf\n\n# A tibble: 3 × 2\n  name  value    \n  &lt;chr&gt; &lt;list&gt;   \n1 a     &lt;int [5]&gt;\n2 b     &lt;int [2]&gt;\n3 c     &lt;int [2]&gt;\n\n\nLa ventaja de esta estructura es que se generaliza de una forma relativamente sencilla - los nombres son útiles si tienes un vector de caracteres con los metadatos, pero no ayudan para otros tipos de datos o para múltiples vectores.\nAhora, si quieres iterar sobre los nombres y valores en paralelo, puedes usar map2():\n\ndf %&gt;%\n  mutate(\n    smry = map2_chr(name, value, ~ stringr::str_c(.x, \": \", .y[1]))\n  )\n\n# A tibble: 3 × 3\n  name  value     smry \n  &lt;chr&gt; &lt;list&gt;    &lt;chr&gt;\n1 a     &lt;int [5]&gt; a: 1 \n2 b     &lt;int [2]&gt; b: 3 \n3 c     &lt;int [2]&gt; c: 5 \n\n\n\n\n25.4.5 Ejercicios\n\nLista todas las funciones en las que puedas pensar que tomen como input un vector atómico y retornen una lista.\nPiensa en funciones de resumen útiles que, como quantile(), retornen múltiples valores.\n¿Qué es lo que falta en el siguiente data frame? ¿Cómo quantile() retorna eso que falta? ¿Por qué eso no es tan útil aquí?\n\n\nmtautos %&gt;%\n  group_by(cilindros) %&gt;%\n  summarise(q = list(quantile(millas))) %&gt;%\n  unnest(q)\n\n# A tibble: 15 × 2\n   cilindros     q\n       &lt;dbl&gt; &lt;dbl&gt;\n 1         4  21.4\n 2         4  22.8\n 3         4  26  \n 4         4  30.4\n 5         4  33.9\n 6         6  17.8\n 7         6  18.6\n 8         6  19.7\n 9         6  21  \n10         6  21.4\n11         8  10.4\n12         8  14.4\n13         8  15.2\n14         8  16.2\n15         8  19.2\n\n\n\n¿Qué hace este código? ¿Por qué podría ser útil?\n\n\nmtautos %&gt;%\n  group_by(cilindros) %&gt;%\n  summarise_each(funs(list))"
  },
  {
    "objectID": "25-model-many.html#simplificando-columnas-lista",
    "href": "25-model-many.html#simplificando-columnas-lista",
    "title": "25  Muchos modelos",
    "section": "25.5 Simplificando columnas-lista",
    "text": "25.5 Simplificando columnas-lista\nPara aplicar las técnicas de manipulación de datos y visualización que has aprendido en este libro, necesitarás simplificar la columna-lista de vuelta a una columna regular (un vector atómico) o conjunto de columnas. La técnica que usarás para volver a una estructura más sencilla depende de si quieres un único valor por elemento, o múltiples valores.\n\nSi quieres un único valor, usa mutate() con map_lgl(), map_int(), map_dbl(), y map_chr() para crear un vector atómico.\nSi quieres varios valores, usa unnest() para convertir columnas-lista de vuelta a columnas regulares, repitiendo las filas tantas veces como sea necesario.\n\nEstas técnicas están descritas con más detalle abajo.\n\n25.5.1 Lista a vector\nSi puedes reducir tu columna lista a un vector atómico entonces será una columna regular. Por ejemplo, siempre puedes resumir un objeto con su tipo y largo, por lo que este código funcionará sin importar cuál tipo de columna-lista tengas:\n\ndf &lt;- tribble(\n  ~x,\n  letters[1:5],\n  1:3,\n  runif(5)\n)\n\ndf %&gt;% mutate(\n  tipo = map_chr(x, typeof),\n  largo = map_int(x, length)\n)\n\n# A tibble: 3 × 3\n  x         tipo      largo\n  &lt;list&gt;    &lt;chr&gt;     &lt;int&gt;\n1 &lt;chr [5]&gt; character     5\n2 &lt;int [3]&gt; integer       3\n3 &lt;dbl [5]&gt; double        5\n\n\nEsta es la misma información básica que obtienes del método de impresión por defecto de tbl , solo que ahora lo puedes usar para filtrar. Es una técnica útil si tienes listas heterogéneas y quieres remover las partes que no te sirven.\nNo te olvides de los atajos de map_*() - puedes usar map_chr(x, \"manzana\") para extraer la cadena de caracteres almacenada en manzana para cada elemento de x. Esto es útil para separar listas anidadas en columnas regulares. Usa el argumento .null para proveer un valor para usar si el elemento es un valor faltante (en lugar de retornar NULL):\n\ndf &lt;- tribble(\n  ~x,\n  list(a = 1, b = 2),\n  list(a = 2, c = 4)\n)\ndf %&gt;% mutate(\n  a = map_dbl(x, \"a\"),\n  b = map_dbl(x, \"b\", .null = NA_real_)\n)\n\n# A tibble: 2 × 3\n  x                    a     b\n  &lt;list&gt;           &lt;dbl&gt; &lt;dbl&gt;\n1 &lt;named list [2]&gt;     1     2\n2 &lt;named list [2]&gt;     2    NA\n\n\n\n\n25.5.2 Desanidando\nunnest() trabaja repitiendo la columna regular una vez para cada elemento de la columna-lista. Por ejemplo, en el siguiente ejemplo sencillo repetimos la primera fila 4 veces (porque el primer elemento de y tiene largo cuatro) y la segunda fila una vez:\n\ntibble(x = 1:2, y = list(1:4, 1)) %&gt;% unnest(y)\n\n# A tibble: 5 × 2\n      x     y\n  &lt;int&gt; &lt;dbl&gt;\n1     1     1\n2     1     2\n3     1     3\n4     1     4\n5     2     1\n\n\nEsto significa que no puedes simultáneamente desanidar dos columnas que contengan un número diferente de elementos:\n\n# Funciona, porque y y z tienen el mismo número de elementos en\n# cada fila\ndf1 &lt;- tribble(\n  ~x, ~y, ~z,\n  1, c(\"a\", \"b\"), 1:2,\n  2, \"c\", 3\n)\ndf1\n\n# A tibble: 2 × 3\n      x y         z        \n  &lt;dbl&gt; &lt;list&gt;    &lt;list&gt;   \n1     1 &lt;chr [2]&gt; &lt;int [2]&gt;\n2     2 &lt;chr [1]&gt; &lt;dbl [1]&gt;\n\ndf1 %&gt;% unnest(c(y, z))\n\n# A tibble: 3 × 3\n      x y         z\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1     1 a         1\n2     1 b         2\n3     2 c         3\n\n# No funciona porque y y z tienen un número diferente de elementos\ndf2 &lt;- tribble(\n  ~x, ~y, ~z,\n  1, \"a\", 1:2,\n  2, c(\"b\", \"c\"), 3\n)\ndf2\n\n# A tibble: 2 × 3\n      x y         z        \n  &lt;dbl&gt; &lt;list&gt;    &lt;list&gt;   \n1     1 &lt;chr [1]&gt; &lt;int [2]&gt;\n2     2 &lt;chr [2]&gt; &lt;dbl [1]&gt;\n\ndf2 %&gt;% unnest(c(y, z))\n\n# A tibble: 4 × 3\n      x y         z\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1     1 a         1\n2     1 a         2\n3     2 b         3\n4     2 c         3\n\n\nEl mismo principio aplica al desanidar columnas-lista de data frames. Puedes desanidar múltiples columnas-lista siempre que todos los data frames de cada fila tengan la misma cantidad de filas.\n\n\n25.5.3 Ejercicios\n\n¿Por qué podría ser útil la función lengths() para crear columnas de vectores atómicos a partir de columnas-lista?\nLista los tipos de vectores más comúnes que se encuentran en un data frame. ¿Qué hace que las listas sean diferentes?"
  },
  {
    "objectID": "25-model-many.html#haciendo-datos-ordenados-con-broom",
    "href": "25-model-many.html#haciendo-datos-ordenados-con-broom",
    "title": "25  Muchos modelos",
    "section": "25.6 Haciendo datos ordenados con broom",
    "text": "25.6 Haciendo datos ordenados con broom\nEl paquete broom provee tres herramientas generales para transformar modelos en data frames ordenados:\n\nbroom::glance(modelo) retorna una fila para cada modelo. Cada columna tiene una medida de resumen del modelo: o bien una medida de la calidad del modelo, o bien complejidad, o una combinación de ambos.\nbroom::tidy(modelo) retorna una fila por cada coeficiente en el modelo. Cada columna brinda información acerca de la estimación o su variabilidad.\nbroom::augment(modelo, data) retorna una fila por cada fila en data, agregando valores adicionales como residuos, y estadísticos de influencia."
  },
  {
    "objectID": "26-communicate.html",
    "href": "26-communicate.html",
    "title": "26  Introducción",
    "section": "",
    "text": "Hasta aquí, hemos aprendido a usar las herramientas para importar tus datos en R, ordenarlos de una manera conveniente para el análisis, y luego interpretarlos a través de su transformación, visualización y modelado. Sin embargo, no importa lo bien que esté hecho tu análisis si no puedes explicarlo de manera sencilla a otros: es decir, que es necesario comunicar tus resultados.\nLa comunicación de resultados es el tema de los siguientes cuatro capítulos.\n\n\n\n\n\n\nEn [el capítulo: R Markdown], aprenderás sobre dicho paquete, el cual es una herramienta para integrar texto, código y resultados. Puedes usarlo en modo notebook, es decir, en un entorno interactivo de ejecución de código para la comunicación de analista-a-analista, y en modo reporte para la comunicación de analista-a-tomadores-de-decisión. Gracias al potencial de los formatos de R Markdown, incluso puedes usar el mismo documento para ambos propósitos.\nEn [el capítulo: Gráficos para la comunicación], aprenderás cómo convertir tus gráficos exploratorios en gráficos explicativos, los cuales ayudarán a quien ve tu análisis por primera vez a comprender de qué se trata de manera fácil y sencilla.\nEn [el capítulo: Formatos de R Markdown], aprenderás un poco sobre la gran variedad de salidas que puedes generar usando la librería R Markdown, incluyendo dashboards (tableros de control), sitios web, y libros.\nTerminaremos con [el flujo de trabajo de R Markdown], donde aprenderás sobre “analysis notebook”, en otras palabras, aprenderás sobre el modo notebook para realizar el análisis y registrar sistemáticamente tus logros y fallas para que puedas aprender de ellos.\n\nDesafortunadamente, estos capítulos se enfocan principalmente en la parte técnica de la comunicación, y no en los verdaderos grandes problemas de comunicar tus pensamientos a otras personas. Sin embargo, existe una gran cantidad de excelentes libros que abordan esta problemática, cuyas referencias estarán disponibles al final de cada capítulo."
  },
  {
    "objectID": "27-rmarkdown.html#introducción",
    "href": "27-rmarkdown.html#introducción",
    "title": "27  R Markdown",
    "section": "27.1 Introducción",
    "text": "27.1 Introducción\nR Markdown provee un marco de escritura para ciencia de datos, que combina tu código, sus resultados y tus comentarios en prosa. Los documentos de R Markdown son completamente reproducibles y soportan docenas de formatos de salida tales como PDFs, archivos de Word, presentaciones y más.\nLos archivos R Markdown están diseñados para ser usados de tres maneras:\n\nPara comunicarse con quienes toman decisiones, que desean enfocarse en las conclusiones, no en el código que subyace al análisis.\nPara colaborar con otras personas que hacen ciencia de datosdatos (¡incluyendo a tu yo futuro!), quienes están interesados tanto en tus conclusiones como en el modo en el que llegaste a ellas (es decir, el código).\nComo un ambiente en el cual hacer ciencia de datos, como si fuera un notebook de laboratorio moderno donde puedes capturar no solo que hiciste, sino también lo que estabas pensando cuando lo hacías.\n\nR Markdown integra una cantidad de paquetes de R y herramientas externas. Esto implica que la ayuda, en general, no está disponible a través de ?. En su lugar, a lo largo de este capítulo y cuando utilices R Markdown en el futuro, mantén estos recursos cerca:\n\nHoja de referencia de R Markdown : Help &gt; Cheatsheets &gt; R Markdown Cheat Sheet\nGuía de referencia R Markdown : Help &gt; Cheatsheets &gt; R Markdown Reference Guide\n\nAmbas hojas también se encuentran disponibles en https://rstudio.com/resources/cheatsheets/&gt;.\n\n27.1.1 Prerrequisitos\nSi bien necesitas el paquete rmarkdown, no necesitas cargarlo o instalarlo explícitamente, ya que RStudio hace ambas acciones de forma automática cuando es necesario."
  },
  {
    "objectID": "27-rmarkdown.html#elementos-básicos-de-r-markdown",
    "href": "27-rmarkdown.html#elementos-básicos-de-r-markdown",
    "title": "27  R Markdown",
    "section": "27.2 Elementos básicos de R Markdown",
    "text": "27.2 Elementos básicos de R Markdown\nEste es un archivo R Markdown, un archivo de texto plano que tiene la extensión .Rmd:\n\n\n---\ntitle: \"Tamaño de los diamantes\"\ndate: 2016-08-25\noutput: html_document\n---\n\n```{r setup, include = FALSE}\nlibrary(datos)\nlibrary(ggplot2)\nlibrary(dplyr)\n\npequenios &lt;- diamantes %&gt;%\n  filter(quilate &lt;= 2.5)\n```\n\nTenemos datos respecto de `r nrow(diamantes)` diamantes. Únicamente \n`r nrow(diamantes) - nrow(pequenios)` son mayores a 2,5 quilates. \nLa distribución de los diamantes pequeños se muestra a continuación:\n\n```{r, echo = FALSE}\npequenios %&gt;%\n  ggplot(aes(quilate)) +\n  geom_freqpoly(binwidth = 0.01)\n```\n\n\nContiene tres tipos importantes de contenido:\n\nUn encabezado YAML (opcional) rodeado de ---\nBloques de código de R rodeados de ```.\nTexto mezclado con formateos de texto simple como # Encabezado e _itálicas_.\n\nCuando abres un archivo .Rmd, obtienes una interfaz de notebook donde el código y el output están intercalados. Puedes ejecutar cada bloque de código haciendo clic en el ícono ejecutar (se parece a un botón de reproducir en la parte superior del bloque de código), o presionando Cmd/Ctrl + Shift + Enter. RStudio ejecuta el código y muestra los resultados incustrados en el código:\n\n\n\n\n\nPara producir un reporte completo que contenga todo el texto, código y resultados, haz clic en “Knit” o presionar Cmd/Ctrl + Shift + K. Puede hacerse también de manera programática con rmarkdown::render(\"1-example.Rmd\"). Esto mostrará el reporte en el panel viewer y creará un archivo HTML independiente que puedes compartir con otras personas.\n\n\n\n\n\nCuando haces knit el documento (knit significa tejer en inglés), R Markdown envía el .Rmd a knitr (http://yihui.name/knitr/) que ejecuta todos los bloques de código y crea un nuevo documento markdown (.md) que incluye el código y su output. El archivo markdown generado por knitr es procesado entonces por pandoc (http://pandoc.org/) que es el responsable de crear el archivo terminado. La ventaja de este flujo de trabajo en dos pasos es que puedes crear un muy amplio rango de formatos de salida, como aprenderás en [Formatos de R markdown ].\n\n\n\n\n\nPara comenzar con tu propio archivo .Rmd, selecciona File &gt; New File &gt; R Markdown… en la barra de menú. RStudio iniciará un asistente que puedes usar para pre-rellenar tu archivo con contenido útil que te recuerda cómo funcionan las principales características de R Markdown.\nLas siguientes secciones profundizan en los tres componentes de un documento de R Markdown en más detalle: el texto Markdown, los bloques de código y el encabezado YAML.\n\n27.2.1 Ejercicios\n\nCrea un nuevo notebook usando File &gt; New File &gt; R Notebook. Lee las instrucciones. Practica ejecutando los bloques. Verifica que puedes modificar el código, re-ejecútalo, y observa la salida modificada.\nCrea un nuevo documento R Markdown con File &gt; New File &gt; R Markdown… Haz clic en el icono apropiado de Knit. Haz Knit usando el atajo de teclado apropiado. Verifica que puedes modificar el input y la actualización del output.\nCompara y contrasta el notebook de R con los archivos de R markdown que has creado antes. ¿Cómo son similares los outputs? ¿Cómo son diferentes? ¿Cómo son similares los inputs? ¿En qué se diferencian? ¿Qué ocurre si copias el encabezado YAML de uno al otro?\nCrea un nuevo documento R Markdown para cada uno de los tres formatos incorporados: HTML, PDF and Word. Haz knit en cada uno de estos tres documentos. ¿Como difiere el output? ¿Cómo difiere el input? (Puedes necesitar instalar LaTeX para poder compilar el output en PDF— RStudio te preguntará si esto es necesario)."
  },
  {
    "objectID": "27-rmarkdown.html#formateo-de-texto-con-markdown",
    "href": "27-rmarkdown.html#formateo-de-texto-con-markdown",
    "title": "27  R Markdown",
    "section": "27.3 Formateo de texto con Markdown",
    "text": "27.3 Formateo de texto con Markdown\nLa prosa en los archivos .Rmd está escrita en Markdown, una colección simple de convenciones para dar formato a archivos de texto plano. Markdown está diseñado para ser fácil de leer y fácil de escribir. Es también muy fácil de aprender. La siguiente guía muestra cómo usar el Markdown de Pandoc, una versión ligeramente extendida de Markdown que R Markdown comprende.\n\n\nFormato de texto\n------------------------------------------------------------\n\n*cursiva*   o _cursiva_\n**negrita**   __negrita__\n`code`\nsuperíndice^2^ y subíndice~2~\n\nEncabezados\n------------------------------------------------------------\n\n# Encabezado de primer nivel\n\n## Encabezado de segundo nivel\n\n### Encabezado de tercer nivel\n\nListas\n------------------------------------------------------------\n\n*   Elemento 1 en lista no enumerada\n\n*   Elemento 2\n\n    * Elemento 2a\n\n    * Elemento 2b\n\n1.  Elemento 1 en lista enumerada\n\n1.  Elemento 2. La numeración se incrementa automáticamente en el output.\n\nEnlaces e imágenes\n------------------------------------------------------------\n\n&lt;http://ejemplo.com&gt;\n\n[texto del enlace](http://ejemplo.com)\n\n![pie de página opcional](ruta/de/la/imagen.png)\n\nTablas \n------------------------------------------------------------\n\nPrimer encabezado     | Segundo encabezado\n--------------------- | ---------------------\nContenido de la celda | Contenido de la celda\nContenido de la celda | Contenido de la celda\n\n\nLa mejor manera de aprender estas convenciones es simplemente probar. Tomará unos días, pero pronto se convertirán en algo natural y no necesitarás pensar en ellas. Si te olvidas, puedes tener una útil hoja de referencia con Help &gt; Markdown Quick Reference.\n\n27.3.1 Ejercicios\n\nPractica lo que has aprendido crando un CV breve. El título debería ser tu nombre, y deberías incluir encabezados para (por lo menos) educación o empleo. Cada una de las secciones debería incluir una lista con viñetas de trabajos/ títulos obtenidos. Resalta el año en negrita.\nUsando la referencia rápida de R Markdown, descubre como:\nAgregar una nota al pie.\nAgregar una linea horizontal.\nAgregar una cita en bloque.\nCopia y pega los contenidos de diamond-sizes.Rmd desde https://github.com/hadley/r4ds/tree/master/rmarkdown a un documento local de R Markdown. Revisa que puedes ejecutarlo, agrega texto después del polígono de frecuencias que describa sus características más llamativas."
  },
  {
    "objectID": "27-rmarkdown.html#bloques-de-código",
    "href": "27-rmarkdown.html#bloques-de-código",
    "title": "27  R Markdown",
    "section": "27.4 Bloques de código",
    "text": "27.4 Bloques de código\nPara ejecutar código dentro de un documento R Markdown, necesitas insertar un bloque o chunk, en inglés. Hay tres maneras para hacerlo:\n\nCon el atajo de teclado: Cmd/Ctrl + Alt + I\nCon el ícono “Insert” en la barra de edición\nTipeando manualmente los delimitadores de bloque ```{r} y ```.\n\nObviamente, nuestra recomendación es que aprendas a usar el atajo de teclado. A largo plazo, te ahorrará mucho tiempo.\nPuedes continuar ejecutando el código usando el atajo de teclado que para este momento (¡esperamos!) ya conoces y amas : Cmd/Ctrl + Enter. Sin embargo, los bloques de código tienen otro atajo de teclado: Cmd/Ctrl + Shift + Enter, que ejecuta todo el código en el bloque. Piensa el bloque como una función. Un bloque debería ser relativamente autónomo y enfocado en torno a una sola tarea.\nLas siguientes secciones describen el encabezado de bloque, que consiste en ```{r, seguido por un nombre opcional para el bloque, seguido luego por opciones separadas por comas y un }. Luego viene tu código de R. El término del bloque se indica con un ``` final.\n\n27.4.1 Nombres de los bloques\nLos bloques puede tener opcionalmente nombres: ```{r nombre}. Esto presenta tres ventajas:\n\nPuedes navegar más fácilmente a bloques específicos usando el navegador de código desplegable abajo a la izquierda en el editor de script:\n\n::: {.cell} ::: {.cell-output-display}  ::: :::\n\nLos gráficos producidos por los bloques tendrán nombres útiles que hace que sean más fáciles de utilizar en otra parte. Más sobre esto en la sección sobre [otras opciones importantes].\nPuedes crear redes de bloques guarados en el caché para evitar re-ejecutar cómputos costosos en cada ejecución. Más sobre esto más adelante.\n\nHay un nombre de bloque que tiene comportamiento especial: setup. Cuando te encuentras en modo notebook, el bloque llamado setup se ejecutará automáticamente una vez, antes de ejecutar cualquier otro código.\n\n\n27.4.2 Opciones de los bloques\nLa salida de los bloques puede personalizarse con options, que son argumentos suministrados en el encabezado del bloque. Knitr provee casi 60 opciones que puedes usar para personalizar tus bloques de código. Aquí cubriremos las opciones de bloques más importantes que usarás más frecuentemente. Puedes ver la lista completa en http://yihui.name/knitr/options/.\nEl conjunto más importante de opciones controla si tu bloque de código es ejecutado y qué resultados estarán insertos en el reporte final:\n\neval = FALSE evita que el código sea evaluado. (Y, obviamente, si el código no es ejecutado no se generaran resultados). Esto es útil para mostrar códigos de ejemplo, o para deshabilitar un gran bloque de código sin comentar cada línea.\ninclude = FALSE ejecuta el código, pero no muestra el código o los resultados en el documento final. Usa esto para código de configuración que no quieres que abarrote tu reporte.\necho = FALSE evita que se vea el código, pero sí muestra los resultados en el archivo final. Utiliza esto cuando quieres escribir reportes enfocados a personas que no quieren ver el código subyacente de R.\nmessage = FALSE o warning = FALSE evita que aparezcan mensajes o advertencias en el archivo final.\nresults = 'hide' oculta el output impreso; fig.show = 'hide' oculta gráficos.\nerror = TRUE causa que el render continúe incluso si el código devuelve un error. Esto es algo que raramente quieres incluir en la versión final de tu reporte, pero puede ser muy útil si necesitas depurar exactamente qué ocurre dentro de tu .Rmd. Es también útil si estás enseñando R y quieres incluir deliberadamente un error. Por defecto, error = FALSE provoca que el knitting falle si hay incluso un error en el documento.\n\nLa siguiente tabla resume qué tipos de output suprime cada opción:\n\n\n\n\n\n\n\n\n\n\n\n\nOpción\nEjecuta\nMuestra\nOutput\nGráficos\nMensajes\nAdvertencias\n\n\n\n\neval = FALSE\n-\n\n-\n-\n-\n-\n\n\ninclude = FALSE\n\n-\n-\n-\n-\n-\n\n\necho = FALSE\n\n-\n\n\n\n\n\n\nresults = \"hide\"\n\n\n-\n\n\n\n\n\nfig.show = \"hide\"\n\n\n\n-\n\n\n\n\nmessage = FALSE\n\n\n\n\n-\n\n\n\nwarning = FALSE\n\n\n\n\n\n-\n\n\n\n\n\n27.4.3 Tablas\nPor defecto, R Markdown imprime data frames y matrices tal como se ven en la consola:\n\nmtcars[1:5, ]\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\n\nSi prefieres que los datos tengan formato adicional, puedes usar la función knitr::kable. El siguiente código genera una Tabla @ref(tab:kable).\n\nknitr::kable(\n  mtcars[1:5, ],\n  caption = \"Un kable de knitr.\"\n)\n\n\nUn kable de knitr.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n\n\n\nLee la documentación para ?knitr::kable para ver los otros modos en los que puedes personalizar la tabla. Para una mayor personalización, considera los paquetes xtable, stargazer, pander, tables y ascii. Cada uno provee un set de herramientas para generar tablas con formato a partir código de R.\nHay también una gran cantidad de opciones para controlar cómo las figuras están embebidas o incrustadas. Aprenderás sobre esto en la sección [guardando tus gráficos].\n\n\n27.4.4 Caching\nNormalmente, cada knit de un documento empieza desde una sesión limpia. Esto es genial para la reproducibilidad, porque se asegura que has capturado cada cómputo importante en el código. Sin embargo, puede ser doloroso si tienes cómputos que toman mucho tiempo. La solución es cache = TRUE. Cuando está configurada, esto guarda el output del bloque en un archivo con un nombre especial en el disco. En ejecuciones siguientes, knitr revisará si el código ha cambiado, y si no ha hecho, reutilizará los resultados del caché.\nEl sistema de caché debe ser usado con cuidado, porque por defecto está solo basado en el código, no en sus dependencias. Por ejemplo, aquí el bloque datos_procesados depende del bloque datos_crudos:\n```{r datos_crudos}\ndatos_crudos &lt;- readr::read_csv(\"un_archivo_muy_grande.csv\")\n```\n\n```{r datos_procesados, cache = TRUE}\ndatos_procesados &lt;- datos_crudos %&gt;% \n  filter(!is.na(variable_important)) %&gt;% \n  mutate(nueva_variable = transformacion_complicada(x, y, z))\n```\nHacer caching en el bloque datos_procesados significa que se re-ejecutará si el pipeline de dplyr se modifica, pero no re-ejecutará si cambia la llamada a read_csv(). Puedes evitar este problema con la opción de bloque dependson (depende de, en inglés):\n```{r datos_procesados, cache = TRUE, dependson = \"datos_crudos\"}\ndatos_procesados &lt;- datos_crudos %&gt;% \n  filter(!is.na(variable_important)) %&gt;% \n  mutate(nueva_variable = transformacion_complicada(x, y, z))\n```\ndependson debiese incluir un vector de caracteres de cada bloque del que depende el bloque cacheado. Knitr actualizará los resultados para el bloque cacheado cada vez que detecta que una de sus dependencias ha cambiado.\nTen en cuenta que los bloques de código no se actualizarán si un_archivo_muy_grande.csv cambia, porque el caché de knitr solo hace seguimiento de los cambios dentro del archivo .Rmd. Si quieres seguir también los cambios hechos en ese archivo, puedes usar la opción cache.extra. Esta es una expresión arbitraria de R que invalidará el caché cada vez que cambie. Una buena función a usar es file.info(): genera mucha información sobre el archivo incluyendo cuándo fue su última modificación. Puedes escribir entonces:\n```{r datos_crudos, cache.extra = file.info(\"un_archivo_muy_grande.csv\")}\ndatos_crudos &lt;- readr::read_csv(\"un_archivo_muy_grande.csv\")\n```\nA medida que tus estrategias de cacheo se vuelvan progresivamente más complicadas, es una buena idea limpiar regularmente todos tus cachés con knitr::clean_cache().\nHemos utilizado el consejo de David Robinson para nombrar estos bloques: cada bloque debe nombrarse según el objeto principal que crea. Esto hace mucho más fácil entender la especificación dependson.\n\n\n27.4.5 Opciones globales\nA medida que trabajes más con knitr, descubrirás que algunas de las opciones de bloque por defecto no se ajustan a tus necesidades y querrás cambiarlas. Puedes hacer esto incluyendo knitr::opts_chunk$set() en un bloque de código. Por ejemplo, cuando escribimos libros y tutoriales seteamos:\n\nknitr::opts_chunk$set(\n  comment = \"#&gt;\",\n  collapse = TRUE\n)\n\nEsto utiliza nuestro formato preferido de comentarios y se asegura que el código y el output se mantengan entrelazados. Por otro lado, si preparas un reporte, puedes fijar:\n\nknitr::opts_chunk$set(\n  echo = FALSE\n)\n\nEsto ocultará por defectoel código, así que solo mostrará los bloques que deliberadamente has elegido mostrar (con echo = TRUE). Puedes considerar fijar message = FALSE y warning = FALSE, pero eso puede hacer más díficil la tarea de depurar problemas, porque no verías ningún mensajes en el documento final.\n\n\n27.4.6 Código dentro de una línea\nHay otro modo de incluir código R en un documento R Markdown: directamente en el texto, con:`r `. Esto puede ser muy útil si mencionas propiedades de tus datos en el texto. Por ejemplo, en el documento de ejemplo que utilizamos al comienzo del capítulo teníamos:\n\nTenemos datos sobre `r nrow(diamonds)` diamantes. Solo `r nrow(diamonds) - nrow(smaller)` son de más de 2.5 quilates. La distribución de los restantes se muestra a continuación:\n\nCuando hacemos knit, los resultados de estos cómputos están insertos en el texto:\n\nTenemos datos de 53940 diamantes. Solo 126 son de más de 2.5 quilates. La distribución de los restantes se muestra a continuación:\n\nCuando insertas números en el texto, la función format() es tu amiga. Esta permite establecer el número de dígitos (digits) para que no imprimas con un grado ridículo de precisión y el separador de miles (big.mark) para hacer que los números sean más fáciles de leer. Siempre combinamos estos en una función de ayuda:\n\ncoma &lt;- function(x) format(x, digits = 2, big.mark = \",\")\ncoma(3452345)\n\n[1] \"3,452,345\"\n\ncoma(.12358124331)\n\n[1] \"0.12\"\n\n\n\n\n27.4.7 Ejercicios\n\nIncluye una sección que explore cómo los tamaños de diamantes varían por corte, color y claridad. Asume que escribes un reporte para alguien que no conoce R, por lo que en lugar de fijar echo = FALSE en cada bloque, fija una opción global.\nDescarga diamond-sizes.Rmd de https://github.com/cienciadedatos/r4ds/blob/traduccion/rmarkdown. Agrega una sección que describa los 20 diamantes mas grandes, incluyendo una tabla que muestre sus atributos más importantes.\nModifica diamonds-sizes.Rmd para usar coma() para producir un formato de output ordenado. También incluye el porcentaje de diamantes que son mayores a 2.5 quilates.\nDefine una red de bloques donde d dependa de c y de b, y tanto b y c dependan de a. Haz que cada bloque imprima lubridate::now(), fija cache = TRUE y verifica que estás comprendiendo cómo se almacena en cache."
  },
  {
    "objectID": "27-rmarkdown.html#solucionando-problemas",
    "href": "27-rmarkdown.html#solucionando-problemas",
    "title": "27  R Markdown",
    "section": "27.5 Solucionando problemas",
    "text": "27.5 Solucionando problemas\nSolucionar problemas en documentos de R Markdown puede ser muy desafiante, ya que no te encuentras usando R en un ambiente de R interactivo. Es por eso que necesitarás aprender algunos trucos nuevos. La primera cosa que siempre debes intentar es recrear el problema en una sesión interactiva. Reinicia R, ejecuta todos los bloques de código (ya sea desde el menú Code, desde el menú desplegable bajo Run o con el atajo del teclado Ctrl + Alt + R). Si tienes suerte, eso recreará el problema y podrás descubrir lo que está ocurriendo interactivamente.\nSi eso no ayuda, debe haber algo diferente entre tu ambiente interactivo y el ambiente de R Markdown. Tendrás que explorar sistemáticamente las opciones. La diferencia más común es el directorio de trabajo: el directorio de trabajo de R Markdown es el directorio en el que se encuentra. Revisa que el directorio de trabajo es el que esperas incluyendo getwd() en un bloque.\nA continuación, piensa en todas las cosas que podrían causar el error. Necesitarás revisar sistemáticamente que tu sesión de R y tu sesión de R Markdown sean la misma. La manera más fácil de hacer esto es fijar error = TRUE en el bloque que causa problemas, y luego usa print() y str() para revisar que la configuración es la esperada."
  },
  {
    "objectID": "27-rmarkdown.html#encabezado-yaml",
    "href": "27-rmarkdown.html#encabezado-yaml",
    "title": "27  R Markdown",
    "section": "27.6 Encabezado YAML",
    "text": "27.6 Encabezado YAML\nPuedes controlar otras configuraciones de “documento completo” haciendo ajustes a los parámetros del encabezado YAML. Estarás preguntándote que significa YAML: es la sigla en inglés de la frase “yet another markup language”, que significa “otro lenguaje de marcado más”. Este lenguaje de marcado está diseñado para representar datos jerárquicos de modo tal que sea fácil de escribir y leer para humanos. R Markdown lo utiliza para controlar muchos detalles del output. Aquí discutiremos dos: parámetros del documento y bibliografías.\n\n27.6.1 Parámetros\nLos documentos R Markdown pueden incluir uno o mas parámetros cuyos valores pueden ser fijados cuando se renderiza el reporte. Los parámetros son útiles cuando quieres re-renderizar el mismo reporte con valores distintos para varios inputs clave. Por ejemplo, podrías querer producir reportes de venta por ramas, resultados de un examen por alumno, resúmenes demográficos por país. Para declarar uno o más parámetros, utiliza el campo params.\nEste ejemplo utiliza el parámetro my_class para determinar que clase de auto mostrar:\n\n\n---\noutput: html_document\nparams:\n  mi_clase: \"suv\"\n---\n\n```{r setup, include = FALSE}\nlibrary(datos)\nlibrary(ggplot2)\nlibrary(dplyr)\n\nclase &lt;- millas %&gt;% filter(clase == params$mi_clase)\n```\n\n# Economía de combustible en vehículos de tipo `r params$mi_clase`\n\n```{r, message = FALSE}\nggplot(clase, aes(cilindrada, autopista)) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n```\n\n\nComo puedes ver, los parámetros están disponibles dentro de los bloques de código como una lista de solo lectura llamada params.\nPuedes escribir vectores atómicos directamente en el encabezado YAML. Puedes también ejecutar expresiones arbitrarias de R agregando !r antes del valor del parámetro. Esta es una buena manera de especificar parámetros de fecha/hora.\nparams:\n start: !r lubridate::ymd(\"2015-01-01\")\n snapshot: !r lubridate::ymd_hms(\"2015-01-01 12:30:00\")\nEn RStudio, puedes hacer clic en la opción “Knit with Parameters” en el menú desplegable Knit para fijar parámetros, renderizar y previsualizar en un solo paso amigable. Puedes personalizar el diálogo fijando otras opciones en el encabezado. Ver para más detalles http://rmarkdown.rstudio.com/developer_parameterized_reports.html#parameter_user_interfaces (en inglés).\nDe manera alternativa, si necesitas producir varios reportes parametrizados, puedes ejecutar rmarkdown::render() con una lista de params:\n\nrmarkdown::render(\"fuel-economy.Rmd\", params = list(mi_clase = \"suv\"))\n\nEsto es particularmente poderoso en conjunto con purrr:pwalk(). El siguiente ejemplo crea un reporte para cada valor de clase que se encuentra en millas. Primero creamos un data frame que tiene una fila para cada clase, dando el nombre de archivo (filename) del reporte y los params:\n\nreportes &lt;- tibble(\n  clase = unique(millas$clase),\n  filename = stringr::str_c(\"economia-combustible-\", clase, \".html\"),\n  params = purrr::map(clase, ~ list(mi_clase = .))\n)\nreportes\n\n# A tibble: 7 × 3\n  clase       filename                              params          \n  &lt;chr&gt;       &lt;chr&gt;                                 &lt;list&gt;          \n1 compacto    economia-combustible-compacto.html    &lt;named list [1]&gt;\n2 mediano     economia-combustible-mediano.html     &lt;named list [1]&gt;\n3 suv         economia-combustible-suv.html         &lt;named list [1]&gt;\n4 2asientos   economia-combustible-2asientos.html   &lt;named list [1]&gt;\n5 minivan     economia-combustible-minivan.html     &lt;named list [1]&gt;\n6 pickup      economia-combustible-pickup.html      &lt;named list [1]&gt;\n7 subcompacto economia-combustible-subcompacto.html &lt;named list [1]&gt;\n\n\nEntonces unimos los nombres de las columnas con los nombres de los argumentos de render(), y utilizamos la función pwalk() (parallel walk) del paquete purrr para invocar render() una vez en cada fila:\n\nreportes %&gt;%\n  select(output_file = filename, params) %&gt;%\n  purrr::pwalk(rmarkdown::render, input = \"fuel-economy.Rmd\")\n\n\n\n27.6.2 Bibliografías y citas\nPandoc puede generar automáticamente citas y bibliografía en varios estilos. Para usar esta característica, especifica un archivo de bibliografía usando el campo bibliography en el encabezado de tu archivo. El campo debe incluir una ruta del directorio que contiene tu archivo .Rmd al archivo que contiene el archivo de bibliografía:\nbibliography: rmarkdown.bib\nPuedes usar muchos formatos comunes de biliografía incluyendo BibLaTeX, BibTeX, endnote, medline.\nPara crear una cita dentro de tu archivo .Rmd, usa una clave compuesta de ‘@’ + el identificador de la cita del archivo de la bibliografía. Después, ubica esta cita entre corchetes. Aquí hay algunos ejemplos:\nMultiple citas se separan con un `;`: Bla bla[@smith04; @doe99].\n\nPuedes incluir comentarios arbritarios dentro de los corchetes:\nBla bla [ver @doe99, pp. 33-35; también @smith04, ch. 1].\n\nRemover los corchetes para crear una cita dentro del texto: @smith04\ndice bla, o @smith04 [p. 33] dice bla.\n\nAgrega un signo `-` antes de la cita para eliminar el nombre del autor:\n\nSmith dice bla [-@smith04].\nCuando R Markdown renderice tu archivo, construirá y agregará una bibliografía al final del documento. La bibliografía contendrá cada una de las referencias citadas de tu archivo de bibliografía, pero no contendrá un encabezado de sección. Como resultado, es una práctica común finalizar el archivo con un encabezado de sección para la bibliografía, tales como # Referencias or # Bibliografía.\nPuedes cambiar el estilo de tus citas y bibliografía referenciando un archivo CSL (sigla de “citation style language”, es decir, lenguaje de estilo de citas) en el campo csl:\nbibliography: rmarkdown.bib\ncsl: apa.csl\nTal y como en el campo de bilbiografía, tu archivo csl debería contener una ruta al archivo. Aquí asumimos que el archivo csl está en el mismo directorio que el archivo .Rmd. Un buen lugar para encontrar archivos CSL para estilos de bibliografía comunes es http://github.com/citation-style-language/styles."
  },
  {
    "objectID": "27-rmarkdown.html#aprendiendo-más",
    "href": "27-rmarkdown.html#aprendiendo-más",
    "title": "27  R Markdown",
    "section": "27.7 Aprendiendo más",
    "text": "27.7 Aprendiendo más\nR Markdown es todavía relativamente reciente y sigue creciendo con rapidez. El mejor lugar para estar al tanto de las innovaciones es el sitio oficial de R Markdown: http://rmarkdown.rstudio.com.\nHay dos tópicos importantes que no hemos mencionado aquí: colaboraciones y los detalles de comunicar de manera precisa tus ideas a otros seres humanos. La colaboración es una parte vital de la ciencia de datos moderna y puedes hacer tu vida mucho más fácil si usas herramientas de control de versión, tales como Git y GitHub. Recomendamos dos recursos gratuitos que te enseñarán Git:\n\n“Happy Git with R”: una introducción amigable a Git y GitHub para personas que usan R, de Jenny Bryan. El libro esta disponible de manera libre en línea en: http://happygitwithr.com\nEl capitulo “Git and GitHub” de R Packages, de Hadley Wickham. Puedes también leerlo online: https://r-pkgs.org/git.html.\n\nTampoco hemos hablado acerca de qué es lo que realmente deberías escribir para poder comunicar claramente los resultados de tu análisis. Para mejorar tu escritura, recomendamos leer cualquiera de estos libros (en inglés): Style: Lessons in Clarity and Grace de Joseph M. Williams & Joseph Bizup o The Sense of Structure: Writing from the Reader’s Perspective de George Gopen. Ambos libros te ayudarán a entender la estructura de oraciones y párrafos, y te darán las herramientas para hacer más clara tu escritura. (Estos libros son bastante caros si se compran nuevos, pero dado que son usados en muchas clases de inglés es posible encontrar copias baratas de segunda mano). George Gopen también ha escrito varios artículos cortos en inglés sobre escritura en https://www.georgegopen.com/the-litigation-articles.html. Están dirigidos a abogados, pero casi todo también se aplica en el contexto de la ciencia de datos."
  },
  {
    "objectID": "28-communicate-plots.html#introducción",
    "href": "28-communicate-plots.html#introducción",
    "title": "28  Comunicar con gráficos",
    "section": "28.1 Introducción",
    "text": "28.1 Introducción\nEn [análisis de datos exploratorios] aprendiste a usar gráficos como herramientas de exploración. Cuando haces gráficos exploratorios, sabes incluso antes de mirar, qué variables mostrará el gráfico. Hiciste cada gráfico con un propósito, lo miraste rápidamente y luego pasaste al siguiente. En el transcurso de la mayoría de los análisis, producirás decenas o cientos de gráficos, muchos de los cuales se desecharán inmediatamente.\nAhora que comprendes tus datos, debes comunicar tu conocimiento a los demás. Es probable que tu audiencia no comparta tus conocimientos previos y no esté profundamente involucrada en los datos. Para ayudar a otros a construir rápidamente un buen modelo mental de los datos, deberás invertir un esfuerzo considerable para que tus gráficos se expliquen por sí solos . En este capítulo, aprenderás algunas de las herramientas que proporciona ggplot2 para hacerlo.\nEste capítulo se centra en las herramientas necesarias para crear buenos gráficos. Supongo que sabes lo que quieres y solo te falta saber cómo hacerlo. Por esa razón, recomiendo combinar este capítulo con un buen libro de visualización general. Me gusta especialmente The Truthful Art, de Albert Cairo. No enseña la mecánica de crear visualizaciones, sino que se enfoca en lo que necesitas pensar para crear gráficos efectivos.\n\n28.1.1 Prerrequisitos\nEn este capítulo, nos centraremos una vez más en ggplot2. También usaremos un poco el paquete dplyr para la manipulación de datos y algunos paquetes como ggrepel y viridis que extienden las funciones de ggplot2. En lugar de cargar esas extensiones aquí, nos referiremos a sus funciones de forma explícita, utilizando la notación :: . Esto ayudará a aclarar qué funciones están integradas en ggplot2 y cuáles vienen de otros paquetes. No olvides que deberás instalar esos paquetes con install.packages() si aún no los tienes.\n\nlibrary(tidyverse)\nlibrary(datos)"
  },
  {
    "objectID": "28-communicate-plots.html#etiquetas",
    "href": "28-communicate-plots.html#etiquetas",
    "title": "28  Comunicar con gráficos",
    "section": "28.2 Etiquetas",
    "text": "28.2 Etiquetas\nEl punto de inicio más sencillo para convertir un gráfico exploratorio en un gráfico expositivo es con buenas etiquetas. Agrega etiquetas con la función labs(). Este ejemplo agrega un título al gráfico:\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(color = clase)) +\n  geom_smooth(se = FALSE) +\n  labs(title = \"La eficiencia del combustible generalmente disminuye con el tamaño del motor\")\n\n\n\n\nEl propósito del título de un gráfico es resumir el hallazgo principal. Evita títulos que simplemente describen el gráfico, por ejemplo “Diagrama de dispersión del desplazamiento del motor frente al ahorro de combustible”.\nSi necesitas agregar más texto, hay otras dos etiquetas útiles que puedes usar en ggplot2 versión 2.2.0 y superiores (que deberían estar disponibles para cuando estés leyendo este libro):\n\nel subtítulo, del inglés subtitle, agrega detalles adicionales en una fuente más pequeña debajo del título.\nla leyenda, del inglés caption, agrega texto en la parte inferior derecha del gráfico, suele usarse para describir la fuente de los datos.\n\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(color = clase)) +\n  geom_smooth(se = FALSE) +\n  labs(\n    title = \"La eficiencia del combustible generalmente disminuye con el tamaño del motor\",\n    subtitle = \"Los automóviles deportivos de dos asientos son la excepción debido a su peso liviano\",\n    caption = \"Datos de fueleconomy.gov\"\n  )\n\n\n\n\nTambién puedes usar labs() para reemplazar los títulos de ejes y leyendas. Por lo general, es una buena idea reemplazar los nombres cortos de las variables con descripciones más detalladas e incluir las unidades.\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(colour = clase)) +\n  geom_smooth(se = FALSE) +\n  labs(\n    x = \"Tamaño del motor (litros)\",\n    y = \"Economía de combustible de carretera (millas)\",\n    colour = \"Tipo de automóvil\"\n  )\n\n\n\n\nEs posible usar ecuaciones matemáticas en lugar de cadenas de texto. Simplemente cambia \"\" por quote() y lee acerca de las opciones disponibles en ?plotmath:\n\ndf &lt;- tibble(\n  x = runif(10),\n  y = runif(10)\n)\n\nggplot(df, aes(x, y)) +\n  geom_point() +\n  labs(\n    x = quote(sum(x[i]^2, i == 1, n)),\n    y = quote(alpha + beta + frac(delta, theta))\n  )\n\n\n\n\n\n28.2.1 Ejercicios\n\nCrea un gráfico partiendo de los datos de economía de combustible con etiquetas para title , subtitle, caption, x, y y color personalizadas.\nLa función geom_smooth() es un poco engañosa porque autopista está sesgada positivamente para motores grandes, debido a la inclusión de autos deportivos livianos con motores grandes. Usa tus herramientas de modelado para ajustar y mostrar un modelo mejor.\nElige un gráfico exploratorio que hayas creado en el último mes y agrégale títulos informativos para volverlo más fácil de comprender para otros."
  },
  {
    "objectID": "28-communicate-plots.html#anotaciones",
    "href": "28-communicate-plots.html#anotaciones",
    "title": "28  Comunicar con gráficos",
    "section": "28.3 Anotaciones",
    "text": "28.3 Anotaciones\nAdemás de etiquetar las partes principales de tu gráfico, a menudo es útil etiquetar observaciones individuales o grupos de observaciones. La primera herramienta que tienes a tu disposición es geom_text(). La función geom_text() es similar a geom_point(), pero tiene una estética adicional: label. Esto hace posible agregar etiquetas textuales a tus gráficos.\nHay dos posibles fuentes de etiquetas. En primer lugar, es posible tener un tibble que proporcione las etiquetas. El siguiente gráfico no es en sí terriblemente útil, pero si lo es su enfoque: filtrar el auto más eficiente de cada clase con dplyr, y luego etiquetarlo en el gráfico:\n\nmejor_de_su_clase &lt;- millas %&gt;%\n  group_by(clase) %&gt;%\n  filter(row_number(desc(autopista)) == 1)\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(colour = clase)) +\n  geom_text(aes(label = modelo), data = mejor_de_su_clase)\n\n\n\n\nEsto es difícil de leer porque las etiquetas se superponen entre sí y con los puntos. Podemos mejorar ligeramente las cosas cambiando por geom_label(), que dibuja un rectángulo detrás del texto. También usamos el parámetro nudge_y para mover las etiquetas ligeramente por encima de los puntos correspondientes:\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(colour = clase)) +\n  geom_label(aes(label = modelo), data = mejor_de_su_clase, nudge_y = 2, alpha = 0.5)\n\n\n\n\nEsto ayuda un poco, pero si te fijas bien en la esquina superior izquierda verás que hay dos etiquetas prácticamente una encima de la otra. Esto sucede porque el kilometraje y el desplazamiento para los mejores automóviles en las categorías de compactos y subcompactos son exactamente los mismos. No hay forma de que podamos solucionar esto aplicando la misma transformación para cada etiqueta. En cambio, podemos usar el paquete ggrepel de Kamil Slowikowski. Este paquete es muy útil ya que ajusta automáticamente las etiquetas para que no se superpongan:\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(colour = clase)) +\n  geom_point(size = 3, shape = 1, data = mejor_de_su_clase) +\n  ggrepel::geom_label_repel(aes(label = modelo), data = mejor_de_su_clase)\n\n\n\n\nTen en cuenta otra técnica muy práctica utilizada aquí: agregué una segunda capa de puntos grandes y huecos para resaltar los puntos que etiqueté.\nA veces puedes usar la misma idea para reemplazar la leyenda con etiquetas colocadas directamente en tu gráfico. Los resultados no son maravillosos para este gráfico en particular, pero tampoco son tan malos. (theme(legend.position = \"none\") desactiva la leyenda — hablaremos de ello en breve).\n\nclase_promedio &lt;- millas %&gt;%\n  group_by(clase) %&gt;%\n  summarise(\n    cilindrada = median(cilindrada),\n    autopista = median(autopista)\n  )\n\nggplot(millas, aes(cilindrada, autopista, colour = clase)) +\n  ggrepel::geom_label_repel(aes(label = clase),\n    data = clase_promedio,\n    size = 6,\n    label.size = 0,\n    segment.color = NA\n  ) +\n  geom_point() +\n  theme(legend.position = \"none\")\n\n\n\n\nAlternativamente puede que quieras agregar una única etiqueta al gráfico, pero de todas formas necesitarás generar un conjunto de datos. Puede ocurrir que desees ubicar la etiqueta en la esquina del gráfico, en ese caso es conveniente crear un nuevo marco de datos usando summarise() para calcular los valores máximos de x e y.\n\netiqueta &lt;- millas %&gt;%\n  summarise(\n    cilindrada = max(cilindrada),\n    autopista = max(autopista),\n    etiqueta = \"El aumento del tamaño del motor está \\nrelacionado con la disminución en el gasto de combustible.\"\n  )\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point() +\n  geom_text(aes(label = etiqueta), data = etiqueta, vjust = \"top\", hjust = \"right\")\n\n\n\n\nSi deseas colocar el texto exactamente en los bordes del gráfico puedes usar +Inf y -Inf. Como ya no estamos calculando las posiciones de millas, podemos usar tibble() para crear el conjunto de datos:\n\netiqueta &lt;- millas %&gt;%\n  summarise(\n    cilindrada = Inf,\n    autopista = Inf,\n    etiqueta = \"El aumento del tamaño del motor está \\nrelacionado con la disminución en el gasto de combustible.\"\n  )\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point() +\n  geom_text(aes(label = etiqueta), data = etiqueta, vjust = \"top\", hjust = \"right\")\n\n\n\n\nEn estos ejemplos, separé manualmente la etiqueta en líneas usando “”. Otra posibilidad es usar stringr::str_wrap() para agregar saltos de línea automáticamente, dado el número de caracteres que deseas por línea:\n\n\"El aumento del tamaño del motor está relacionado con la disminución en el gasto de combustible.\" %&gt;%\n  stringr::str_wrap(width = 40) %&gt;%\n  writeLines()\n\nEl aumento del tamaño del motor está\nrelacionado con la disminución en el\ngasto de combustible.\n\n\nTen en cuenta el uso de hjust y vjust para controlar la alineación de la etiqueta. La figura @ref(fig:just) muestra las nueve combinaciones posibles.\n\n\n\n\n\nLas nueve combinaciones posibles con hjust y vjust.\n\n\n\n\nRecuerda que además de geom_text(), en ggplot2 tienes muchos otros geoms disponibles para ayudar a agregar notas a tu gráfico . Algunas ideas:\n\nEmplea geom_hline() y geom_vline() para agregar líneas de referencia. A menudo las hago gruesas (size = 2) y blancas (color = white), y las dibujo debajo de la primera capa de datos. Eso las hace fáciles de ver, sin distraer la atención de los datos.\nEmplea geom_rect() para dibujar un rectángulo alrededor de los puntos de interés. Los límites del rectángulo están definidos por las estéticas xmin,xmax, ymin,ymax.\nEmplea geom_segment() con el argumento arrow para destacar un punto en particular con una flecha. Usa la estética x e y para definir la ubicación inicial, y xend y yend para definir la ubicación final.\n\n¡El único límite es tu imaginación! (y tu paciencia para posicionar las anotaciones de forma estéticamente agradable)\n\n28.3.1 Ejercicios\n\nUsa las infinitas posiciones que permite geom_text() para colocar texto en cada una de las cuatro esquinas del gráfico.\nLee la documentación de la función annotate(). ¿Cómo puedes usarla para agregar una etiqueta de texto a un gráfico sin tener que crear un tibble?\n¿Cómo interactúan las etiquetas producidas por geom_text() con la separación en facetas? ¿Cómo puedes agregar una etiqueta a una sola faceta? ¿Cómo puedes poner una etiqueta diferente en cada faceta? (Sugerencia: piensa en los datos subyacentes).\n¿Qué argumentos para geom_label() controlan la apariencia de la caja que se ve atrás?\n¿Cuáles son los cuatro argumentos de arrow()? ¿Cómo funcionan? Crea una serie de gráficos que demuestren las opciones más importantes."
  },
  {
    "objectID": "28-communicate-plots.html#escalas",
    "href": "28-communicate-plots.html#escalas",
    "title": "28  Comunicar con gráficos",
    "section": "28.4 Escalas",
    "text": "28.4 Escalas\nLa tercera forma en que puedes mejorar tu gráfico para comunicar es ajustar las escalas. Las escalas controla el mapeo de los valores de los datos a cosas que puedes percibir. Normalmente, ggplot2 agrega escalas automáticamente. Por ejemplo, cuando tipeas:\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(colour = clase))\n\nggplot2 agrega automáticamente escalas predeterminadas detrás de escena:\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(colour = clase)) +\n  scale_x_continuous() +\n  scale_y_continuous() +\n  scale_colour_discrete()\n\nTen en cuenta que los nombres de las escalas comienzan siempre igual: scale_ seguido del nombre de la estética, luego _ y finalmente el nombre de la escala. Las escalas predeterminadas se nombran según el tipo de variable con la que se alinean: continua, discreta, fecha y hora (datetime) o fecha. Hay muchas escalas no predeterminadas que aprenderás a continuación.\nLas escalas predeterminadas se han elegido cuidadosamente para ser adecuadas para una gama amplia de valores. Sin embargo, es posible que desees sobrescribir los valores predeterminados por dos razones:\n\nEs posible que desees modificar algunos de los parámetros de la escala predeterminada. Esto te permite hacer cosas como cambiar los intervalos de valores en los ejes o las etiquetas de cada valor visible.\nEs posible que desees reemplazar la escala por completo, y utilizar un algoritmo completamente diferente. Por lo general tu opción será mejor que la predeterminada ya que sabes más acerca de los datos.\n\n\n28.4.1 Marcas de los ejes y leyendas\nHay dos argumentos principales que afectan la apariencia de las marcas, del inglés ticks, en los ejes y las leyendas:breaks y labels, del inglés quiebre y etiqueta respectivamente. Los breaks controlan la posición de las marcas en los ejes o los valores asociados con las leyendas. Las labels controlan la etiqueta de texto asociada con cada marca/leyenda. El uso más común de los breaks es redefinir la opción predeterminada:\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point() +\n  scale_y_continuous(breaks = seq(15, 40, by = 5))\n\n\n\n\nPuedes usar labels de la misma manera (un vector de caracteres de la misma longitud que breaks), o puedes establecerlas como NULL del inglés nulo, para suprimir las etiquetas por completo. Esto es útil para mapas, o para publicar gráficos donde no puedes compartir los números absolutos.\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point() +\n  scale_x_continuous(labels = NULL) +\n  scale_y_continuous(labels = NULL)\n\n\n\n\nTambién puedes usar breaks y labels para controlar la apariencia de las leyendas. En conjunto, los ejes y las leyendas se llaman guías. Los ejes se usan para la estética de x e y; las leyendas se usan para todo lo demás.\nOtro uso de los breaks es cuando tienes relativamente pocos puntos de datos y deseas resaltar exactamente dónde se producen las observaciones. Como ejemplo, el siguiente gráfico muestra cuándo comenzó y terminó su mandato cada presidente de los Estados Unidos.\n\npresidencial %&gt;%\n  mutate(id = 33 + row_number()) %&gt;%\n  ggplot(aes(inicio, id)) +\n  geom_point() +\n  geom_segment(aes(xend = fin, yend = id)) +\n  scale_x_date(NULL, breaks = presidencial$inicio, date_labels = \"'%y\")\n\n\n\n\nTen en cuenta que la especificación de breaks y labels para escalas en formato de fecha y fecha y hora es ligeramente diferente:\n\ndate_labels toma en cuenta la especificación de formato, en la misma forma que parse_datetime().\ndate_breaks (no se muestra aquí), toma una cadena como “2 días” o “1 mes”.\n\n\n\n28.4.2 Diseño de leyendas\nCon mayor frecuencia utilizarás breaks y labels para ajustar los ejes. Aunque ambos también funcionan con leyendas, hay algunas otras técnicas que podrías usar.\nPara controlar la posición general de la leyenda, debes usar una configuración de theme() del inglés tema. Volveremos a los temas al final del capítulo, pero en resumen, controlan las partes del gráfico que no son de datos. La configuración del tema legend.position del inglés posición de la leyenda, controla dónde se dibuja la leyenda:\n\nbase &lt;- ggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(colour = clase))\n\nbase + theme(legend.position = \"left\")\n\n\n\nbase + theme(legend.position = \"top\")\n\n\n\nbase + theme(legend.position = \"bottom\")\n\n\n\nbase + theme(legend.position = \"right\") # the default\n\n\n\n\nTambién puedes usar legend.position = \"none\" para suprimir por completo la visualización de la leyenda.\nPara controlar la visualización de leyendas individuales, usa guides() junto con guide_legend() o guide_colourbar(). El siguiente ejemplo muestra dos configuraciones importantes: controlar el número de filas que usa la leyenda con nrow, y redefinir una de las estéticas para agrandar los puntos. Esto es particularmente útil si has usado un valor de alfa bajo para mostrar muchos puntos en un diagrama.\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(colour = clase)) +\n  geom_smooth(se = FALSE) +\n  theme(legend.position = \"bottom\") +\n  guides(colour = guide_legend(nrow = 1, override.aes = list(size = 4)))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n28.4.3 Reemplazando una escala\nEn lugar de simplemente modificar un poco los detalles, puedes reemplazar la escala por completo. Hay dos tipos de escalas que es probable que desees cambiar: escalas de posición continua y escalas de color. Afortunadamente, los mismos principios se aplican a todos los demás aspectos estéticos, por lo que una vez que hayas dominado la posición y el color serás capaz de realizar rápidamente otros reemplazos de escala.\nEsto es muy útil para graficar transformaciones de tu variable. A modo de ejemplo, como hemos visto en diamond prices, es más fácil ver la relación precisa entre quilate y precio si aplicamos una transformación logarítmica en base 10:\n\nggplot(diamantes, aes(quilate, precio)) +\n  geom_bin2d()\n\n\n\nggplot(diamantes, aes(log10(quilate), log10(precio))) +\n  geom_bin2d()\n\n\n\n\nSin embargo, la desventaja de esta transformación es que los ejes ahora están etiquetados con los valores transformados, por lo que se vuelve difícil interpretar el gráfico. En lugar de hacer la transformación en el mapeo estético, podemos hacerlo con la escala. Esto es visualmente idéntico, excepto que los ejes están etiquetados en la escala original de los datos.\n\nggplot(diamantes, aes(quilate, precio)) +\n  geom_bin2d() +\n  scale_x_log10() +\n  scale_y_log10()\n\n\n\n\nOtra escala que se personaliza con frecuencia es el color. La escala categórica predeterminada selecciona los colores que están espaciados uniformemente alrededor del círculo cromático. Otras alternativas útiles son las escalas de ColorBrewer que han sido ajustadas manualmente para que funcionen mejor para personas con tipos comunes de daltonismo. Los dos gráficos de abajo se ven similares, sin embargo hay suficiente diferencia en los tonos rojo y verde tal que los puntos de la derecha pueden distinguirse incluso por personas con daltonismo rojo-verde.\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(color = traccion))\n\n\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(color = traccion)) +\n  scale_colour_brewer(palette = \"Set1\")\n\n\n\n\nNo olvides las técnicas más simples. Si solo hay unos pocos colores, puedes agregar un mapeo de forma redundante. Esto también ayudará a asegurar que tu gráfico sea interpretable en blanco y negro.\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(color = traccion, shape = traccion)) +\n  scale_colour_brewer(palette = \"Set1\")\n\n\n\n\nLas escalas de ColorBrewer están documentadas en línea en http://colorbrewer2.org/ y están disponibles en R en el paquete RColorBrewer de Erich Neuwirth. La figura @ref(fig:brewer) muestra la lista completa de paletas de colores disponibles. Las paletas secuenciales (arriba) y divergentes (abajo) son particularmente útiles si sus valores categóricos están ordenados o tienen un “centro”. Esto a menudo ocurre si has utilizado cut() para convertir una variable continua en una variable categórica.\n\n\n\n\n\nTodas las escalas ColorBrewer.\n\n\n\n\nCuando tengas un mapeo predefinido entre valores y colores, usa scale_colour_manual(). Por ejemplo, si mapeamos los partidos presidenciales de Estados Unidos en color, queremos usar el mapeo estándar de color rojo para republicanos y azul para demócratas:\n\npresidencial %&gt;%\n  mutate(id = 33 + row_number()) %&gt;%\n  ggplot(aes(inicio, id, colour = partido)) +\n  geom_point() +\n  geom_segment(aes(xend = fin, yend = id)) +\n  scale_colour_manual(values = c(Republicano = \"red\", Demócrata = \"blue\"))\n\n\n\n\nPara generar una escala de color para variables continuas , puedes usar built in scale_colour_gradient() o scale_fill_gradient(). Si tienes una escala divergente, puedes usar scale_colour_gradient2(). Eso tepermite dar, por ejemplo, diferentes colores a valores positivos y negativos. Esto a veces también es útil si quieres distinguir puntos por encima o por debajo de la media.\nOtra opción es scale_colour_viridis() proporcionada por el paquete viridis. Es un análogo continuo de las escalas categóricas de ColorBrewer. Los diseñadores, Nathaniel Smith y Stéfan van der Walt, adaptaron cuidadosamente una paleta de color para variables continuas que tiene buenas propiedades perceptuales. Aquí hay un ejemplo de viridis:\n\ndf &lt;- tibble(\n  x = rnorm(10000),\n  y = rnorm(10000)\n)\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  coord_fixed()\n\n\n\nggplot(df, aes(x, y)) +\n  geom_hex() +\n  viridis::scale_fill_viridis() +\n  coord_fixed()\n\n\n\n\nTen en cuenta que todas las escalas de color vienen en dos variedades: scale_colour_x() y scale_fill_x() para la estética color y fill, respectivamente (las escalas de color se expresan tanto en inglés americano como británico).\n\n\n28.4.4 Ejercicios\n\n¿Por qué el siguiente código no reemplaza la escala predeterminada?\n\n::: {.cell}\nggplot(df, aes(x, y)) +\n geom_hex() +\n scale_colour_gradient(low = \"white\", high = \"red\") +\n coord_fixed()\n:::\n\n¿Cuál es el primer argumento para cada escala? ¿Cómo se compara con labs()?\nCambia la visualización de los términos presidenciales de las siguientes maneras:\n\n\nCombinando las dos variantes que se muestran arriba.\nMejorando la visualización del eje y.\nEtiquetando cada término con el nombre del presidente.\nAgregandoetiquetas informativas al gráfico.\nPoniendo intervalos de 4 años (¡esto es más complicado de lo que parece!).\n\n\nUtiliza override.aes para que la leyenda en el siguiente gráfico sea más fácil de ver:\n\n::: {.cell}\nggplot(diamantes, aes(quilate, precio)) +\n geom_point(aes(colour = corte, alpha = 1 / 20))\n::: {.cell-output-display}  ::: :::"
  },
  {
    "objectID": "28-communicate-plots.html#haciendo-zoom",
    "href": "28-communicate-plots.html#haciendo-zoom",
    "title": "28  Comunicar con gráficos",
    "section": "28.5 Haciendo Zoom",
    "text": "28.5 Haciendo Zoom\nHay tres formas de controlar los límites de un gráfico:\n\nModificando los datos que se grafican\nEstableciendo los límites en cada escala\nEstableciendo xlim y ylim en coord_cartesian()\n\nPara ampliar una región del gráfico, generalmente es mejor usar coord_cartesian().Compara los siguientes dos gráficos:\n\nggplot(millas, mapping = aes(cilindrada, autopista)) +\n  geom_point(aes(color = clase)) +\n  geom_smooth() +\n  coord_cartesian(xlim = c(5, 7), ylim = c(10, 30))\n\n\n\nmillas %&gt;%\n  filter(cilindrada &gt;= 5, cilindrada &lt;= 7, autopista &gt;= 10, autopista &lt;= 30) %&gt;%\n  ggplot(aes(cilindrada, autopista)) +\n  geom_point(aes(color = clase)) +\n  geom_smooth()\n\n\n\n\nTambién puedes establecer limits del inglés límites en escalas individuales. La reducción de los límites del gráfico es equivalente a seleccionar un subconjunto de los datos. En general es más útil si deseas expandir los límites, por ejemplo, cuando quieres hacer coincidir escalas de diferentes gráficos. A modo de ejemplo, si extraemos dos clases de automóviles y los graficamos por separado, son difíciles de comparar ya que las tres escalas (el eje x, el eje y y la estética del color) tienen rangos diferentes.\n\nsuv &lt;- millas %&gt;% filter(clase == \"suv\")\ncompacto &lt;- millas %&gt;% filter(clase == \"compacto\")\n\nggplot(suv, aes(cilindrada, autopista, colour = traccion)) +\n  geom_point()\n\n\n\nggplot(compacto, aes(cilindrada, autopista, colour = traccion)) +\n  geom_point()\n\n\n\n\nUna forma de superar este problema es compartir la escala entre varios gráficos, estableciendo una escala única a partir de los límites del conjunto de datos completo.\n\nx_scale &lt;- scale_x_continuous(limits = range(millas$cilindrada))\ny_scale &lt;- scale_y_continuous(limits = range(millas$autopista))\ncol_scale &lt;- scale_colour_discrete(limits = unique(millas$traccion))\n\nggplot(suv, aes(cilindrada, autopista, colour = traccion)) +\n  geom_point() +\n  x_scale +\n  y_scale +\n  col_scale\n\n\n\nggplot(compacto, aes(cilindrada, autopista, colour = traccion)) +\n  geom_point() +\n  x_scale +\n  y_scale +\n  col_scale\n\n\n\n\nEn este caso particular podrías haber simplemente empleado la separación en facetas, pero esta técnica es más útil en general, por ejemplo, si deseas realizar gráficos en varias páginas de un informe."
  },
  {
    "objectID": "28-communicate-plots.html#temas",
    "href": "28-communicate-plots.html#temas",
    "title": "28  Comunicar con gráficos",
    "section": "28.6 Temas",
    "text": "28.6 Temas\nFinalmente, puedes personalizar los elementos de tu gráfico que no son datos aplicando un tema:\n\nggplot(millas, aes(cilindrada, autopista)) +\n  geom_point(aes(color = clase)) +\n  geom_smooth(se = FALSE) +\n  theme_bw()\n\n\n\n\nggplot2 incluye ocho temas por defecto, como se muestra en la Figura @ref(fig:themes). Muchos otros están incluidos en paquetes adicionales como ggthemes (https://github.com/jrnold/ggthemes), de Jeffrey Arnold.\n\n\n\n\n\nThe eight themes built-in to ggplot2.\n\n\n\n\nMuchas personas se preguntan por qué el tema predeterminado tiene un fondo gris. Esta fue una elección deliberada ya que el fondo gris pone los datos por delante mientras siguen siendo visibles las líneas de la cuadrícula. Las líneas blancas de la cuadrícula son visibles (lo cual es importante porque ayudan significativamente a evaluar la posición), pero tienen poco impacto visual y son fáciles de eliminar. El fondo gris le da a al gráfico un color tipográfico similar al del texto, asegurando que los gráficos encajen con el flujo de un documento sin saltar con un fondo blanco brillante. Finalmente, el fondo gris crea un campo continuo de color que asegura que el gráfico se perciba como una sola entidad visual.\nTambién es posible controlar componentes individuales de cada tema, como el tamaño y el color de la fuente utilizada para el eje y. Desafortunadamente, este nivel de detalle está fuera del alcance de este libro, por lo que deberás leer el libro ggplot2 book para obtener todos los detalles. También puedes crear tus propios temas, si estás tratando de hacer coincidir un estilo corporativo o de revista en particular."
  },
  {
    "objectID": "28-communicate-plots.html#guardando-tus-gráficos",
    "href": "28-communicate-plots.html#guardando-tus-gráficos",
    "title": "28  Comunicar con gráficos",
    "section": "28.7 Guardando tus gráficos",
    "text": "28.7 Guardando tus gráficos\nHay dos formas principales de obtener tus gráficos desde R: ggsave() y knitr. ggsave() guardarán el gráfico más reciente en el disco.\n\nggplot(millas, aes(cilindrada, autopista)) + geom_point()\n\n\n\nggsave(\"mi_grafico.pdf\")\n\nSaving 7 x 5 in image\n\n\nSi no especificas width y height, del inglés el ancho y el alto, se usarán las dimensiones del dispositivo empleado para graficar. Para que el código sea reproducible, necesitarás especificarlos.\nEn general, sin embargo, creo que deberías armar tus informes finales utilizando R Markdown, por lo que quiero centrarme en las opciones importantes para los bloques de código que debes conocer para graficar. Puedes obtener más información sobre ggsave() en la documentación.\n\n28.7.1 Redimensionar una figura\nEl mayor desafío de los gráficos en R Markdown es conseguir que tus figuras tengan el tamaño y la forma correctos. Hay cinco opciones principales que controlan el tamaño de la figura: fig.width, fig.height, fig.asp, out.width y out.height. El tamaño de la imagen es un desafío porque hay dos tamaños (el tamaño de la figura creada por R y el tamaño al que se inserta en el documento de salida) y varias formas de especificarlo (es decir, altura, ancho y relación de aspecto: elige dos de tres).\nSolo uso tres de las cinco opciones:\n\nEncuentro estéticamente más agradable que los gráficos tengan un ancho consistente. Para hacer cumplir esto, configuro fig.width = 6 (6 “) y fig.asp = 0.618 (la proporción áurea) en los valores predeterminados. Luego, en bloques individuales, solo ajusto fig.asp.\nControlo el tamaño de salida con out.width y lo configuro a un porcentaje del ancho de línea). De manera predeterminada, out.width = \"70%\" y fig.align = \"center\". Eso le da a los gráficos cierto espacio para respirar, sin ocupar demasiado espacio.\nPara poner múltiples gráficos en una sola fila, establezco out.width en 50% para dos gráficos, 33% en 3 gráficos, o 25% en 4 gráficos, y setfig.align = \"default\". Dependiendo de lo que intento ilustrar (por ejemplo, mostrar datos o variacionesdel gráfico), también modificaré fig.width cómo se explica a continuación.\n\nSi observas que tienes que entrecerrar los ojos para leer el texto de tu gráfico, debes ajustar fig.width. Si fig.width es mayor que el tamaño de la figura en el documento final, el texto será demasiado pequeño; si fig.width es más pequeño, el texto será demasiado grande. A menudo necesitarás experimentar un poco para calcular la proporción correcta entre fig.width y el ancho asociado en tu documento. Para ilustrar el principio, los siguientes tres gráficos tienen fig.width de 4, 6 y 8, respectivamente:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSi deseas asegurarte que el tamaño de fuente es el mismo en todas tus figuras, al establecer out.width, también necesitarás ajustar fig.width para mantener la misma proporción en relación al out.width predeterminado. Por ejemplo, si tu valor predeterminado de fig.width es 6 y out.width es 0.7, cuando establezcas out.width = \"50%\" necesitarás establecer fig.width a 4.3 (6 * 0.5 / 0.7).\n\n\n28.7.2 Otras opciones importantes\nAl mezclar código y texto, como hago en este libro, recomiendo configurar fig.show = \"hold\" para que los gráficos se muestren después del código. Esto tiene el agradable efecto secundario de obligarte a dividir grandes bloques de código con sus explicaciones.\nPara agregar un título al gráfico, usa fig.cap. En R Markdown esto cambiará la figura de “inline” a “floating”.\nSi estás produciendo resultados en formato PDF, el tipo de gráficos predeterminado es PDF. Esta es una buena configuración predeterminada porque los PDF son gráficos vectoriales de alta calidad. Sin embargo, pueden generar gráficos muy grandes y lentos si muestras miles de puntos. En ese caso, configura dev = \"png\" para forzar el uso de PNG. Son de calidad ligeramente inferior, pero serán mucho más compactos.\nEs una buena idea darles nombres a los bloques de código que producen figuras, incluso si no etiquetas rutinariamente otros bloques. Etiquetar el bloque se utiliza para generar el nombre de archivo del gráfico en el disco, por lo que darle un nombre a los bloques hace que sea mucho más fácil seleccionar gráficas y reutilizarlas en otras circunstancias (por ejemplo, si deseas colocar rápidamente un solo gráfico en un correo electrónico o un tweet)."
  },
  {
    "objectID": "28-communicate-plots.html#aprendiendo-más",
    "href": "28-communicate-plots.html#aprendiendo-más",
    "title": "28  Comunicar con gráficos",
    "section": "28.8 Aprendiendo más",
    "text": "28.8 Aprendiendo más\nEl mejor lugar para aprender más es el libro de ggplot2: ggplot2: Elegant graphics for data analysis. Este explica con mucha más profundidad la teoría subyacente y tiene muchos más ejemplos de cómo combinar las piezas individuales para resolver problemas prácticos. Desafortunadamente, el libro no está disponible en línea de forma gratuita, aunque puede encontrar el código fuente en https://github.com/hadley/ggplot2-book.\nOtro gran recurso es la guía de extensiones ggplot2 https://exts.ggplot2.tidyverse.org/gallery/. Este sitio enumera muchos de los paquetes que amplían ggplot2 con nuevos geoms y escalas. Es un buen lugar para comenzar si tratas de hacer algo que parece difícil con ggplot2."
  },
  {
    "objectID": "29-rmarkdown-formats.html#introducción",
    "href": "29-rmarkdown-formats.html#introducción",
    "title": "29  Formatos de R Markdown",
    "section": "29.1 Introducción",
    "text": "29.1 Introducción\nHasta ahora has visto R Markdown usado para producir documentos HTML. Este capítulo muestra una breve descripción de algunos de los muchos otros tipos de documentos que puedes generar con R Markdown. Hay dos maneras de definir el output de un documento:\n\nDe forma permanente, modificando el encabezado YAML:\ntitle: \"Demo Viridis\"\noutput: html_document\nDe forma transitoria, llamando rmarkdown::render() directamente:\n\nrmarkdown::render(\"diamond-sizes.Rmd\", output_format = \"word_document\")\n\nEsto es útil si quieres producir múltiples tipos de outputs programáticamente.\n\nEl botón knit de RStudio genera un archivo con el primer tipo de formato listado en el campooutput. Puedes generar archivos en formatos adicionales haciendo clic en el menú de selección al lado del botón knit."
  },
  {
    "objectID": "29-rmarkdown-formats.html#opciones-de-salida",
    "href": "29-rmarkdown-formats.html#opciones-de-salida",
    "title": "29  Formatos de R Markdown",
    "section": "29.2 Opciones de salida",
    "text": "29.2 Opciones de salida\nCada formato de salida está asociado con una función de R. Puedes escribir foo o pkg::foo. Si omites pkg, por defecto se asume que es rmarkdown. Es importante conocer el nombre de la función que genera el documento de salida, porque así es como obtienes ayuda. Por ejemplo, para saber qué parámetros puedes definir con html_document, busca en ?rmarkdown::html_document.\nPara sobrescribir los parámetros predeterminados necesitas usar un campo de output extendido. Por ejemplo, si quisieras generar un html_document con una tabla de contenido flotante, deberías usar:\noutput:\n  html_document:\n    toc: true\n    toc_float: true\nIncluso puedes generar múltiples salidas suministrando una lista de formatos:\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n  pdf_document: default\nNota la sintaxis especial si no quieres modificar ninguna de las opciones por defecto: debes agregar default."
  },
  {
    "objectID": "29-rmarkdown-formats.html#documentos",
    "href": "29-rmarkdown-formats.html#documentos",
    "title": "29  Formatos de R Markdown",
    "section": "29.3 Documentos",
    "text": "29.3 Documentos\nEl capítulo anterior se enfocó en en la salida por defecto, que es html_document. Sin embargo, hay un número de variaciones básicas para generar diferentes tipos de documentos:\n\npdf_document crea un PDF con LaTeX (un sistema de código abierto de composición de textos), que necesitarás instalar. RStudio te notificará si no lo tienes.\nword_document para documentos de Microsoft Word (.docx).\nodt_document para documentos de texto OpenDocument (.odt).\nrtf_document para documentos de Formato de Texto Enriquecido (.rtf).\nmd_document para documentos Markdown. Típicamente no es muy útil en sí mismo, pero puedes usarlo si, por ejemplo, tu CMS corporativo o tu wiki de laboratorio usa markdown.\ngithub_document: esta es una versión de md_document específicamente diseñada para compartir en GitHub.\n\nRecuerda que cuando generes un documento para compartirlo con responsables de la toma de decisiones, puedes desactivar la visualización predeterminada de código, definiendo las opciones globales en el fragmento de configuración (setup):\n\nknitr::opts_chunk$set(echo = FALSE)\n\nOtra opción para los html_documentes hacer que los fragmentos de código estén escondidos por defecto, pero visibles con un clic:\noutput:\n  html_document:\n    code_folding: hide"
  },
  {
    "objectID": "29-rmarkdown-formats.html#notebooks",
    "href": "29-rmarkdown-formats.html#notebooks",
    "title": "29  Formatos de R Markdown",
    "section": "29.4 Notebooks",
    "text": "29.4 Notebooks\nUn notebook html_notebook es una variación de un html_document. Los outputs de los dos documentos son muy similares, pero tienen propósitos distintos. Un html_document está enfocado en la comunicación con personas encargadas de la toma de decisiones, mientras que un notebook está enfocado en colaborar con otros/as científicos/as de datos. Estos propósitos diferentes llevan a que la salida HTML sea usada de diferentes maneras. Ambas contendrán todo el output renderizado, pero el notebook también contendrá el código fuente completo. Esto significa que puedes usar el archivo .nb.html generado por el notebook de dos maneras:\n\nPuedes verlo en un navegador web y ver el output generado. A diferencia del html_document, esta renderización siempre incluye una copia incrustada del código fuente que lo generó.\nPuedes editarlo en RStudio. Cuando abras un archivo .nb.html, RStudio automáticamente recreará el archivo .Rmd que lo creó. En el futuro, también podrás incluir archivos de soporte (por ej., archivos de datos .csv), que serán extraídos automáticamente cuando sea necesario.\n\nEnviar archivos .nb.html por correo electrónico es una manera simple de compartir los análisis con tus colegas. Pero las cosas se pondrán difíciles tan pronto como quieras hacer cambios. Si esto empieza a suceder, es un buen momento para aprender Git y GitHub. Aprender Git y Github definitivamente es doloroso al principio, pero la recompensa de la colaboración es enorme. Como se mencionó anteriormente, Git y GitHub están fuera del alcance de este libro, pero este es un consejo útil si ya los estás usando: usa las dos salidas, html_notebook y github_document:\noutput:\n  html_notebook: default\n  github_document: default\nhtml_notebook te da una vista previa local y un archivo que puedes compartir por correo electrónico. github_document crea un archivo md mínimo que puedes ingresar en Git. Puedes revisar fácilmente cómo los resultados de tus análisis (no solo el código) cambian con el tiempo y GitHub lo renderizará muy bien en línea."
  },
  {
    "objectID": "29-rmarkdown-formats.html#presentaciones",
    "href": "29-rmarkdown-formats.html#presentaciones",
    "title": "29  Formatos de R Markdown",
    "section": "29.5 Presentaciones",
    "text": "29.5 Presentaciones\nTambién puedes usar R Markdown para crear presentaciones. Obtienes menos control visual que con herramientas como Keynote y PowerPoint, pero ahorrarás mucho tiempo insertando automáticamente los resultados de tu código R en una presentación. Las presentaciones funcionan dividiendo tu contenido en diapositivas, con una nueva diapositiva que comienza en cada encabezado de primer nivel (#) o de segundo nivel (##). También puedes insertar una regla horizontal (***) para crear una nueva diapositiva sin encabezado.\nR Markdown viene con tres formatos de presentación integrados:\n\nioslides_presentation - Presentación HTML con ioslides.\nslidy_presentation - Presentación HTML con W3C Slidy.\nbeamer_presentation - Presentación PDF con LaTeX Beamer.\n\nOtros dos formatos populares son proporcionados por paquetes:\n\nrevealjs::revealjs_presentation - Presentación HTML con reveal.js. Requiere el paquete revealjs.\nrmdshower, https://github.com/MangoTheCat/rmdshower, proporciona un wrapper para el motor de presentaciones shower, https://github.com/shower/shower ."
  },
  {
    "objectID": "29-rmarkdown-formats.html#dashboards",
    "href": "29-rmarkdown-formats.html#dashboards",
    "title": "29  Formatos de R Markdown",
    "section": "29.6 Dashboards",
    "text": "29.6 Dashboards\nLos dashboards o tableros de control son una forma útil de comunicar grandes cantidades de información de forma visual y rápida. Flexdashboard hace que sea particularmente fácil crear dashboards usando R Markdown y proporciona una convención de cómo los encabezados afectan el diseño:\n\nCada encabezado de Nivel 1 (#) comienza una nueva página en el dashboard.\nCada encabezado de Nivel 2 (##) comienza una nueva columna.\nCada encabezado de Nivel 3 (###) comienza una nueva fila.\n\nPor ejemplo, puedes producir este dashboard:\n\n\n\n\n\nUsando este código:\n\n\n---\ntitle: \"Dashboard de distribución de diamantes\"\noutput: flexdashboard::flex_dashboard\n---\n\n```{r setup, include = FALSE}\nlibrary(datos)\nlibrary(ggplot2)\nlibrary(dplyr)\nknitr::opts_chunk$set(fig.width = 5, fig.asp = 1 / 3)\n```\n\n## Columna 1\n\n### Quilate\n\n```{r}\nggplot(diamantes, aes(quilate)) + geom_histogram(binwidth = 0.1)\n```\n\n### Corte\n\n```{r}\nggplot(diamantes, aes(corte)) + geom_bar()\n```\n\n### Color\n\n```{r}\nggplot(diamantes, aes(color)) + geom_bar()\n```\n\n## Columna 2\n\n### Diamantes más grandes\n\n```{r}\ndiamantes %&gt;%\n  arrange(desc(quilate)) %&gt;%\n  head(100) %&gt;%\n  select(quilate, corte, color, precio) %&gt;%\n  DT::datatable()\n```\n\n\nFlexdashboard también proporciona herramientas simples para crear barras laterales, tabuladores, cuadros de valores y medidores. Para obtener más información (en inglés) acerca de Flexdashboard visita http://rmarkdown.rstudio.com/flexdashboard/."
  },
  {
    "objectID": "29-rmarkdown-formats.html#interactividad",
    "href": "29-rmarkdown-formats.html#interactividad",
    "title": "29  Formatos de R Markdown",
    "section": "29.7 Interactividad",
    "text": "29.7 Interactividad\nCualquier formato HTML (documento, notebook, presentación o dashboard) puede contener componentes interactivos.\n\n29.7.1 htmlwidgets\nHTML es un formato interactivo y puedes aprovechar esa interactividad con htmlwidgets, que son funciones de R que producen visualizaciones HTML interactivas. Por ejemplo, fíjate en el mapa de leaflet a continuación. Si estás viendo esta página en la web, puedes arrastrar el mapa, acercar y alejar, etc. Obviamente no puedes hacer esto en un libro, por lo que RMarkdown automáticamente inserta una captura de pantalla estática.\n\nlibrary(leaflet)\nleaflet() %&gt;%\n  setView(174.764, -36.877, zoom = 16) %&gt;% \n  addTiles() %&gt;%\n  addMarkers(174.764, -36.877, popup = \"Maungawhau\") \n\n\n\n\n\nLo bueno de htmlwidgets es que no necesitas saber nada sobre HTML o JavaScript para usarlos. Todos los detalles están incluidos en el paquete, por lo que no tienes que preocuparte por eso.\nHay muchos paquetes que proporcionan htmlwidgets, incluyendo:\n\ndygraphs, http://rstudio.github.io/dygraphs/, para visualizaciones interactivas de series de tiempo.\nDT, http://rstudio.github.io/DT/, para tablas interactivas.\nthreejs, https://github.com/bwlewis/rthreejs, para plots 3D interactivos.\nDiagrammeR, http://rich-iannone.github.io/DiagrammeR/, para diagramas (como diagramas de flujo y diagramas simples de nodos).\n\nPara obtener más información sobre los htmlwidgets y ver una lista más completa de los paquetes que los proporcionan, visita http://www.htmlwidgets.org/.\n\n\n29.7.2 Shiny\nLos htmlwidgets proporcionan interactividad del lado del cliente, es decir que toda la interactividad ocurre en el navegador, independientemente de R. Por un lado, esto es bueno porque puedes distribuir el archivo HTML sin ninguna conexión con R. Sin embargo, también limita fundamentalmente lo que puedes hacer a las cosas que han sido implementadas en HTML y JavaScript. Una alternativa es usar shiny, un paquete que te permite crear interactividad usando código R, no JavaScript.\nPara llamar código Shiny desde un documento R Markdown, agrega runtime: shiny al encabezado:\ntitle: \"Applicación Web Shiny\"\noutput: html_document\nruntime: shiny\nLuego puedes usar las funciones de “input” para agregar componentes interactivos al documento:\n\nlibrary(shiny)\ntextInput(\"nombre\", \"Cuál es tu nombre?\")\nnumericInput(\"edad\", \"Cuántos años tienes?\", NA, min = 0, max = 150)\n\n\n\n\n\n\nDespués puedes referirte a los valores con input$nombre e input$edad y el código que los usa se volverá a ejecutar automáticamente cada vez que los valores cambien.\nNo podemos mostrarte una aplicación Shiny corriendo ahora porque las interacciones de Shiny ocurren en el lado del servidor. Esto quiere decir que puedes escribir aplicaciones interactivas sin saber JavaScript, pero necesitas un servidor para correrlas. Esto introduce un problema logístico: Las aplicaciones Shiny necesitan un servidor para correr en línea. Cuando corres una aplicación Shiny en tu propia computadora, Shiny automáticamente crea un servidor Shiny para que la puedas correr, pero necesitarás un servidor Shiny público si quieres proporcionar este tipo de interactividad en línea. Ésta es la limitación fundamental de Shiny: puedes crear en Shiny todo lo que puedes crear en R, pero necesitarás que R esté corriendo en algún lugar.\nAprende más sobre Shiny en: http://shiny.rstudio.com/."
  },
  {
    "objectID": "29-rmarkdown-formats.html#sitios-web",
    "href": "29-rmarkdown-formats.html#sitios-web",
    "title": "29  Formatos de R Markdown",
    "section": "29.8 Sitios Web",
    "text": "29.8 Sitios Web\nCon un poco más de infraestructura puedes usar R Markdown para crear un sitio web completo:\n\nColoca todos tus archivos .Rmd en un mismo directorio. index.Rmd será tu página de inicio.\nAgrega un archivo YAML llamado _site.yml que proporcionará la navegación para el sitio. Por ejemplo:\n\n\nname: \"mi-sitio\"\nnavbar:\n  title: \"Mi Sitio\"\n  left:\n    - text: \"Inicio\"\n      href: index.html\n    - text: \"Colores Viridis\"\n      href: 1-example.html\n    - text: \"Colores Terrain\"\n      href: 3-inline.html\n\n\n\nEjecuta rmarkdown::render_site() para crear _site, un directorio de archivos listo para ser implementado como un sitio web estático independiente, o si usas un proyecto de RStudio para el directorio de tu sitio web, RStudio agregará una pestaña de compilación que puedes usar para crear y obtener una vista previa de tu sitio.\nLee más acerca de sitios web en: http://rmarkdown.rstudio.com/rmarkdown_websites.html."
  },
  {
    "objectID": "29-rmarkdown-formats.html#otros-formatos",
    "href": "29-rmarkdown-formats.html#otros-formatos",
    "title": "29  Formatos de R Markdown",
    "section": "29.9 Otros Formatos",
    "text": "29.9 Otros Formatos\nOtros paquetes proveen incluso más formatos de salida:\n\nEl paquete bookdown, https://github.com/rstudio/bookdown, hace que crear libros, como este mismo, sea fácil. Para aprender más, lee Authoring Books with R Markdown, de Yihui Xie, el que, por supuesto, escrito en bookdown. Visita http://www.bookdown.org para ver otros libros bookdown escritos por la comunidad de R.\nEl paquete prettydoc, https://github.com/yixuan/prettydoc/, proporciona formatos livianos de documentos con una gama de temas atractivos.\nEl paquete rticles, https://github.com/rstudio/rticles, compila una selección de formatos específicos para revistas científicas.\n\nConsulta http://rmarkdown.rstudio.com/formats.html para ver una lista de más formatos. También puedes crear tu propio formato siguiendo las instrucciones en inglés de: http://rmarkdown.rstudio.com/developer_custom_formats.html."
  },
  {
    "objectID": "29-rmarkdown-formats.html#aprende-más",
    "href": "29-rmarkdown-formats.html#aprende-más",
    "title": "29  Formatos de R Markdown",
    "section": "29.10 Aprende más",
    "text": "29.10 Aprende más\nPara obtener más información sobre comunicación efectiva con estos diferentes formatos, recomiendo los siguientes recursos (en inglés):\n\nPara mejorar tus habilidades de presentación, recomiendo: Presentation Patterns, de Neal Ford, Matthew McCollough y Nathaniel Schutta. Proporciona un conjunto de patrones efectivos (de alto y bajo nivel) que puedes usar para mejorar tus presentaciones.\nSi das charlas académicas, recomiendo que leas la guía para dar charlas del grupo Leek: Leek group guide to giving talks.\nNosotros no lo hemos tomado, pero hemos escuchado buenos comentarios sobre el curso en línea Public Speaking de Matt McGarrity: https://www.coursera.org/learn/public-speaking.\nSi estás creando muchos dashboards, asegúrate de leer: Information Dashboard Design: The Effective Visual Communication of Data. Te ayudará a crear dashboards realmente útiles y no solo bonitos a la vista.\nComunicar tus ideas efectivamente a menudo se beneficia de un poco de conocimiento en diseño gráfico. El libro de diseño para no diseñadores, The Non-Designer’s Design Book, es un buen lugar para empezar."
  },
  {
    "objectID": "30-rmarkdown-workflow.html",
    "href": "30-rmarkdown-workflow.html",
    "title": "30  Flujo de trabajo en R Markdown",
    "section": "",
    "text": "Anteriormente discutimos un flujo de trabajo básico para capturar tu código de R en el que trabajas interactivamente en la consola y luego capuras los que funciona en el editor de script. R Markdown une la consola y el editor de script, desdibujando los límites entre exploración interactiva y captura de código a largo plazo. Puedes iterar rápidamente dentro un bloque, editando y re-ejecutando con Cmd/Ctrl + Shift + Enter. Cuando estés conforme, puedes seguir adelante e iniciar un nuevo bloque.\nR Markdown es importante también ya que integra de manera estrecha prosa y código. Esto hace que sea un gran cuaderno de análisis, porque permite desarrollar código y registrar tus pensamientos. Un cuaderno de análisis comparte muchos de los mismos objetivos que tiene un cuaderno de laboratorio clásico en las ciencias físicas. Puede:\n\nRegistrar qué se hizo y por qué se hizo. Independientemente de cuán buena sea tu memoria, si no registras lo que haces llegará un momento en que habrás olvidado detalles importantes.\nApoyar el pensamiento riguroso. Es mas probable que logres un análisis sólido si registras tus pensamientos mientras avanzas y continuas reflexionando sobre ellos. Esto también te ahorra tiempo cuando eventualmente escribas tu análisis para compartir con otros.\nAyudar a que otras personas comprendan tu trabajo. Es raro hacer un análisis de datos por sola/o; con frecuencia trabajarás como parte de un equipo. Un cuaderno de laboratorio ayuda a que compartas no solo lo que has hecho, sino también por qué lo hiciste con tus colegas.\n\nMuchos de estos buenos consejos sobre el uso efectivo de cuadernos de laboratorio pueden también ser aplicados a los cuadernos de análisis. Hemos extraído de nuestras propias experiencias y los consejos de Colin Purrington sobre cuadernos de laboratorio (http://colinpurrington.com/tips/lab-notebooks) para sugerir los siguientes consejos:\n\nAsegúrate de que cada cuaderno tenga un título descriptivo, un nombre de archivo evocativo y un primer párrafo que describa brevemente los objetivos del análisis.\nUtiliza el campo para fecha del encabezado YAML para registrar la fecha en la que comienzas a trabajar en el cuaderno:\ndate: 2016-08-23\nUtiliza el formato ISO8601 AAAA-MM-DD para que no haya ambiguedad. ¡Utilízalo incluso si no escribes normalmente fechas de ese modo!\nSi pasas mucho tiempo en una idea de análisis y resulta ser un callejón sin salida, ¡no la elimines! Escribe una nota breve sobre por qué falló y déjala en el cuaderno. Esto te ayudará a evitar ir por el mismo callejón sin salida cuando regreses a ese análisis en el futuro.\nGeneralmente, es mejor que hagas la entrada de datos fuera de R. Pero si necesitas registrar un pequeño bloque de datos, establécelo de modo claro usando tibble::tribble().\nSi descubres un error en un archivo de datos, nunca lo modifiques directamente,\nsino que escribe código para corregir el valor. Explica por qué lo corregiste.\nAntes de concluir el día, asgúrate de que puedes hacer knit en archivo (si utilizas cacheo, asegúrate de limpiar los cachés). Esto te permitirá corregir cualquier problema mientras el código está todavía fresco en tu mente.\nSi quieres que tu código sea reproducible a largo plazo (es decir, que puedas regresar a ejecutarlo el mes próximo o el año próximo), necesitarás registrar las versiones de los paquetes que tu código usa. Un enfoque riguroso es usar packrat, http://rstudio.github.io/packrat/, el cual almacena paquetes en tu directorio de proyecto, o checkpoint, https://github.com/RevolutionAnalytics/checkpoint, el que reinstala paquetes disponibles en una fecha determinada. Un truco rápido es incluir un bloque que ejecute sessionInfo() — , esto no te permitirá recrear fácilmente tus paquetes tal y como están hoy, pero por lo menos sabrás cuales eran.\nCrearás muchos, muchos, muchos cuadernos de análisis a lo largo de tu carrera. ¿Cómo puedes organizarlos de modo tal que puedas encontrarlos otra vez en el futuro? Recomendamos almacenarlos en proyectos individuales y tener un buen esquema para nombrarlos."
  }
]